[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "albumentations",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "albumentations",
        "description": "albumentations",
        "detail": "albumentations",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "DetectMultiBackend",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DetectMultiBackend",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "C3",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "SPP",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "SPPF",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "BottleneckCSP",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "C3x",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Concat",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Conv",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "CrossConv",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DWConvTranspose2d",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Focus",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "autopad",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "C3",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "C3SPP",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "C3TR",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "SPP",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "SPPF",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "BottleneckCSP",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "C3Ghost",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "C3x",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Classify",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Concat",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Contract",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Conv",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "CrossConv",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DetectMultiBackend",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DWConvTranspose2d",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Expand",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Focus",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "GhostBottleneck",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "GhostConv",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "Proto",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DetectMultiBackend",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DetectMultiBackend",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DetectMultiBackend",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "DetectMultiBackend",
        "importPath": "models.common",
        "description": "models.common",
        "isExtraImport": true,
        "detail": "models.common",
        "documentation": {}
    },
    {
        "label": "classify_transforms",
        "importPath": "utils.augmentations",
        "description": "utils.augmentations",
        "isExtraImport": true,
        "detail": "utils.augmentations",
        "documentation": {}
    },
    {
        "label": "Albumentations",
        "importPath": "utils.augmentations",
        "description": "utils.augmentations",
        "isExtraImport": true,
        "detail": "utils.augmentations",
        "documentation": {}
    },
    {
        "label": "augment_hsv",
        "importPath": "utils.augmentations",
        "description": "utils.augmentations",
        "isExtraImport": true,
        "detail": "utils.augmentations",
        "documentation": {}
    },
    {
        "label": "classify_albumentations",
        "importPath": "utils.augmentations",
        "description": "utils.augmentations",
        "isExtraImport": true,
        "detail": "utils.augmentations",
        "documentation": {}
    },
    {
        "label": "classify_transforms",
        "importPath": "utils.augmentations",
        "description": "utils.augmentations",
        "isExtraImport": true,
        "detail": "utils.augmentations",
        "documentation": {}
    },
    {
        "label": "copy_paste",
        "importPath": "utils.augmentations",
        "description": "utils.augmentations",
        "isExtraImport": true,
        "detail": "utils.augmentations",
        "documentation": {}
    },
    {
        "label": "letterbox",
        "importPath": "utils.augmentations",
        "description": "utils.augmentations",
        "isExtraImport": true,
        "detail": "utils.augmentations",
        "documentation": {}
    },
    {
        "label": "mixup",
        "importPath": "utils.augmentations",
        "description": "utils.augmentations",
        "isExtraImport": true,
        "detail": "utils.augmentations",
        "documentation": {}
    },
    {
        "label": "random_perspective",
        "importPath": "utils.augmentations",
        "description": "utils.augmentations",
        "isExtraImport": true,
        "detail": "utils.augmentations",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadScreenshots",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "create_classification_dataloader",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "create_classification_dataloader",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "exif_transpose",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "letterbox",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadScreenshots",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadScreenshots",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "utils.dataloaders",
        "description": "utils.dataloaders",
        "isExtraImport": true,
        "detail": "utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "cv2",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "DATASETS_DIR",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "WorkingDirectory",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_git_info",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_git_status",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_suffix",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "is_jupyter",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "scale_boxes",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "cv2",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "scale_boxes",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "scale_segments",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_amp",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_git_info",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_git_status",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_suffix",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "get_latest_run",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_class_weights",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_image_weights",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "one_cycle",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_mutation",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "coco80_to_coco91_class",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "scale_boxes",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "resample_segments",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "segment2box",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywhn2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "DATASETS_DIR",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "clean_str",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "cv2",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "is_colab",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "is_kaggle",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "segments2boxes",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "unzip_file",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyn2xy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywhn2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywhn",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "clip_boxes",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "file_date",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "git_describe",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "file_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "cv2",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "scale_boxes",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "file_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "get_default_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "url2file",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_amp",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_git_info",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_git_status",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_suffix",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "get_latest_run",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_class_weights",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_image_weights",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "methods",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "one_cycle",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_mutation",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "coco80_to_coco91_class",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "scale_boxes",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "utils.general",
        "description": "utils.general",
        "isExtraImport": true,
        "detail": "utils.general",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "reshape_classifier_output",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_DDP",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_optimizer",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smartCrossEntropyLoss",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "copy_attr",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_conv_and_bn",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "initialize_weights",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "profile",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "scale_img",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_sync",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_DDP",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_optimizer",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_resume",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "profile",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_DDP",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_optimizer",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_resume",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "utils.torch_utils",
        "description": "utils.torch_utils",
        "isExtraImport": true,
        "detail": "utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "check_output",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "torch.hub",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.hub",
        "description": "torch.hub",
        "detail": "torch.hub",
        "documentation": {}
    },
    {
        "label": "torch.optim.lr_scheduler",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim.lr_scheduler",
        "description": "torch.optim.lr_scheduler",
        "detail": "torch.optim.lr_scheduler",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "amp",
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "isExtraImport": true,
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "amp",
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "isExtraImport": true,
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "val",
        "importPath": "classify",
        "description": "classify",
        "isExtraImport": true,
        "detail": "classify",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "MixConv2d",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "MixConv2d",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "importPath": "models.experimental",
        "description": "models.experimental",
        "isExtraImport": true,
        "detail": "models.experimental",
        "documentation": {}
    },
    {
        "label": "ClassificationModel",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "Detect",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "Segment",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "ClassificationModel",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "Detect",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models.yolo",
        "description": "models.yolo",
        "isExtraImport": true,
        "detail": "models.yolo",
        "documentation": {}
    },
    {
        "label": "GenericLogger",
        "importPath": "utils.loggers",
        "description": "utils.loggers",
        "isExtraImport": true,
        "detail": "utils.loggers",
        "documentation": {}
    },
    {
        "label": "GenericLogger",
        "importPath": "utils.loggers",
        "description": "utils.loggers",
        "isExtraImport": true,
        "detail": "utils.loggers",
        "documentation": {}
    },
    {
        "label": "LOGGERS",
        "importPath": "utils.loggers",
        "description": "utils.loggers",
        "isExtraImport": true,
        "detail": "utils.loggers",
        "documentation": {}
    },
    {
        "label": "Loggers",
        "importPath": "utils.loggers",
        "description": "utils.loggers",
        "isExtraImport": true,
        "detail": "utils.loggers",
        "documentation": {}
    },
    {
        "label": "imshow_cls",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "feature_visualization",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_evolve",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_labels",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_val_study",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_evolve",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_val_study",
        "importPath": "utils.plots",
        "description": "utils.plots",
        "isExtraImport": true,
        "detail": "utils.plots",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contextlib",
        "description": "contextlib",
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "ZipFile",
        "importPath": "zipfile",
        "description": "zipfile",
        "isExtraImport": true,
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "is_zipfile",
        "importPath": "zipfile",
        "description": "zipfile",
        "isExtraImport": true,
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ExifTags",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageOps",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "threaded",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "threaded",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "notebook_init",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "importPath": "utils.downloads",
        "description": "utils.downloads",
        "isExtraImport": true,
        "detail": "utils.downloads",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "importPath": "utils.downloads",
        "description": "utils.downloads",
        "isExtraImport": true,
        "detail": "utils.downloads",
        "documentation": {}
    },
    {
        "label": "is_url",
        "importPath": "utils.downloads",
        "description": "utils.downloads",
        "isExtraImport": true,
        "detail": "utils.downloads",
        "documentation": {}
    },
    {
        "label": "curl_download",
        "importPath": "utils.downloads",
        "description": "utils.downloads",
        "isExtraImport": true,
        "detail": "utils.downloads",
        "documentation": {}
    },
    {
        "label": "gsutil_getsize",
        "importPath": "utils.downloads",
        "description": "utils.downloads",
        "isExtraImport": true,
        "detail": "utils.downloads",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "importPath": "utils.downloads",
        "description": "utils.downloads",
        "isExtraImport": true,
        "detail": "utils.downloads",
        "documentation": {}
    },
    {
        "label": "is_url",
        "importPath": "utils.downloads",
        "description": "utils.downloads",
        "isExtraImport": true,
        "detail": "utils.downloads",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "keras",
        "importPath": "tensorflow",
        "description": "tensorflow",
        "isExtraImport": true,
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "SiLU",
        "importPath": "utils.activations",
        "description": "utils.activations",
        "isExtraImport": true,
        "detail": "utils.activations",
        "documentation": {}
    },
    {
        "label": "check_anchor_order",
        "importPath": "utils.autoanchor",
        "description": "utils.autoanchor",
        "isExtraImport": true,
        "detail": "utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "check_anchors",
        "importPath": "utils.autoanchor",
        "description": "utils.autoanchor",
        "isExtraImport": true,
        "detail": "utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "check_anchors",
        "importPath": "utils.autoanchor",
        "description": "utils.autoanchor",
        "isExtraImport": true,
        "detail": "utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "masks2segments",
        "importPath": "utils.segment.general",
        "description": "utils.segment.general",
        "isExtraImport": true,
        "detail": "utils.segment.general",
        "documentation": {}
    },
    {
        "label": "process_mask",
        "importPath": "utils.segment.general",
        "description": "utils.segment.general",
        "isExtraImport": true,
        "detail": "utils.segment.general",
        "documentation": {}
    },
    {
        "label": "process_mask_native",
        "importPath": "utils.segment.general",
        "description": "utils.segment.general",
        "isExtraImport": true,
        "detail": "utils.segment.general",
        "documentation": {}
    },
    {
        "label": "mask_iou",
        "importPath": "utils.segment.general",
        "description": "utils.segment.general",
        "isExtraImport": true,
        "detail": "utils.segment.general",
        "documentation": {}
    },
    {
        "label": "process_mask",
        "importPath": "utils.segment.general",
        "description": "utils.segment.general",
        "isExtraImport": true,
        "detail": "utils.segment.general",
        "documentation": {}
    },
    {
        "label": "process_mask_native",
        "importPath": "utils.segment.general",
        "description": "utils.segment.general",
        "isExtraImport": true,
        "detail": "utils.segment.general",
        "documentation": {}
    },
    {
        "label": "scale_image",
        "importPath": "utils.segment.general",
        "description": "utils.segment.general",
        "isExtraImport": true,
        "detail": "utils.segment.general",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "lr_scheduler",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "lr_scheduler",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "segment.val",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "segment.val",
        "description": "segment.val",
        "detail": "segment.val",
        "documentation": {}
    },
    {
        "label": "run",
        "importPath": "segment.val",
        "description": "segment.val",
        "isExtraImport": true,
        "detail": "segment.val",
        "documentation": {}
    },
    {
        "label": "check_train_batch_size",
        "importPath": "utils.autobatch",
        "description": "utils.autobatch",
        "isExtraImport": true,
        "detail": "utils.autobatch",
        "documentation": {}
    },
    {
        "label": "check_train_batch_size",
        "importPath": "utils.autobatch",
        "description": "utils.autobatch",
        "isExtraImport": true,
        "detail": "utils.autobatch",
        "documentation": {}
    },
    {
        "label": "Callbacks",
        "importPath": "utils.callbacks",
        "description": "utils.callbacks",
        "isExtraImport": true,
        "detail": "utils.callbacks",
        "documentation": {}
    },
    {
        "label": "Callbacks",
        "importPath": "utils.callbacks",
        "description": "utils.callbacks",
        "isExtraImport": true,
        "detail": "utils.callbacks",
        "documentation": {}
    },
    {
        "label": "Callbacks",
        "importPath": "utils.callbacks",
        "description": "utils.callbacks",
        "isExtraImport": true,
        "detail": "utils.callbacks",
        "documentation": {}
    },
    {
        "label": "Callbacks",
        "importPath": "utils.callbacks",
        "description": "utils.callbacks",
        "isExtraImport": true,
        "detail": "utils.callbacks",
        "documentation": {}
    },
    {
        "label": "Callbacks",
        "importPath": "utils.callbacks",
        "description": "utils.callbacks",
        "isExtraImport": true,
        "detail": "utils.callbacks",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "utils.segment.dataloaders",
        "description": "utils.segment.dataloaders",
        "isExtraImport": true,
        "detail": "utils.segment.dataloaders",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "utils.segment.dataloaders",
        "description": "utils.segment.dataloaders",
        "isExtraImport": true,
        "detail": "utils.segment.dataloaders",
        "documentation": {}
    },
    {
        "label": "ComputeLoss",
        "importPath": "utils.segment.loss",
        "description": "utils.segment.loss",
        "isExtraImport": true,
        "detail": "utils.segment.loss",
        "documentation": {}
    },
    {
        "label": "KEYS",
        "importPath": "utils.segment.metrics",
        "description": "utils.segment.metrics",
        "isExtraImport": true,
        "detail": "utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "fitness",
        "importPath": "utils.segment.metrics",
        "description": "utils.segment.metrics",
        "isExtraImport": true,
        "detail": "utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "Metrics",
        "importPath": "utils.segment.metrics",
        "description": "utils.segment.metrics",
        "isExtraImport": true,
        "detail": "utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "ap_per_class_box_and_mask",
        "importPath": "utils.segment.metrics",
        "description": "utils.segment.metrics",
        "isExtraImport": true,
        "detail": "utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "plot_images_and_masks",
        "importPath": "utils.segment.plots",
        "description": "utils.segment.plots",
        "isExtraImport": true,
        "detail": "utils.segment.plots",
        "documentation": {}
    },
    {
        "label": "plot_results_with_masks",
        "importPath": "utils.segment.plots",
        "description": "utils.segment.plots",
        "isExtraImport": true,
        "detail": "utils.segment.plots",
        "documentation": {}
    },
    {
        "label": "plot_images_and_masks",
        "importPath": "utils.segment.plots",
        "description": "utils.segment.plots",
        "isExtraImport": true,
        "detail": "utils.segment.plots",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_ioa",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "fitness",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_iou",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "fitness",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "fitness",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "ap_per_class",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "matplotlib.image",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.image",
        "description": "matplotlib.image",
        "detail": "matplotlib.image",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "Task",
        "importPath": "clearml",
        "description": "clearml",
        "isExtraImport": true,
        "detail": "clearml",
        "documentation": {}
    },
    {
        "label": "HyperParameterOptimizer",
        "importPath": "clearml.automation",
        "description": "clearml.automation",
        "isExtraImport": true,
        "detail": "clearml.automation",
        "documentation": {}
    },
    {
        "label": "UniformParameterRange",
        "importPath": "clearml.automation",
        "description": "clearml.automation",
        "isExtraImport": true,
        "detail": "clearml.automation",
        "documentation": {}
    },
    {
        "label": "OptimizerOptuna",
        "importPath": "clearml.automation.optuna",
        "description": "clearml.automation.optuna",
        "isExtraImport": true,
        "detail": "clearml.automation.optuna",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "comet_ml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "comet_ml",
        "description": "comet_ml",
        "detail": "comet_ml",
        "documentation": {}
    },
    {
        "label": "train",
        "importPath": "train",
        "description": "train",
        "isExtraImport": true,
        "detail": "train",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "dataloader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "distributed",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "torchvision.transforms",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "torchvision.transforms.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.transforms.functional",
        "description": "torchvision.transforms.functional",
        "detail": "torchvision.transforms.functional",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "psutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil",
        "description": "psutil",
        "detail": "psutil",
        "documentation": {}
    },
    {
        "label": "urllib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib",
        "description": "urllib",
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "logging.config",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging.config",
        "description": "logging.config",
        "detail": "logging.config",
        "documentation": {}
    },
    {
        "label": "signal",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "signal",
        "description": "signal",
        "detail": "signal",
        "documentation": {}
    },
    {
        "label": "is_tarfile",
        "importPath": "tarfile",
        "description": "tarfile",
        "isExtraImport": true,
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "typing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "typing",
        "description": "typing",
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "pkg_resources",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pkg_resources",
        "description": "pkg_resources",
        "detail": "pkg_resources",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "gaussian_filter1d",
        "importPath": "scipy.ndimage.filters",
        "description": "scipy.ndimage.filters",
        "isExtraImport": true,
        "detail": "scipy.ndimage.filters",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "export",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "export",
        "description": "export",
        "detail": "export",
        "documentation": {}
    },
    {
        "label": "val",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "val",
        "description": "val",
        "detail": "val",
        "documentation": {}
    },
    {
        "label": "run",
        "importPath": "val",
        "description": "val",
        "isExtraImport": true,
        "detail": "val",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "optimize_for_mobile",
        "importPath": "torch.utils.mobile_optimizer",
        "description": "torch.utils.mobile_optimizer",
        "isExtraImport": true,
        "detail": "torch.utils.mobile_optimizer",
        "documentation": {}
    },
    {
        "label": "check_comet_resume",
        "importPath": "utils.loggers.comet.comet_utils",
        "description": "utils.loggers.comet.comet_utils",
        "isExtraImport": true,
        "detail": "utils.loggers.comet.comet_utils",
        "documentation": {}
    },
    {
        "label": "ComputeLoss",
        "importPath": "utils.loss",
        "description": "utils.loss",
        "isExtraImport": true,
        "detail": "utils.loss",
        "documentation": {}
    },
    {
        "label": "create_annotation_for_image",
        "kind": 2,
        "importPath": "utils.create_annotations",
        "description": "utils.create_annotations",
        "peekOfCode": "def create_annotation_for_image(images_dir: str, labels_dir: str, classes_file_path: str) -> None:\n    \"\"\"\n               \n        dataset/images/train/\n        dataset/images/val/\n           \n        dataset/labels/train/\n        dataset/labels/val/\n              \n          :",
        "detail": "utils.create_annotations",
        "documentation": {}
    },
    {
        "label": "write_data_yaml",
        "kind": 2,
        "importPath": "utils.create_data_yaml",
        "description": "utils.create_data_yaml",
        "peekOfCode": "def write_data_yaml(data_yaml_path: str, classes_file_path: str, train_path: str, val_path: str) -> None:\n    \"\"\"\n            dataset/data.yaml    YOLO\n          :\n        - data_yaml_path: str     \n        - classes_file_path: str        ID\n        - train_path: str        dataset/images/train\n        - val_path: str        dataset/images/val\n    \"\"\"\n    class_amount, classes = get_all_classes(classes_file_path) #       dict()",
        "detail": "utils.create_data_yaml",
        "documentation": {}
    },
    {
        "label": "create_duplicate_elements",
        "kind": 2,
        "importPath": "utils.duplicate_elements",
        "description": "utils.duplicate_elements",
        "peekOfCode": "def create_duplicate_elements(source_dir: str, output_train_dir: str, output_val_dir: str) -> None:\n    \"\"\"\n                   YOLO\n          :\n        - source_dir: str           \n        - output_train_dir: str        \n        - output_val_dir: str        \n    \"\"\"\n    #    \n    create_dir(MEDIA) #   media   ()",
        "detail": "utils.duplicate_elements",
        "documentation": {}
    },
    {
        "label": "get_all_classes",
        "kind": 2,
        "importPath": "utils.get_all_classes",
        "description": "utils.get_all_classes",
        "peekOfCode": "def get_all_classes(classes_file_path: str):\n    \"\"\"\n              ID   classes.txt\n          :\n        classes_file_path: str        ID\n               :\n        key -   \n        value - ID \n    \"\"\"\n    classes: dict = dict() #      ",
        "detail": "utils.get_all_classes",
        "documentation": {}
    },
    {
        "label": "get_file_name",
        "kind": 2,
        "importPath": "utils.get_file_name",
        "description": "utils.get_file_name",
        "peekOfCode": "def get_file_name(path: str) -> str:\n    \"\"\"\n                    \n          :\n        - path: str   \n          \n    \"\"\"\n    full_name = path.split('/')[-1] #     \n    name = full_name.split('.')[0] #   \n    return name ",
        "detail": "utils.get_file_name",
        "documentation": {}
    },
    {
        "label": "get_file_name_for_class",
        "kind": 2,
        "importPath": "utils.get_file_name",
        "description": "utils.get_file_name",
        "peekOfCode": "def get_file_name_for_class(path: str) -> str:\n    \"\"\"\n                  \n              \n          :\n        - path: str   \n          \n    \"\"\"\n    full_name = get_file_name(path) #    \n    result = re.sub(r'_\\d+__\\d+$', '', full_name) #     ",
        "detail": "utils.get_file_name",
        "documentation": {}
    },
    {
        "label": "get_files_from_dir",
        "kind": 2,
        "importPath": "utils.get_files_from_dirs",
        "description": "utils.get_files_from_dirs",
        "peekOfCode": "def get_files_from_dir(dir_path: str) -> list:\n    \"\"\"\n              \n          :\n        - dir_path: str     \n            \n    \"\"\"\n    items: list = list() #     \n    for item in os.listdir(dir_path): #     \n        if os.path.isfile(get_full_path(dir_path, item)): #         ",
        "detail": "utils.get_files_from_dirs",
        "documentation": {}
    },
    {
        "label": "get_dirs_from_dir",
        "kind": 2,
        "importPath": "utils.get_files_from_dirs",
        "description": "utils.get_files_from_dirs",
        "peekOfCode": "def get_dirs_from_dir(dir_path: str) -> list:\n    \"\"\"\n               \n          :\n        - dir_path: str   \n            \n    \"\"\"\n    folders = [item for item in os.listdir(dir_path) if os.path.isdir(get_full_path(dir_path, item))] \n    return folders\n# val = len(get_files_from_dir('media/output_val_dir'))",
        "detail": "utils.get_files_from_dirs",
        "documentation": {}
    },
    {
        "label": "get_full_path",
        "kind": 2,
        "importPath": "utils.get_full_path",
        "description": "utils.get_full_path",
        "peekOfCode": "def get_full_path(dir_path: str, image_name: str) -> str:\n    \"\"\"\n            \n           \n        - dir_path: str    \n        - image_name: str     \n    \"\"\"\n    path = os.path.join(dir_path, image_name) #  \n    return path",
        "detail": "utils.get_full_path",
        "documentation": {}
    },
    {
        "label": "get_class_id_by_name",
        "kind": 2,
        "importPath": "utils.get_image_class_id",
        "description": "utils.get_image_class_id",
        "peekOfCode": "def get_class_id_by_name(class_name: str, file_path: str) -> int:\n    \"\"\"\n           ID    \n                      ID \n          :\n        - class_name: str  \n        - file_path: str      \n         ID \n    \"\"\"\n    create_file(file_path) #        ",
        "detail": "utils.get_image_class_id",
        "documentation": {}
    },
    {
        "label": "create_dir",
        "kind": 2,
        "importPath": "utils.process_dirs",
        "description": "utils.process_dirs",
        "peekOfCode": "def create_dir(dir_name: str) -> None:\n    \"\"\"\n            \n          :\n        - dir_name: str      \n    \"\"\"\n    os.makedirs(dir_name, exist_ok=True) #      \ndef move_dirs(path_from: str, path_to: str) -> None:\n    \"\"\"\n                  ",
        "detail": "utils.process_dirs",
        "documentation": {}
    },
    {
        "label": "move_dirs",
        "kind": 2,
        "importPath": "utils.process_dirs",
        "description": "utils.process_dirs",
        "peekOfCode": "def move_dirs(path_from: str, path_to: str) -> None:\n    \"\"\"\n                  \n          :\n        - path_from: str     \n        - path_to: str     \n    \"\"\"\n    create_dir(path_to) #       \n    for item in os.listdir(path_from): #       \n        item_path = get_full_path(path_from, item) #          ",
        "detail": "utils.process_dirs",
        "documentation": {}
    },
    {
        "label": "delete_dirs",
        "kind": 2,
        "importPath": "utils.process_dirs",
        "description": "utils.process_dirs",
        "peekOfCode": "def delete_dirs(path_to_dir: str) -> None:\n    \"\"\"\n                   \n          :\n        - path_to_dir: str      \n    \"\"\"\n    if os.path.exists(path_to_dir): #    \n        shutil.rmtree(path_to_dir) #   \ndef create_file(file_name: str) -> None:\n    \"\"\"",
        "detail": "utils.process_dirs",
        "documentation": {}
    },
    {
        "label": "create_file",
        "kind": 2,
        "importPath": "utils.process_dirs",
        "description": "utils.process_dirs",
        "peekOfCode": "def create_file(file_name: str) -> None:\n    \"\"\"\n              \n          :\n        - file_name: str      \n    \"\"\"\n    if not os.path.exists(file_name): #    \n        with open(file_name, \"w\") as f: #     \n            pass #      ,       \ndef delete_file(file_path: str) -> None:",
        "detail": "utils.process_dirs",
        "documentation": {}
    },
    {
        "label": "delete_file",
        "kind": 2,
        "importPath": "utils.process_dirs",
        "description": "utils.process_dirs",
        "peekOfCode": "def delete_file(file_path: str) -> None:\n    \"\"\"\n              \n          :\n        - file_path: str      \n    \"\"\"\n    if os.path.exists(file_path): #    \n        os.remove(file_path) #     ",
        "detail": "utils.process_dirs",
        "documentation": {}
    },
    {
        "label": "get_resized_images",
        "kind": 2,
        "importPath": "utils.resize_elements",
        "description": "utils.resize_elements",
        "peekOfCode": "def get_resized_images(images_dir_path: str, output_dir_path: str) -> None:\n    \"\"\"\n                        \n          :\n        - images_dir_path: str     \n        - output_dir_path: str       \n    \"\"\"\n    create_dir(MEDIA) #   media ()\n    all_images = get_files_from_dir(images_dir_path) #     \n    for image in all_images: #      ",
        "detail": "utils.resize_elements",
        "documentation": {}
    },
    {
        "label": "measure_time",
        "kind": 2,
        "importPath": "utils.utils",
        "description": "utils.utils",
        "peekOfCode": "def measure_time(func):\n    \"\"\"\n             \n           \n    \"\"\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        result = func(*args, **kwargs)\n        elapsed = time.time() - start_time",
        "detail": "utils.utils",
        "documentation": {}
    },
    {
        "label": "create_dataset_dir",
        "kind": 2,
        "importPath": "utils.utils",
        "description": "utils.utils",
        "peekOfCode": "def create_dataset_dir(file: str, *dirs: list) -> None:\n    \"\"\"\n             dataset    \n          :\n        - file: str     \n        - *dirs: list         dataset\n    \"\"\"\n    for dir in dirs: #       \n        create_dir(dir) #      \n    create_file(file) #   dataset/data.yaml",
        "detail": "utils.utils",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.classify.predict",
        "description": "yolov5.classify.predict",
        "peekOfCode": "def run(\n    weights=ROOT / \"yolov5s-cls.pt\",  # model.pt path(s)\n    source=ROOT / \"data/images\",  # file/dir/URL/glob/screen/0(webcam)\n    data=ROOT / \"data/coco128.yaml\",  # dataset.yaml path\n    imgsz=(224, 224),  # inference size (height, width)\n    device=\"\",  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n    view_img=False,  # show results\n    save_txt=False,  # save results to *.txt\n    nosave=False,  # do not save images/videos\n    augment=False,  # augmented inference",
        "detail": "yolov5.classify.predict",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.classify.predict",
        "description": "yolov5.classify.predict",
        "peekOfCode": "def parse_opt():\n    \"\"\"Parses command line arguments for YOLOv5 inference settings including model, source, device, and image size.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", nargs=\"+\", type=str, default=ROOT / \"yolov5s-cls.pt\", help=\"model path(s)\")\n    parser.add_argument(\"--source\", type=str, default=ROOT / \"data/images\", help=\"file/dir/URL/glob/screen/0(webcam)\")\n    parser.add_argument(\"--data\", type=str, default=ROOT / \"data/coco128.yaml\", help=\"(optional) dataset.yaml path\")\n    parser.add_argument(\"--imgsz\", \"--img\", \"--img-size\", nargs=\"+\", type=int, default=[224], help=\"inference size h,w\")\n    parser.add_argument(\"--device\", default=\"\", help=\"cuda device, i.e. 0 or 0,1,2,3 or cpu\")\n    parser.add_argument(\"--view-img\", action=\"store_true\", help=\"show results\")\n    parser.add_argument(\"--save-txt\", action=\"store_true\", help=\"save results to *.txt\")",
        "detail": "yolov5.classify.predict",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.classify.predict",
        "description": "yolov5.classify.predict",
        "peekOfCode": "def main(opt):\n    \"\"\"Executes YOLOv5 model inference with options for ONNX DNN and video frame-rate stride adjustments.\"\"\"\n    check_requirements(ROOT / \"requirements.txt\", exclude=(\"tensorboard\", \"thop\"))\n    run(**vars(opt))\nif __name__ == \"__main__\":\n    opt = parse_opt()\n    main(opt)",
        "detail": "yolov5.classify.predict",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.classify.predict",
        "description": "yolov5.classify.predict",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom ultralytics.utils.plotting import Annotator\nfrom models.common import DetectMultiBackend\nfrom utils.augmentations import classify_transforms\nfrom utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\nfrom utils.general import (",
        "detail": "yolov5.classify.predict",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.classify.predict",
        "description": "yolov5.classify.predict",
        "peekOfCode": "ROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom ultralytics.utils.plotting import Annotator\nfrom models.common import DetectMultiBackend\nfrom utils.augmentations import classify_transforms\nfrom utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\nfrom utils.general import (\n    LOGGER,",
        "detail": "yolov5.classify.predict",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.classify.predict",
        "description": "yolov5.classify.predict",
        "peekOfCode": "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom ultralytics.utils.plotting import Annotator\nfrom models.common import DetectMultiBackend\nfrom utils.augmentations import classify_transforms\nfrom utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\nfrom utils.general import (\n    LOGGER,\n    Profile,\n    check_file,\n    check_img_size,",
        "detail": "yolov5.classify.predict",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "def train(opt, device):\n    \"\"\"Trains a YOLOv5 model, managing datasets, model optimization, logging, and saving checkpoints.\"\"\"\n    init_seeds(opt.seed + 1 + RANK, deterministic=True)\n    save_dir, data, bs, epochs, nw, imgsz, pretrained = (\n        opt.save_dir,\n        Path(opt.data),\n        opt.batch_size,\n        opt.epochs,\n        min(os.cpu_count() - 1, opt.workers),\n        opt.imgsz,",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "def parse_opt(known=False):\n    \"\"\"Parses command line arguments for YOLOv5 training including model path, dataset, epochs, and more, returning\n    parsed arguments.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, default=\"yolov5s-cls.pt\", help=\"initial weights path\")\n    parser.add_argument(\"--data\", type=str, default=\"imagenette160\", help=\"cifar10, cifar100, mnist, imagenet, ...\")\n    parser.add_argument(\"--epochs\", type=int, default=10, help=\"total training epochs\")\n    parser.add_argument(\"--batch-size\", type=int, default=64, help=\"total batch size for all GPUs\")\n    parser.add_argument(\"--imgsz\", \"--img\", \"--img-size\", type=int, default=224, help=\"train, val image size (pixels)\")",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "def main(opt):\n    \"\"\"Executes YOLOv5 training with given options, handling device setup and DDP mode; includes pre-training checks.\"\"\"\n    if RANK in {-1, 0}:\n        print_args(vars(opt))\n        check_git_status()\n        check_requirements(ROOT / \"requirements.txt\")\n    # DDP mode\n    device = select_device(opt.device, batch_size=opt.batch_size)\n    if LOCAL_RANK != -1:\n        assert opt.batch_size != -1, \"AutoBatch is coming soon for classification, please pass a valid --batch-size\"",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "def run(**kwargs):\n    \"\"\"\n    Executes YOLOv5 model training or inference with specified parameters, returning updated options.\n    Example: from yolov5 import classify; classify.train.run(data=mnist, imgsz=320, model='yolov5m')\n    \"\"\"\n    opt = parse_opt(True)\n    for k, v in kwargs.items():\n        setattr(opt, k, v)\n    main(opt)\n    return opt",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom classify import val as validate\nfrom models.experimental import attempt_load\nfrom models.yolo import ClassificationModel, DetectionModel\nfrom utils.dataloaders import create_classification_dataloader\nfrom utils.general import (",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "ROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom classify import val as validate\nfrom models.experimental import attempt_load\nfrom models.yolo import ClassificationModel, DetectionModel\nfrom utils.dataloaders import create_classification_dataloader\nfrom utils.general import (\n    DATASETS_DIR,",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom classify import val as validate\nfrom models.experimental import attempt_load\nfrom models.yolo import ClassificationModel, DetectionModel\nfrom utils.dataloaders import create_classification_dataloader\nfrom utils.general import (\n    DATASETS_DIR,\n    LOGGER,\n    TQDM_BAR_FORMAT,\n    WorkingDirectory,",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "kind": 5,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "LOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nGIT_INFO = check_git_info()\ndef train(opt, device):\n    \"\"\"Trains a YOLOv5 model, managing datasets, model optimization, logging, and saving checkpoints.\"\"\"\n    init_seeds(opt.seed + 1 + RANK, deterministic=True)\n    save_dir, data, bs, epochs, nw, imgsz, pretrained = (\n        opt.save_dir,\n        Path(opt.data),",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "RANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nGIT_INFO = check_git_info()\ndef train(opt, device):\n    \"\"\"Trains a YOLOv5 model, managing datasets, model optimization, logging, and saving checkpoints.\"\"\"\n    init_seeds(opt.seed + 1 + RANK, deterministic=True)\n    save_dir, data, bs, epochs, nw, imgsz, pretrained = (\n        opt.save_dir,\n        Path(opt.data),\n        opt.batch_size,",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "WORLD_SIZE",
        "kind": 5,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "WORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nGIT_INFO = check_git_info()\ndef train(opt, device):\n    \"\"\"Trains a YOLOv5 model, managing datasets, model optimization, logging, and saving checkpoints.\"\"\"\n    init_seeds(opt.seed + 1 + RANK, deterministic=True)\n    save_dir, data, bs, epochs, nw, imgsz, pretrained = (\n        opt.save_dir,\n        Path(opt.data),\n        opt.batch_size,\n        opt.epochs,",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "GIT_INFO",
        "kind": 5,
        "importPath": "yolov5.classify.train",
        "description": "yolov5.classify.train",
        "peekOfCode": "GIT_INFO = check_git_info()\ndef train(opt, device):\n    \"\"\"Trains a YOLOv5 model, managing datasets, model optimization, logging, and saving checkpoints.\"\"\"\n    init_seeds(opt.seed + 1 + RANK, deterministic=True)\n    save_dir, data, bs, epochs, nw, imgsz, pretrained = (\n        opt.save_dir,\n        Path(opt.data),\n        opt.batch_size,\n        opt.epochs,\n        min(os.cpu_count() - 1, opt.workers),",
        "detail": "yolov5.classify.train",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.classify.val",
        "description": "yolov5.classify.val",
        "peekOfCode": "def run(\n    data=ROOT / \"../datasets/mnist\",  # dataset dir\n    weights=ROOT / \"yolov5s-cls.pt\",  # model.pt path(s)\n    batch_size=128,  # batch size\n    imgsz=224,  # inference size (pixels)\n    device=\"\",  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n    workers=8,  # max dataloader workers (per RANK in DDP mode)\n    verbose=False,  # verbose output\n    project=ROOT / \"runs/val-cls\",  # save to project/name\n    name=\"exp\",  # save to project/name",
        "detail": "yolov5.classify.val",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.classify.val",
        "description": "yolov5.classify.val",
        "peekOfCode": "def parse_opt():\n    \"\"\"Parses and returns command line arguments for YOLOv5 model evaluation and inference settings.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--data\", type=str, default=ROOT / \"../datasets/mnist\", help=\"dataset path\")\n    parser.add_argument(\"--weights\", nargs=\"+\", type=str, default=ROOT / \"yolov5s-cls.pt\", help=\"model.pt path(s)\")\n    parser.add_argument(\"--batch-size\", type=int, default=128, help=\"batch size\")\n    parser.add_argument(\"--imgsz\", \"--img\", \"--img-size\", type=int, default=224, help=\"inference size (pixels)\")\n    parser.add_argument(\"--device\", default=\"\", help=\"cuda device, i.e. 0 or 0,1,2,3 or cpu\")\n    parser.add_argument(\"--workers\", type=int, default=8, help=\"max dataloader workers (per RANK in DDP mode)\")\n    parser.add_argument(\"--verbose\", nargs=\"?\", const=True, default=True, help=\"verbose output\")",
        "detail": "yolov5.classify.val",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.classify.val",
        "description": "yolov5.classify.val",
        "peekOfCode": "def main(opt):\n    \"\"\"Executes the YOLOv5 model prediction workflow, handling argument parsing and requirement checks.\"\"\"\n    check_requirements(ROOT / \"requirements.txt\", exclude=(\"tensorboard\", \"thop\"))\n    run(**vars(opt))\nif __name__ == \"__main__\":\n    opt = parse_opt()\n    main(opt)",
        "detail": "yolov5.classify.val",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.classify.val",
        "description": "yolov5.classify.val",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.common import DetectMultiBackend\nfrom utils.dataloaders import create_classification_dataloader\nfrom utils.general import (\n    LOGGER,\n    TQDM_BAR_FORMAT,",
        "detail": "yolov5.classify.val",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.classify.val",
        "description": "yolov5.classify.val",
        "peekOfCode": "ROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.common import DetectMultiBackend\nfrom utils.dataloaders import create_classification_dataloader\nfrom utils.general import (\n    LOGGER,\n    TQDM_BAR_FORMAT,\n    Profile,",
        "detail": "yolov5.classify.val",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.classify.val",
        "description": "yolov5.classify.val",
        "peekOfCode": "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.common import DetectMultiBackend\nfrom utils.dataloaders import create_classification_dataloader\nfrom utils.general import (\n    LOGGER,\n    TQDM_BAR_FORMAT,\n    Profile,\n    check_img_size,\n    check_requirements,\n    colorstr,",
        "detail": "yolov5.classify.val",
        "documentation": {}
    },
    {
        "label": "Conv",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class Conv(nn.Module):\n    \"\"\"Applies a convolution, batch normalization, and activation function to an input tensor in a neural network.\"\"\"\n    default_act = nn.SiLU()  # default activation\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n        \"\"\"Initializes a standard convolution layer with optional batch normalization and activation.\"\"\"\n        super().__init__()\n        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n        self.bn = nn.BatchNorm2d(c2)\n        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n    def forward(self, x):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class DWConv(Conv):\n    \"\"\"Implements a depth-wise convolution layer with optional activation for efficient spatial filtering.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, d=1, act=True):\n        \"\"\"Initializes a depth-wise convolution layer with optional activation; args: input channels (c1), output\n        channels (c2), kernel size (k), stride (s), dilation (d), and activation flag (act).\n        \"\"\"\n        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), d=d, act=act)\nclass DWConvTranspose2d(nn.ConvTranspose2d):\n    \"\"\"A depth-wise transpose convolutional layer for upsampling in neural networks, particularly in YOLOv5 models.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "DWConvTranspose2d",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class DWConvTranspose2d(nn.ConvTranspose2d):\n    \"\"\"A depth-wise transpose convolutional layer for upsampling in neural networks, particularly in YOLOv5 models.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0):\n        \"\"\"Initializes a depth-wise transpose convolutional layer for YOLOv5; args: input channels (c1), output channels\n        (c2), kernel size (k), stride (s), input padding (p1), output padding (p2).\n        \"\"\"\n        super().__init__(c1, c2, k, s, p1, p2, groups=math.gcd(c1, c2))\nclass TransformerLayer(nn.Module):\n    \"\"\"Transformer layer with multihead attention and linear layers, optimized by removing LayerNorm.\"\"\"\n    def __init__(self, c, num_heads):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "TransformerLayer",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class TransformerLayer(nn.Module):\n    \"\"\"Transformer layer with multihead attention and linear layers, optimized by removing LayerNorm.\"\"\"\n    def __init__(self, c, num_heads):\n        \"\"\"\n        Initializes a transformer layer, sans LayerNorm for performance, with multihead attention and linear layers.\n        See  as described in https://arxiv.org/abs/2010.11929.\n        \"\"\"\n        super().__init__()\n        self.q = nn.Linear(c, c, bias=False)\n        self.k = nn.Linear(c, c, bias=False)",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "TransformerBlock",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class TransformerBlock(nn.Module):\n    \"\"\"A Transformer block for vision tasks with convolution, position embeddings, and Transformer layers.\"\"\"\n    def __init__(self, c1, c2, num_heads, num_layers):\n        \"\"\"Initializes a Transformer block for vision tasks, adapting dimensions if necessary and stacking specified\n        layers.\n        \"\"\"\n        super().__init__()\n        self.conv = None\n        if c1 != c2:\n            self.conv = Conv(c1, c2)",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class Bottleneck(nn.Module):\n    \"\"\"A bottleneck layer with optional shortcut and group convolution for efficient feature extraction.\"\"\"\n    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes a standard bottleneck layer with optional shortcut and group convolution, supporting channel\n        expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_, c2, 3, 1, g=g)",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "BottleneckCSP",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class BottleneckCSP(nn.Module):\n    \"\"\"CSP bottleneck layer for feature extraction with cross-stage partial connections and optional shortcuts.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes CSP bottleneck with optional shortcuts; args: ch_in, ch_out, number of repeats, shortcut bool,\n        groups, expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "CrossConv",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class CrossConv(nn.Module):\n    \"\"\"Implements a cross convolution layer with downsampling, expansion, and optional shortcut.\"\"\"\n    def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False):\n        \"\"\"\n        Initializes CrossConv with downsampling, expanding, and optionally shortcutting; `c1` input, `c2` output\n        channels.\n        Inputs are ch_in, ch_out, kernel, stride, groups, expansion, shortcut.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "C3",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class C3(nn.Module):\n    \"\"\"Implements a CSP Bottleneck module with three convolutions for enhanced feature extraction in neural networks.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes C3 module with options for channel count, bottleneck repetition, shortcut usage, group\n        convolutions, and expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "C3x",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class C3x(C3):\n    \"\"\"Extends the C3 module with cross-convolutions for enhanced feature extraction in neural networks.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes C3x module with cross-convolutions, extending C3 with customizable channel dimensions, groups,\n        and expansion.\n        \"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)\n        self.m = nn.Sequential(*(CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)))\nclass C3TR(C3):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "C3TR",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class C3TR(C3):\n    \"\"\"C3 module with TransformerBlock for enhanced feature extraction in object detection models.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes C3 module with TransformerBlock for enhanced feature extraction, accepts channel sizes, shortcut\n        config, group, and expansion.\n        \"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)\n        self.m = TransformerBlock(c_, c_, 4, n)\nclass C3SPP(C3):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "C3SPP",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class C3SPP(C3):\n    \"\"\"Extends the C3 module with an SPP layer for enhanced spatial feature extraction and customizable channels.\"\"\"\n    def __init__(self, c1, c2, k=(5, 9, 13), n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes a C3 module with SPP layer for advanced spatial feature extraction, given channel sizes, kernel\n        sizes, shortcut, group, and expansion ratio.\n        \"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)\n        self.m = SPP(c_, c_, k)\nclass C3Ghost(C3):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "C3Ghost",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class C3Ghost(C3):\n    \"\"\"Implements a C3 module with Ghost Bottlenecks for efficient feature extraction in YOLOv5.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes YOLOv5's C3 module with Ghost Bottlenecks for efficient feature extraction.\"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*(GhostBottleneck(c_, c_) for _ in range(n)))\nclass SPP(nn.Module):\n    \"\"\"Implements Spatial Pyramid Pooling (SPP) for feature extraction, ref: https://arxiv.org/abs/1406.4729.\"\"\"\n    def __init__(self, c1, c2, k=(5, 9, 13)):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "SPP",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class SPP(nn.Module):\n    \"\"\"Implements Spatial Pyramid Pooling (SPP) for feature extraction, ref: https://arxiv.org/abs/1406.4729.\"\"\"\n    def __init__(self, c1, c2, k=(5, 9, 13)):\n        \"\"\"Initializes SPP layer with Spatial Pyramid Pooling, ref: https://arxiv.org/abs/1406.4729, args: c1 (input channels), c2 (output channels), k (kernel sizes).\"\"\"\n        super().__init__()\n        c_ = c1 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)\n        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])\n    def forward(self, x):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "SPPF",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class SPPF(nn.Module):\n    \"\"\"Implements a fast Spatial Pyramid Pooling (SPPF) layer for efficient feature extraction in YOLOv5 models.\"\"\"\n    def __init__(self, c1, c2, k=5):\n        \"\"\"\n        Initializes YOLOv5 SPPF layer with given channels and kernel size for YOLOv5 model, combining convolution and\n        max pooling.\n        Equivalent to SPP(k=(5, 9, 13)).\n        \"\"\"\n        super().__init__()\n        c_ = c1 // 2  # hidden channels",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "Focus",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class Focus(nn.Module):\n    \"\"\"Focuses spatial information into channel space using slicing and convolution for efficient feature extraction.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):\n        \"\"\"Initializes Focus module to concentrate width-height info into channel space with configurable convolution\n        parameters.\n        \"\"\"\n        super().__init__()\n        self.conv = Conv(c1 * 4, c2, k, s, p, g, act=act)\n        # self.contract = Contract(gain=2)\n    def forward(self, x):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "GhostConv",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class GhostConv(nn.Module):\n    \"\"\"Implements Ghost Convolution for efficient feature extraction, see https://github.com/huawei-noah/ghostnet.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):\n        \"\"\"Initializes GhostConv with in/out channels, kernel size, stride, groups, and activation; halves out channels\n        for efficiency.\n        \"\"\"\n        super().__init__()\n        c_ = c2 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, k, s, None, g, act=act)\n        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act=act)",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "GhostBottleneck",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class GhostBottleneck(nn.Module):\n    \"\"\"Efficient bottleneck layer using Ghost Convolutions, see https://github.com/huawei-noah/ghostnet.\"\"\"\n    def __init__(self, c1, c2, k=3, s=1):\n        \"\"\"Initializes GhostBottleneck with ch_in `c1`, ch_out `c2`, kernel size `k`, stride `s`; see https://github.com/huawei-noah/ghostnet.\"\"\"\n        super().__init__()\n        c_ = c2 // 2\n        self.conv = nn.Sequential(\n            GhostConv(c1, c_, 1, 1),  # pw\n            DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw\n            GhostConv(c_, c2, 1, 1, act=False),",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "Contract",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class Contract(nn.Module):\n    \"\"\"Contracts spatial dimensions into channel dimensions for efficient processing in neural networks.\"\"\"\n    def __init__(self, gain=2):\n        \"\"\"Initializes a layer to contract spatial dimensions (width-height) into channels, e.g., input shape\n        (1,64,80,80) to (1,256,40,40).\n        \"\"\"\n        super().__init__()\n        self.gain = gain\n    def forward(self, x):\n        \"\"\"Processes input tensor to expand channel dimensions by contracting spatial dimensions, yielding output shape",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "Expand",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class Expand(nn.Module):\n    \"\"\"Expands spatial dimensions by redistributing channels, e.g., from (1,64,80,80) to (1,16,160,160).\"\"\"\n    def __init__(self, gain=2):\n        \"\"\"\n        Initializes the Expand module to increase spatial dimensions by redistributing channels, with an optional gain\n        factor.\n        Example: x(1,64,80,80) to x(1,16,160,160).\n        \"\"\"\n        super().__init__()\n        self.gain = gain",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "Concat",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class Concat(nn.Module):\n    \"\"\"Concatenates tensors along a specified dimension for efficient tensor manipulation in neural networks.\"\"\"\n    def __init__(self, dimension=1):\n        \"\"\"Initializes a Concat module to concatenate tensors along a specified dimension.\"\"\"\n        super().__init__()\n        self.d = dimension\n    def forward(self, x):\n        \"\"\"Concatenates a list of tensors along a specified dimension; `x` is a list of tensors, `dimension` is an\n        int.\n        \"\"\"",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "DetectMultiBackend",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class DetectMultiBackend(nn.Module):\n    \"\"\"YOLOv5 MultiBackend class for inference on various backends including PyTorch, ONNX, TensorRT, and more.\"\"\"\n    def __init__(self, weights=\"yolov5s.pt\", device=torch.device(\"cpu\"), dnn=False, data=None, fp16=False, fuse=True):\n        \"\"\"Initializes DetectMultiBackend with support for various inference backends, including PyTorch and ONNX.\"\"\"\n        #   PyTorch:              weights = *.pt\n        #   TorchScript:                    *.torchscript\n        #   ONNX Runtime:                   *.onnx\n        #   ONNX OpenCV DNN:                *.onnx --dnn\n        #   OpenVINO:                       *_openvino_model\n        #   CoreML:                         *.mlpackage",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "AutoShape",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class AutoShape(nn.Module):\n    \"\"\"AutoShape class for robust YOLOv5 inference with preprocessing, NMS, and support for various input formats.\"\"\"\n    conf = 0.25  # NMS confidence threshold\n    iou = 0.45  # NMS IoU threshold\n    agnostic = False  # NMS class-agnostic\n    multi_label = False  # NMS multiple labels per box\n    classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n    max_det = 1000  # maximum number of detections per image\n    amp = False  # Automatic Mixed Precision (AMP) inference\n    def __init__(self, model, verbose=True):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "Detections",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class Detections:\n    \"\"\"Manages YOLOv5 detection results with methods for visualization, saving, cropping, and exporting detections.\"\"\"\n    def __init__(self, ims, pred, files, times=(0, 0, 0), names=None, shape=None):\n        \"\"\"Initializes the YOLOv5 Detections class with image info, predictions, filenames, timing and normalization.\"\"\"\n        super().__init__()\n        d = pred[0].device  # device\n        gn = [torch.tensor([*(im.shape[i] for i in [1, 0, 1, 0]), 1, 1], device=d) for im in ims]  # normalizations\n        self.ims = ims  # list of images as numpy arrays\n        self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)\n        self.names = names  # class names",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "Proto",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class Proto(nn.Module):\n    \"\"\"YOLOv5 mask Proto module for segmentation models, performing convolutions and upsampling on input tensors.\"\"\"\n    def __init__(self, c1, c_=256, c2=32):\n        \"\"\"Initializes YOLOv5 Proto module for segmentation with input, proto, and mask channels configuration.\"\"\"\n        super().__init__()\n        self.cv1 = Conv(c1, c_, k=3)\n        self.upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n        self.cv2 = Conv(c_, c_, k=3)\n        self.cv3 = Conv(c_, c2)\n    def forward(self, x):",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "Classify",
        "kind": 6,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "class Classify(nn.Module):\n    \"\"\"YOLOv5 classification head with convolution, pooling, and dropout layers for channel transformation.\"\"\"\n    def __init__(\n        self, c1, c2, k=1, s=1, p=None, g=1, dropout_p=0.0\n    ):  # ch_in, ch_out, kernel, stride, padding, groups, dropout probability\n        \"\"\"Initializes YOLOv5 classification head with convolution, pooling, and dropout layers for input to output\n        channel transformation.\n        \"\"\"\n        super().__init__()\n        c_ = 1280  # efficientnet_b0 size",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "autopad",
        "kind": 2,
        "importPath": "yolov5.models.common",
        "description": "yolov5.models.common",
        "peekOfCode": "def autopad(k, p=None, d=1):\n    \"\"\"\n    Pads kernel to 'same' output shape, adjusting for optional dilation; returns padding size.\n    `k`: kernel, `p`: padding, `d`: dilation.\n    \"\"\"\n    if d > 1:\n        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size\n    if p is None:\n        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n    return p",
        "detail": "yolov5.models.common",
        "documentation": {}
    },
    {
        "label": "Sum",
        "kind": 6,
        "importPath": "yolov5.models.experimental",
        "description": "yolov5.models.experimental",
        "peekOfCode": "class Sum(nn.Module):\n    \"\"\"Weighted sum of 2 or more layers https://arxiv.org/abs/1911.09070.\"\"\"\n    def __init__(self, n, weight=False):\n        \"\"\"Initializes a module to sum outputs of layers with number of inputs `n` and optional weighting, supporting 2+\n        inputs.\n        \"\"\"\n        super().__init__()\n        self.weight = weight  # apply weights boolean\n        self.iter = range(n - 1)  # iter object\n        if weight:",
        "detail": "yolov5.models.experimental",
        "documentation": {}
    },
    {
        "label": "MixConv2d",
        "kind": 6,
        "importPath": "yolov5.models.experimental",
        "description": "yolov5.models.experimental",
        "peekOfCode": "class MixConv2d(nn.Module):\n    \"\"\"Mixed Depth-wise Conv https://arxiv.org/abs/1907.09595.\"\"\"\n    def __init__(self, c1, c2, k=(1, 3), s=1, equal_ch=True):\n        \"\"\"Initializes MixConv2d with mixed depth-wise convolutional layers, taking input and output channels (c1, c2),\n        kernel sizes (k), stride (s), and channel distribution strategy (equal_ch).\n        \"\"\"\n        super().__init__()\n        n = len(k)  # number of convolutions\n        if equal_ch:  # equal c_ per group\n            i = torch.linspace(0, n - 1e-6, c2).floor()  # c2 indices",
        "detail": "yolov5.models.experimental",
        "documentation": {}
    },
    {
        "label": "Ensemble",
        "kind": 6,
        "importPath": "yolov5.models.experimental",
        "description": "yolov5.models.experimental",
        "peekOfCode": "class Ensemble(nn.ModuleList):\n    \"\"\"Ensemble of models.\"\"\"\n    def __init__(self):\n        \"\"\"Initializes an ensemble of models to be used for aggregated predictions.\"\"\"\n        super().__init__()\n    def forward(self, x, augment=False, profile=False, visualize=False):\n        \"\"\"Performs forward pass aggregating outputs from an ensemble of models..\"\"\"\n        y = [module(x, augment, profile, visualize)[0] for module in self]\n        # y = torch.stack(y).max(0)[0]  # max ensemble\n        # y = torch.stack(y).mean(0)  # mean ensemble",
        "detail": "yolov5.models.experimental",
        "documentation": {}
    },
    {
        "label": "attempt_load",
        "kind": 2,
        "importPath": "yolov5.models.experimental",
        "description": "yolov5.models.experimental",
        "peekOfCode": "def attempt_load(weights, device=None, inplace=True, fuse=True):\n    \"\"\"\n    Loads and fuses an ensemble or single YOLOv5 model from weights, handling device placement and model adjustments.\n    Example inputs: weights=[a,b,c] or a single model weights=[a] or weights=a.\n    \"\"\"\n    from models.yolo import Detect, Model\n    model = Ensemble()\n    for w in weights if isinstance(weights, list) else [weights]:\n        ckpt = torch.load(attempt_download(w), map_location=\"cpu\")  # load\n        ckpt = (ckpt.get(\"ema\") or ckpt[\"model\"]).to(device).float()  # FP32 model",
        "detail": "yolov5.models.experimental",
        "documentation": {}
    },
    {
        "label": "TFBN",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFBN(keras.layers.Layer):\n    \"\"\"TensorFlow BatchNormalization wrapper for initializing with optional pretrained weights.\"\"\"\n    def __init__(self, w=None):\n        \"\"\"Initializes a TensorFlow BatchNormalization layer with optional pretrained weights.\"\"\"\n        super().__init__()\n        self.bn = keras.layers.BatchNormalization(\n            beta_initializer=keras.initializers.Constant(w.bias.numpy()),\n            gamma_initializer=keras.initializers.Constant(w.weight.numpy()),\n            moving_mean_initializer=keras.initializers.Constant(w.running_mean.numpy()),\n            moving_variance_initializer=keras.initializers.Constant(w.running_var.numpy()),",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFPad",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFPad(keras.layers.Layer):\n    \"\"\"Pads input tensors in spatial dimensions 1 and 2 with specified integer or tuple padding values.\"\"\"\n    def __init__(self, pad):\n        \"\"\"\n        Initializes a padding layer for spatial dimensions 1 and 2 with specified padding, supporting both int and tuple\n        inputs.\n        Inputs are\n        \"\"\"\n        super().__init__()\n        if isinstance(pad, int):",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFConv",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFConv(keras.layers.Layer):\n    \"\"\"Implements a standard convolutional layer with optional batch normalization and activation for TensorFlow.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True, w=None):\n        \"\"\"\n        Initializes a standard convolution layer with optional batch normalization and activation; supports only\n        group=1.\n        Inputs are ch_in, ch_out, weights, kernel, stride, padding, groups.\n        \"\"\"\n        super().__init__()\n        assert g == 1, \"TF v2.2 Conv2D does not support 'groups' argument\"",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFDWConv",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFDWConv(keras.layers.Layer):\n    \"\"\"Initializes a depthwise convolution layer with optional batch normalization and activation for TensorFlow.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p=None, act=True, w=None):\n        \"\"\"\n        Initializes a depthwise convolution layer with optional batch normalization and activation for TensorFlow\n        models.\n        Input are ch_in, ch_out, weights, kernel, stride, padding, groups.\n        \"\"\"\n        super().__init__()\n        assert c2 % c1 == 0, f\"TFDWConv() output={c2} must be a multiple of input={c1} channels\"",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFDWConvTranspose2d",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFDWConvTranspose2d(keras.layers.Layer):\n    \"\"\"Implements a depthwise ConvTranspose2D layer for TensorFlow with specific settings.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0, w=None):\n        \"\"\"\n        Initializes depthwise ConvTranspose2D layer with specific channel, kernel, stride, and padding settings.\n        Inputs are ch_in, ch_out, weights, kernel, stride, padding, groups.\n        \"\"\"\n        super().__init__()\n        assert c1 == c2, f\"TFDWConv() output={c2} must be equal to input={c1} channels\"\n        assert k == 4 and p1 == 1, \"TFDWConv() only valid for k=4 and p1=1\"",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFFocus",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFFocus(keras.layers.Layer):\n    \"\"\"Focuses spatial information into channel space using pixel shuffling and convolution for TensorFlow models.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True, w=None):\n        \"\"\"\n        Initializes TFFocus layer to focus width and height information into channel space with custom convolution\n        parameters.\n        Inputs are ch_in, ch_out, kernel, stride, padding, groups.\n        \"\"\"\n        super().__init__()\n        self.conv = TFConv(c1 * 4, c2, k, s, p, g, act, w.conv)",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFBottleneck",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFBottleneck(keras.layers.Layer):\n    \"\"\"Implements a TensorFlow bottleneck layer with optional shortcut connections for efficient feature extraction.\"\"\"\n    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5, w=None):\n        \"\"\"\n        Initializes a standard bottleneck layer for TensorFlow models, expanding and contracting channels with optional\n        shortcut.\n        Arguments are ch_in, ch_out, shortcut, groups, expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFCrossConv",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFCrossConv(keras.layers.Layer):\n    \"\"\"Implements a cross convolutional layer with optional expansion, grouping, and shortcut for TensorFlow.\"\"\"\n    def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False, w=None):\n        \"\"\"Initializes cross convolution layer with optional expansion, grouping, and shortcut addition capabilities.\"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = TFConv(c1, c_, (1, k), (1, s), w=w.cv1)\n        self.cv2 = TFConv(c_, c2, (k, 1), (s, 1), g=g, w=w.cv2)\n        self.add = shortcut and c1 == c2\n    def call(self, inputs):",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFConv2d",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFConv2d(keras.layers.Layer):\n    \"\"\"Implements a TensorFlow 2D convolution layer, mimicking PyTorch's nn.Conv2D for specified filters and stride.\"\"\"\n    def __init__(self, c1, c2, k, s=1, g=1, bias=True, w=None):\n        \"\"\"Initializes a TensorFlow 2D convolution layer, mimicking PyTorch's nn.Conv2D functionality for given filter\n        sizes and stride.\n        \"\"\"\n        super().__init__()\n        assert g == 1, \"TF v2.2 Conv2D does not support 'groups' argument\"\n        self.conv = keras.layers.Conv2D(\n            filters=c2,",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFBottleneckCSP",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFBottleneckCSP(keras.layers.Layer):\n    \"\"\"Implements a CSP bottleneck layer for TensorFlow models to enhance gradient flow and efficiency.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, w=None):\n        \"\"\"\n        Initializes CSP bottleneck layer with specified channel sizes, count, shortcut option, groups, and expansion\n        ratio.\n        Inputs are ch_in, ch_out, number, shortcut, groups, expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFC3",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFC3(keras.layers.Layer):\n    \"\"\"CSP bottleneck layer with 3 convolutions for TensorFlow, supporting optional shortcuts and group convolutions.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, w=None):\n        \"\"\"\n        Initializes CSP Bottleneck with 3 convolutions, supporting optional shortcuts and group convolutions.\n        Inputs are ch_in, ch_out, number, shortcut, groups, expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFC3x",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFC3x(keras.layers.Layer):\n    \"\"\"A TensorFlow layer for enhanced feature extraction using cross-convolutions in object detection models.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, w=None):\n        \"\"\"\n        Initializes layer with cross-convolutions for enhanced feature extraction in object detection models.\n        Inputs are ch_in, ch_out, number, shortcut, groups, expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFSPP",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFSPP(keras.layers.Layer):\n    \"\"\"Implements spatial pyramid pooling for YOLOv3-SPP with specific channels and kernel sizes.\"\"\"\n    def __init__(self, c1, c2, k=(5, 9, 13), w=None):\n        \"\"\"Initializes a YOLOv3-SPP layer with specific input/output channels and kernel sizes for pooling.\"\"\"\n        super().__init__()\n        c_ = c1 // 2  # hidden channels\n        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)\n        self.cv2 = TFConv(c_ * (len(k) + 1), c2, 1, 1, w=w.cv2)\n        self.m = [keras.layers.MaxPool2D(pool_size=x, strides=1, padding=\"SAME\") for x in k]\n    def call(self, inputs):",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFSPPF",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFSPPF(keras.layers.Layer):\n    \"\"\"Implements a fast spatial pyramid pooling layer for TensorFlow with optimized feature extraction.\"\"\"\n    def __init__(self, c1, c2, k=5, w=None):\n        \"\"\"Initializes a fast spatial pyramid pooling layer with customizable in/out channels, kernel size, and\n        weights.\n        \"\"\"\n        super().__init__()\n        c_ = c1 // 2  # hidden channels\n        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)\n        self.cv2 = TFConv(c_ * 4, c2, 1, 1, w=w.cv2)",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFDetect",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFDetect(keras.layers.Layer):\n    \"\"\"Implements YOLOv5 object detection layer in TensorFlow for predicting bounding boxes and class probabilities.\"\"\"\n    def __init__(self, nc=80, anchors=(), ch=(), imgsz=(640, 640), w=None):\n        \"\"\"Initializes YOLOv5 detection layer for TensorFlow with configurable classes, anchors, channels, and image\n        size.\n        \"\"\"\n        super().__init__()\n        self.stride = tf.convert_to_tensor(w.stride.numpy(), dtype=tf.float32)\n        self.nc = nc  # number of classes\n        self.no = nc + 5  # number of outputs per anchor",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFSegment",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFSegment(TFDetect):\n    \"\"\"YOLOv5 segmentation head for TensorFlow, combining detection and segmentation.\"\"\"\n    def __init__(self, nc=80, anchors=(), nm=32, npr=256, ch=(), imgsz=(640, 640), w=None):\n        \"\"\"Initializes YOLOv5 Segment head with specified channel depths, anchors, and input size for segmentation\n        models.\n        \"\"\"\n        super().__init__(nc, anchors, ch, imgsz, w)\n        self.nm = nm  # number of masks\n        self.npr = npr  # number of protos\n        self.no = 5 + nc + self.nm  # number of outputs per anchor",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFProto",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFProto(keras.layers.Layer):\n    \"\"\"Implements convolutional and upsampling layers for feature extraction in YOLOv5 segmentation.\"\"\"\n    def __init__(self, c1, c_=256, c2=32, w=None):\n        \"\"\"Initializes TFProto layer with convolutional and upsampling layers for feature extraction and\n        transformation.\n        \"\"\"\n        super().__init__()\n        self.cv1 = TFConv(c1, c_, k=3, w=w.cv1)\n        self.upsample = TFUpsample(None, scale_factor=2, mode=\"nearest\")\n        self.cv2 = TFConv(c_, c_, k=3, w=w.cv2)",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFUpsample",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFUpsample(keras.layers.Layer):\n    \"\"\"Implements a TensorFlow upsampling layer with specified size, scale factor, and interpolation mode.\"\"\"\n    def __init__(self, size, scale_factor, mode, w=None):\n        \"\"\"\n        Initializes a TensorFlow upsampling layer with specified size, scale_factor, and mode, ensuring scale_factor is\n        even.\n        Warning: all arguments needed including 'w'\n        \"\"\"\n        super().__init__()\n        assert scale_factor % 2 == 0, \"scale_factor must be multiple of 2\"",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFConcat",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFConcat(keras.layers.Layer):\n    \"\"\"Implements TensorFlow's version of torch.concat() for concatenating tensors along the last dimension.\"\"\"\n    def __init__(self, dimension=1, w=None):\n        \"\"\"Initializes a TensorFlow layer for NCHW to NHWC concatenation, requiring dimension=1.\"\"\"\n        super().__init__()\n        assert dimension == 1, \"convert only NCHW to NHWC concat\"\n        self.d = 3\n    def call(self, inputs):\n        \"\"\"Concatenates a list of tensors along the last dimension, used for NCHW to NHWC conversion.\"\"\"\n        return tf.concat(inputs, self.d)",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "TFModel",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class TFModel:\n    \"\"\"Implements YOLOv5 model in TensorFlow, supporting TensorFlow, Keras, and TFLite formats for object detection.\"\"\"\n    def __init__(self, cfg=\"yolov5s.yaml\", ch=3, nc=None, model=None, imgsz=(640, 640)):\n        \"\"\"Initializes TF YOLOv5 model with specified configuration, channels, classes, model instance, and input\n        size.\n        \"\"\"\n        super().__init__()\n        if isinstance(cfg, dict):\n            self.yaml = cfg  # model dict\n        else:  # is *.yaml",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "AgnosticNMS",
        "kind": 6,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "class AgnosticNMS(keras.layers.Layer):\n    \"\"\"Performs agnostic non-maximum suppression (NMS) on detected objects using IoU and confidence thresholds.\"\"\"\n    def call(self, input, topk_all, iou_thres, conf_thres):\n        \"\"\"Performs agnostic NMS on input tensors using given thresholds and top-K selection.\"\"\"\n        return tf.map_fn(\n            lambda x: self._nms(x, topk_all, iou_thres, conf_thres),\n            input,\n            fn_output_signature=(tf.float32, tf.float32, tf.float32, tf.int32),\n            name=\"agnostic_nms\",\n        )",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "parse_model",
        "kind": 2,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "def parse_model(d, ch, model, imgsz):\n    \"\"\"Parses a model definition dict `d` to create YOLOv5 model layers, including dynamic channel adjustments.\"\"\"\n    LOGGER.info(f\"\\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}\")\n    anchors, nc, gd, gw, ch_mul = (\n        d[\"anchors\"],\n        d[\"nc\"],\n        d[\"depth_multiple\"],\n        d[\"width_multiple\"],\n        d.get(\"channel_multiple\"),\n    )",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "activations",
        "kind": 2,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "def activations(act=nn.SiLU):\n    \"\"\"Converts PyTorch activations to TensorFlow equivalents, supporting LeakyReLU, Hardswish, and SiLU/Swish.\"\"\"\n    if isinstance(act, nn.LeakyReLU):\n        return lambda x: keras.activations.relu(x, alpha=0.1)\n    elif isinstance(act, nn.Hardswish):\n        return lambda x: x * tf.nn.relu6(x + 3) * 0.166666667\n    elif isinstance(act, (nn.SiLU, SiLU)):\n        return lambda x: keras.activations.swish(x)\n    else:\n        raise Exception(f\"no matching TensorFlow activation found for PyTorch activation {act}\")",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "representative_dataset_gen",
        "kind": 2,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "def representative_dataset_gen(dataset, ncalib=100):\n    \"\"\"Generates a representative dataset for calibration by yielding transformed numpy arrays from the input\n    dataset.\n    \"\"\"\n    for n, (path, img, im0s, vid_cap, string) in enumerate(dataset):\n        im = np.transpose(img, [1, 2, 0])\n        im = np.expand_dims(im, axis=0).astype(np.float32)\n        im /= 255\n        yield [im]\n        if n >= ncalib:",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "def run(\n    weights=ROOT / \"yolov5s.pt\",  # weights path\n    imgsz=(640, 640),  # inference size h,w\n    batch_size=1,  # batch size\n    dynamic=False,  # dynamic batch size\n):\n    # PyTorch model\n    \"\"\"Exports YOLOv5 model from PyTorch to TensorFlow and Keras formats, performing inference for validation.\"\"\"\n    im = torch.zeros((batch_size, 3, *imgsz))  # BCHW image\n    model = attempt_load(weights, device=torch.device(\"cpu\"), inplace=True, fuse=False)",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "def parse_opt():\n    \"\"\"Parses and returns command-line options for model inference, including weights path, image size, batch size, and\n    dynamic batching.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", type=str, default=ROOT / \"yolov5s.pt\", help=\"weights path\")\n    parser.add_argument(\"--imgsz\", \"--img\", \"--img-size\", nargs=\"+\", type=int, default=[640], help=\"inference size h,w\")\n    parser.add_argument(\"--batch-size\", type=int, default=1, help=\"batch size\")\n    parser.add_argument(\"--dynamic\", action=\"store_true\", help=\"dynamic batch size\")\n    opt = parser.parse_args()",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "def main(opt):\n    \"\"\"Executes the YOLOv5 model run function with parsed command line options.\"\"\"\n    run(**vars(opt))\nif __name__ == \"__main__\":\n    opt = parse_opt()\n    main(opt)",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\n# ROOT = ROOT.relative_to(Path.cwd())  # relative\nimport numpy as np\nimport tensorflow as tf\nimport torch\nimport torch.nn as nn\nfrom tensorflow import keras",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.models.tf",
        "description": "yolov5.models.tf",
        "peekOfCode": "ROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\n# ROOT = ROOT.relative_to(Path.cwd())  # relative\nimport numpy as np\nimport tensorflow as tf\nimport torch\nimport torch.nn as nn\nfrom tensorflow import keras\nfrom models.common import (",
        "detail": "yolov5.models.tf",
        "documentation": {}
    },
    {
        "label": "Detect",
        "kind": 6,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "class Detect(nn.Module):\n    \"\"\"YOLOv5 Detect head for processing input tensors and generating detection outputs in object detection models.\"\"\"\n    stride = None  # strides computed during build\n    dynamic = False  # force grid reconstruction\n    export = False  # export mode\n    def __init__(self, nc=80, anchors=(), ch=(), inplace=True):\n        \"\"\"Initializes YOLOv5 detection layer with specified classes, anchors, channels, and inplace operations.\"\"\"\n        super().__init__()\n        self.nc = nc  # number of classes\n        self.no = nc + 5  # number of outputs per anchor",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "Segment",
        "kind": 6,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "class Segment(Detect):\n    \"\"\"YOLOv5 Segment head for segmentation models, extending Detect with mask and prototype layers.\"\"\"\n    def __init__(self, nc=80, anchors=(), nm=32, npr=256, ch=(), inplace=True):\n        \"\"\"Initializes YOLOv5 Segment head with options for mask count, protos, and channel adjustments.\"\"\"\n        super().__init__(nc, anchors, ch, inplace)\n        self.nm = nm  # number of masks\n        self.npr = npr  # number of protos\n        self.no = 5 + nc + self.nm  # number of outputs per anchor\n        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv\n        self.proto = Proto(ch[0], self.npr, self.nm)  # protos",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "kind": 6,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "class BaseModel(nn.Module):\n    \"\"\"YOLOv5 base model.\"\"\"\n    def forward(self, x, profile=False, visualize=False):\n        \"\"\"Executes a single-scale inference or training pass on the YOLOv5 base model, with options for profiling and\n        visualization.\n        \"\"\"\n        return self._forward_once(x, profile, visualize)  # single-scale inference, train\n    def _forward_once(self, x, profile=False, visualize=False):\n        \"\"\"Performs a forward pass on the YOLOv5 model, enabling profiling and feature visualization options.\"\"\"\n        y, dt = [], []  # outputs",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "kind": 6,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "class DetectionModel(BaseModel):\n    \"\"\"YOLOv5 detection model class for object detection tasks, supporting custom configurations and anchors.\"\"\"\n    def __init__(self, cfg=\"yolov5s.yaml\", ch=3, nc=None, anchors=None):\n        \"\"\"Initializes YOLOv5 model with configuration file, input channels, number of classes, and custom anchors.\"\"\"\n        super().__init__()\n        if isinstance(cfg, dict):\n            self.yaml = cfg  # model dict\n        else:  # is *.yaml\n            import yaml  # for torch hub\n            self.yaml_file = Path(cfg).name",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "kind": 6,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "class SegmentationModel(DetectionModel):\n    \"\"\"YOLOv5 segmentation model for object detection and segmentation tasks with configurable parameters.\"\"\"\n    def __init__(self, cfg=\"yolov5s-seg.yaml\", ch=3, nc=None, anchors=None):\n        \"\"\"Initializes a YOLOv5 segmentation model with configurable params: cfg (str) for configuration, ch (int) for channels, nc (int) for num classes, anchors (list).\"\"\"\n        super().__init__(cfg, ch, nc, anchors)\nclass ClassificationModel(BaseModel):\n    \"\"\"YOLOv5 classification model for image classification tasks, initialized with a config file or detection model.\"\"\"\n    def __init__(self, cfg=None, model=None, nc=1000, cutoff=10):\n        \"\"\"Initializes YOLOv5 model with config file `cfg`, input channels `ch`, number of classes `nc`, and `cuttoff`\n        index.",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "ClassificationModel",
        "kind": 6,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "class ClassificationModel(BaseModel):\n    \"\"\"YOLOv5 classification model for image classification tasks, initialized with a config file or detection model.\"\"\"\n    def __init__(self, cfg=None, model=None, nc=1000, cutoff=10):\n        \"\"\"Initializes YOLOv5 model with config file `cfg`, input channels `ch`, number of classes `nc`, and `cuttoff`\n        index.\n        \"\"\"\n        super().__init__()\n        self._from_detection_model(model, nc, cutoff) if model is not None else self._from_yaml(cfg)\n    def _from_detection_model(self, model, nc=1000, cutoff=10):\n        \"\"\"Creates a classification model from a YOLOv5 detection model, slicing at `cutoff` and adding a classification",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "parse_model",
        "kind": 2,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "def parse_model(d, ch):\n    \"\"\"Parses a YOLOv5 model from a dict `d`, configuring layers based on input channels `ch` and model architecture.\"\"\"\n    LOGGER.info(f\"\\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}\")\n    anchors, nc, gd, gw, act, ch_mul = (\n        d[\"anchors\"],\n        d[\"nc\"],\n        d[\"depth_multiple\"],\n        d[\"width_multiple\"],\n        d.get(\"activation\"),\n        d.get(\"channel_multiple\"),",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nif platform.system() != \"Windows\":\n    ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.common import (\n    C3,\n    C3SPP,\n    C3TR,",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "ROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nif platform.system() != \"Windows\":\n    ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.common import (\n    C3,\n    C3SPP,\n    C3TR,\n    SPP,",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "Model",
        "kind": 5,
        "importPath": "yolov5.models.yolo",
        "description": "yolov5.models.yolo",
        "peekOfCode": "Model = DetectionModel  # retain YOLOv5 'Model' class for backwards compatibility\nclass SegmentationModel(DetectionModel):\n    \"\"\"YOLOv5 segmentation model for object detection and segmentation tasks with configurable parameters.\"\"\"\n    def __init__(self, cfg=\"yolov5s-seg.yaml\", ch=3, nc=None, anchors=None):\n        \"\"\"Initializes a YOLOv5 segmentation model with configurable params: cfg (str) for configuration, ch (int) for channels, nc (int) for num classes, anchors (list).\"\"\"\n        super().__init__(cfg, ch, nc, anchors)\nclass ClassificationModel(BaseModel):\n    \"\"\"YOLOv5 classification model for image classification tasks, initialized with a config file or detection model.\"\"\"\n    def __init__(self, cfg=None, model=None, nc=1000, cutoff=10):\n        \"\"\"Initializes YOLOv5 model with config file `cfg`, input channels `ch`, number of classes `nc`, and `cuttoff`",
        "detail": "yolov5.models.yolo",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.segment.predict",
        "description": "yolov5.segment.predict",
        "peekOfCode": "def run(\n    weights=ROOT / \"yolov5s-seg.pt\",  # model.pt path(s)\n    source=ROOT / \"data/images\",  # file/dir/URL/glob/screen/0(webcam)\n    data=ROOT / \"data/coco128.yaml\",  # dataset.yaml path\n    imgsz=(640, 640),  # inference size (height, width)\n    conf_thres=0.25,  # confidence threshold\n    iou_thres=0.45,  # NMS IOU threshold\n    max_det=1000,  # maximum detections per image\n    device=\"\",  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n    view_img=False,  # show results",
        "detail": "yolov5.segment.predict",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.segment.predict",
        "description": "yolov5.segment.predict",
        "peekOfCode": "def parse_opt():\n    \"\"\"Parses command-line options for YOLOv5 inference including model paths, data sources, inference settings, and\n    output preferences.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", nargs=\"+\", type=str, default=ROOT / \"yolov5s-seg.pt\", help=\"model path(s)\")\n    parser.add_argument(\"--source\", type=str, default=ROOT / \"data/images\", help=\"file/dir/URL/glob/screen/0(webcam)\")\n    parser.add_argument(\"--data\", type=str, default=ROOT / \"data/coco128.yaml\", help=\"(optional) dataset.yaml path\")\n    parser.add_argument(\"--imgsz\", \"--img\", \"--img-size\", nargs=\"+\", type=int, default=[640], help=\"inference size h,w\")\n    parser.add_argument(\"--conf-thres\", type=float, default=0.25, help=\"confidence threshold\")",
        "detail": "yolov5.segment.predict",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.segment.predict",
        "description": "yolov5.segment.predict",
        "peekOfCode": "def main(opt):\n    \"\"\"Executes YOLOv5 model inference with given options, checking for requirements before launching.\"\"\"\n    check_requirements(ROOT / \"requirements.txt\", exclude=(\"tensorboard\", \"thop\"))\n    run(**vars(opt))\nif __name__ == \"__main__\":\n    opt = parse_opt()\n    main(opt)",
        "detail": "yolov5.segment.predict",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.segment.predict",
        "description": "yolov5.segment.predict",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom ultralytics.utils.plotting import Annotator, colors, save_one_box\nfrom models.common import DetectMultiBackend\nfrom utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\nfrom utils.general import (\n    LOGGER,",
        "detail": "yolov5.segment.predict",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.segment.predict",
        "description": "yolov5.segment.predict",
        "peekOfCode": "ROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom ultralytics.utils.plotting import Annotator, colors, save_one_box\nfrom models.common import DetectMultiBackend\nfrom utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\nfrom utils.general import (\n    LOGGER,\n    Profile,",
        "detail": "yolov5.segment.predict",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.segment.predict",
        "description": "yolov5.segment.predict",
        "peekOfCode": "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom ultralytics.utils.plotting import Annotator, colors, save_one_box\nfrom models.common import DetectMultiBackend\nfrom utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\nfrom utils.general import (\n    LOGGER,\n    Profile,\n    check_file,\n    check_img_size,\n    check_imshow,",
        "detail": "yolov5.segment.predict",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "def train(hyp, opt, device, callbacks):\n    \"\"\"\n    Trains the YOLOv5 model on a dataset, managing hyperparameters, model optimization, logging, and validation.\n    `hyp` is path/to/hyp.yaml or hyp dictionary.\n    \"\"\"\n    (\n        save_dir,\n        epochs,\n        batch_size,\n        weights,",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "def parse_opt(known=False):\n    \"\"\"\n    Parses command line arguments for training configurations, returning parsed arguments.\n    Supports both known and unknown args.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", type=str, default=ROOT / \"yolov5s-seg.pt\", help=\"initial weights path\")\n    parser.add_argument(\"--cfg\", type=str, default=\"\", help=\"model.yaml path\")\n    parser.add_argument(\"--data\", type=str, default=ROOT / \"data/coco128-seg.yaml\", help=\"dataset.yaml path\")\n    parser.add_argument(\"--hyp\", type=str, default=ROOT / \"data/hyps/hyp.scratch-low.yaml\", help=\"hyperparameters path\")",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "def main(opt, callbacks=Callbacks()):\n    \"\"\"Initializes training or evolution of YOLOv5 models based on provided configuration and options.\"\"\"\n    if RANK in {-1, 0}:\n        print_args(vars(opt))\n        check_git_status()\n        check_requirements(ROOT / \"requirements.txt\")\n    # Resume\n    if opt.resume and not opt.evolve:  # resume from specified or most recent last.pt\n        last = Path(check_file(opt.resume) if isinstance(opt.resume, str) else get_latest_run())\n        opt_yaml = last.parent.parent / \"opt.yaml\"  # train options yaml",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "def run(**kwargs):\n    \"\"\"\n    Executes YOLOv5 training with given parameters, altering options programmatically; returns updated options.\n    Example: import train; train.run(data='coco128.yaml', imgsz=320, weights='yolov5m.pt')\n    \"\"\"\n    opt = parse_opt(True)\n    for k, v in kwargs.items():\n        setattr(opt, k, v)\n    main(opt)\n    return opt",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nimport segment.val as validate  # for end-of-epoch mAP\nfrom models.experimental import attempt_load\nfrom models.yolo import SegmentationModel\nfrom utils.autoanchor import check_anchors\nfrom utils.autobatch import check_train_batch_size",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "ROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nimport segment.val as validate  # for end-of-epoch mAP\nfrom models.experimental import attempt_load\nfrom models.yolo import SegmentationModel\nfrom utils.autoanchor import check_anchors\nfrom utils.autobatch import check_train_batch_size\nfrom utils.callbacks import Callbacks",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nimport segment.val as validate  # for end-of-epoch mAP\nfrom models.experimental import attempt_load\nfrom models.yolo import SegmentationModel\nfrom utils.autoanchor import check_anchors\nfrom utils.autobatch import check_train_batch_size\nfrom utils.callbacks import Callbacks\nfrom utils.downloads import attempt_download, is_url\nfrom utils.general import (\n    LOGGER,",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "kind": 5,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "LOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nGIT_INFO = check_git_info()\ndef train(hyp, opt, device, callbacks):\n    \"\"\"\n    Trains the YOLOv5 model on a dataset, managing hyperparameters, model optimization, logging, and validation.\n    `hyp` is path/to/hyp.yaml or hyp dictionary.\n    \"\"\"\n    (",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "RANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nGIT_INFO = check_git_info()\ndef train(hyp, opt, device, callbacks):\n    \"\"\"\n    Trains the YOLOv5 model on a dataset, managing hyperparameters, model optimization, logging, and validation.\n    `hyp` is path/to/hyp.yaml or hyp dictionary.\n    \"\"\"\n    (\n        save_dir,",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "WORLD_SIZE",
        "kind": 5,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "WORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nGIT_INFO = check_git_info()\ndef train(hyp, opt, device, callbacks):\n    \"\"\"\n    Trains the YOLOv5 model on a dataset, managing hyperparameters, model optimization, logging, and validation.\n    `hyp` is path/to/hyp.yaml or hyp dictionary.\n    \"\"\"\n    (\n        save_dir,\n        epochs,",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "GIT_INFO",
        "kind": 5,
        "importPath": "yolov5.segment.train",
        "description": "yolov5.segment.train",
        "peekOfCode": "GIT_INFO = check_git_info()\ndef train(hyp, opt, device, callbacks):\n    \"\"\"\n    Trains the YOLOv5 model on a dataset, managing hyperparameters, model optimization, logging, and validation.\n    `hyp` is path/to/hyp.yaml or hyp dictionary.\n    \"\"\"\n    (\n        save_dir,\n        epochs,\n        batch_size,",
        "detail": "yolov5.segment.train",
        "documentation": {}
    },
    {
        "label": "save_one_txt",
        "kind": 2,
        "importPath": "yolov5.segment.val",
        "description": "yolov5.segment.val",
        "peekOfCode": "def save_one_txt(predn, save_conf, shape, file):\n    \"\"\"Saves detection results in txt format; includes class, xywh (normalized), optionally confidence if `save_conf` is\n    True.\n    \"\"\"\n    gn = torch.tensor(shape)[[1, 0, 1, 0]]  # normalization gain whwh\n    for *xyxy, conf, cls in predn.tolist():\n        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n        with open(file, \"a\") as f:\n            f.write((\"%g \" * len(line)).rstrip() % line + \"\\n\")",
        "detail": "yolov5.segment.val",
        "documentation": {}
    },
    {
        "label": "save_one_json",
        "kind": 2,
        "importPath": "yolov5.segment.val",
        "description": "yolov5.segment.val",
        "peekOfCode": "def save_one_json(predn, jdict, path, class_map, pred_masks):\n    \"\"\"\n    Saves a JSON file with detection results including bounding boxes, category IDs, scores, and segmentation masks.\n    Example JSON result: {\"image_id\": 42, \"category_id\": 18, \"bbox\": [258.15, 41.29, 348.26, 243.78], \"score\": 0.236}.\n    \"\"\"\n    from pycocotools.mask import encode\n    def single_encode(x):\n        \"\"\"Encodes binary mask arrays into RLE (Run-Length Encoding) format for JSON serialization.\"\"\"\n        rle = encode(np.asarray(x[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n        rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")",
        "detail": "yolov5.segment.val",
        "documentation": {}
    },
    {
        "label": "process_batch",
        "kind": 2,
        "importPath": "yolov5.segment.val",
        "description": "yolov5.segment.val",
        "peekOfCode": "def process_batch(detections, labels, iouv, pred_masks=None, gt_masks=None, overlap=False, masks=False):\n    \"\"\"\n    Return correct prediction matrix\n    Arguments:\n        detections (array[N, 6]), x1, y1, x2, y2, conf, class\n        labels (array[M, 5]), class, x1, y1, x2, y2\n    Returns:\n        correct (array[N, 10]), for 10 IoU levels.\n    \"\"\"\n    if masks:",
        "detail": "yolov5.segment.val",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.segment.val",
        "description": "yolov5.segment.val",
        "peekOfCode": "def run(\n    data,\n    weights=None,  # model.pt path(s)\n    batch_size=32,  # batch size\n    imgsz=640,  # inference size (pixels)\n    conf_thres=0.001,  # confidence threshold\n    iou_thres=0.6,  # NMS IoU threshold\n    max_det=300,  # maximum detections per image\n    task=\"val\",  # train, val, test, speed or study\n    device=\"\",  # cuda device, i.e. 0 or 0,1,2,3 or cpu",
        "detail": "yolov5.segment.val",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.segment.val",
        "description": "yolov5.segment.val",
        "peekOfCode": "def parse_opt():\n    \"\"\"Parses command line arguments for configuring YOLOv5 options like dataset path, weights, batch size, and\n    inference settings.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--data\", type=str, default=ROOT / \"data/coco128-seg.yaml\", help=\"dataset.yaml path\")\n    parser.add_argument(\"--weights\", nargs=\"+\", type=str, default=ROOT / \"yolov5s-seg.pt\", help=\"model path(s)\")\n    parser.add_argument(\"--batch-size\", type=int, default=32, help=\"batch size\")\n    parser.add_argument(\"--imgsz\", \"--img\", \"--img-size\", type=int, default=640, help=\"inference size (pixels)\")\n    parser.add_argument(\"--conf-thres\", type=float, default=0.001, help=\"confidence threshold\")",
        "detail": "yolov5.segment.val",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.segment.val",
        "description": "yolov5.segment.val",
        "peekOfCode": "def main(opt):\n    \"\"\"Executes YOLOv5 tasks including training, validation, testing, speed, and study with configurable options.\"\"\"\n    check_requirements(ROOT / \"requirements.txt\", exclude=(\"tensorboard\", \"thop\"))\n    if opt.task in (\"train\", \"val\", \"test\"):  # run normally\n        if opt.conf_thres > 0.001:  # https://github.com/ultralytics/yolov5/issues/1466\n            LOGGER.warning(f\"WARNING  confidence threshold {opt.conf_thres} > 0.001 produces invalid results\")\n        if opt.save_hybrid:\n            LOGGER.warning(\"WARNING  --save-hybrid returns high mAP from hybrid labels, not from predictions alone\")\n        run(**vars(opt))\n    else:",
        "detail": "yolov5.segment.val",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.segment.val",
        "description": "yolov5.segment.val",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nimport torch.nn.functional as F\nfrom models.common import DetectMultiBackend\nfrom models.yolo import SegmentationModel\nfrom utils.callbacks import Callbacks\nfrom utils.general import (",
        "detail": "yolov5.segment.val",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.segment.val",
        "description": "yolov5.segment.val",
        "peekOfCode": "ROOT = FILE.parents[1]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nimport torch.nn.functional as F\nfrom models.common import DetectMultiBackend\nfrom models.yolo import SegmentationModel\nfrom utils.callbacks import Callbacks\nfrom utils.general import (\n    LOGGER,",
        "detail": "yolov5.segment.val",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.segment.val",
        "description": "yolov5.segment.val",
        "peekOfCode": "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nimport torch.nn.functional as F\nfrom models.common import DetectMultiBackend\nfrom models.yolo import SegmentationModel\nfrom utils.callbacks import Callbacks\nfrom utils.general import (\n    LOGGER,\n    NUM_THREADS,\n    TQDM_BAR_FORMAT,\n    Profile,",
        "detail": "yolov5.segment.val",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.utils.aws.resume",
        "description": "yolov5.utils.aws.resume",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[2]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nport = 0  # --master_port\npath = Path(\"\").resolve()\nfor last in path.rglob(\"*/**/last.pt\"):\n    ckpt = torch.load(last)\n    if ckpt[\"optimizer\"] is None:\n        continue",
        "detail": "yolov5.utils.aws.resume",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.utils.aws.resume",
        "description": "yolov5.utils.aws.resume",
        "peekOfCode": "ROOT = FILE.parents[2]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nport = 0  # --master_port\npath = Path(\"\").resolve()\nfor last in path.rglob(\"*/**/last.pt\"):\n    ckpt = torch.load(last)\n    if ckpt[\"optimizer\"] is None:\n        continue\n    # Load opt.yaml",
        "detail": "yolov5.utils.aws.resume",
        "documentation": {}
    },
    {
        "label": "port",
        "kind": 5,
        "importPath": "yolov5.utils.aws.resume",
        "description": "yolov5.utils.aws.resume",
        "peekOfCode": "port = 0  # --master_port\npath = Path(\"\").resolve()\nfor last in path.rglob(\"*/**/last.pt\"):\n    ckpt = torch.load(last)\n    if ckpt[\"optimizer\"] is None:\n        continue\n    # Load opt.yaml\n    with open(last.parent.parent / \"opt.yaml\", errors=\"ignore\") as f:\n        opt = yaml.safe_load(f)\n    # Get device count",
        "detail": "yolov5.utils.aws.resume",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "yolov5.utils.aws.resume",
        "description": "yolov5.utils.aws.resume",
        "peekOfCode": "path = Path(\"\").resolve()\nfor last in path.rglob(\"*/**/last.pt\"):\n    ckpt = torch.load(last)\n    if ckpt[\"optimizer\"] is None:\n        continue\n    # Load opt.yaml\n    with open(last.parent.parent / \"opt.yaml\", errors=\"ignore\") as f:\n        opt = yaml.safe_load(f)\n    # Get device count\n    d = opt[\"device\"].split(\",\")  # devices",
        "detail": "yolov5.utils.aws.resume",
        "documentation": {}
    },
    {
        "label": "DETECTION_URL",
        "kind": 5,
        "importPath": "yolov5.utils.flask_rest_api.example_request",
        "description": "yolov5.utils.flask_rest_api.example_request",
        "peekOfCode": "DETECTION_URL = \"http://localhost:5000/v1/object-detection/yolov5s\"\nIMAGE = \"zidane.jpg\"\n# Read image\nwith open(IMAGE, \"rb\") as f:\n    image_data = f.read()\nresponse = requests.post(DETECTION_URL, files={\"image\": image_data}).json()\npprint.pprint(response)",
        "detail": "yolov5.utils.flask_rest_api.example_request",
        "documentation": {}
    },
    {
        "label": "IMAGE",
        "kind": 5,
        "importPath": "yolov5.utils.flask_rest_api.example_request",
        "description": "yolov5.utils.flask_rest_api.example_request",
        "peekOfCode": "IMAGE = \"zidane.jpg\"\n# Read image\nwith open(IMAGE, \"rb\") as f:\n    image_data = f.read()\nresponse = requests.post(DETECTION_URL, files={\"image\": image_data}).json()\npprint.pprint(response)",
        "detail": "yolov5.utils.flask_rest_api.example_request",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "yolov5.utils.flask_rest_api.example_request",
        "description": "yolov5.utils.flask_rest_api.example_request",
        "peekOfCode": "response = requests.post(DETECTION_URL, files={\"image\": image_data}).json()\npprint.pprint(response)",
        "detail": "yolov5.utils.flask_rest_api.example_request",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "yolov5.utils.flask_rest_api.restapi",
        "description": "yolov5.utils.flask_rest_api.restapi",
        "peekOfCode": "def predict(model):\n    \"\"\"Predict and return object detections in JSON format given an image and model name via a Flask REST API POST\n    request.\n    \"\"\"\n    if request.method != \"POST\":\n        return\n    if request.files.get(\"image\"):\n        # Method 1\n        # with request.files[\"image\"] as f:\n        #     im = Image.open(io.BytesIO(f.read()))",
        "detail": "yolov5.utils.flask_rest_api.restapi",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "yolov5.utils.flask_rest_api.restapi",
        "description": "yolov5.utils.flask_rest_api.restapi",
        "peekOfCode": "app = Flask(__name__)\nmodels = {}\nDETECTION_URL = \"/v1/object-detection/<model>\"\n@app.route(DETECTION_URL, methods=[\"POST\"])\ndef predict(model):\n    \"\"\"Predict and return object detections in JSON format given an image and model name via a Flask REST API POST\n    request.\n    \"\"\"\n    if request.method != \"POST\":\n        return",
        "detail": "yolov5.utils.flask_rest_api.restapi",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 5,
        "importPath": "yolov5.utils.flask_rest_api.restapi",
        "description": "yolov5.utils.flask_rest_api.restapi",
        "peekOfCode": "models = {}\nDETECTION_URL = \"/v1/object-detection/<model>\"\n@app.route(DETECTION_URL, methods=[\"POST\"])\ndef predict(model):\n    \"\"\"Predict and return object detections in JSON format given an image and model name via a Flask REST API POST\n    request.\n    \"\"\"\n    if request.method != \"POST\":\n        return\n    if request.files.get(\"image\"):",
        "detail": "yolov5.utils.flask_rest_api.restapi",
        "documentation": {}
    },
    {
        "label": "DETECTION_URL",
        "kind": 5,
        "importPath": "yolov5.utils.flask_rest_api.restapi",
        "description": "yolov5.utils.flask_rest_api.restapi",
        "peekOfCode": "DETECTION_URL = \"/v1/object-detection/<model>\"\n@app.route(DETECTION_URL, methods=[\"POST\"])\ndef predict(model):\n    \"\"\"Predict and return object detections in JSON format given an image and model name via a Flask REST API POST\n    request.\n    \"\"\"\n    if request.method != \"POST\":\n        return\n    if request.files.get(\"image\"):\n        # Method 1",
        "detail": "yolov5.utils.flask_rest_api.restapi",
        "documentation": {}
    },
    {
        "label": "ClearmlLogger",
        "kind": 6,
        "importPath": "yolov5.utils.loggers.clearml.clearml_utils",
        "description": "yolov5.utils.loggers.clearml.clearml_utils",
        "peekOfCode": "class ClearmlLogger:\n    \"\"\"\n    Log training runs, datasets, models, and predictions to ClearML.\n    This logger sends information to ClearML at app.clear.ml or to your own hosted server. By default, this information\n    includes hyperparameters, system configuration and metrics, model metrics, code information and basic data metrics\n    and analyses.\n    By providing additional command line arguments to train.py, datasets, models and predictions can also be logged.\n    \"\"\"\n    def __init__(self, opt, hyp):\n        \"\"\"",
        "detail": "yolov5.utils.loggers.clearml.clearml_utils",
        "documentation": {}
    },
    {
        "label": "construct_dataset",
        "kind": 2,
        "importPath": "yolov5.utils.loggers.clearml.clearml_utils",
        "description": "yolov5.utils.loggers.clearml.clearml_utils",
        "peekOfCode": "def construct_dataset(clearml_info_string):\n    \"\"\"Load in a clearml dataset and fill the internal data_dict with its contents.\"\"\"\n    dataset_id = clearml_info_string.replace(\"clearml://\", \"\")\n    dataset = Dataset.get(dataset_id=dataset_id)\n    dataset_root_path = Path(dataset.get_local_copy())\n    # We'll search for the yaml file definition in the dataset\n    yaml_filenames = list(glob.glob(str(dataset_root_path / \"*.yaml\")) + glob.glob(str(dataset_root_path / \"*.yml\")))\n    if len(yaml_filenames) > 1:\n        raise ValueError(\n            \"More than one yaml file was found in the dataset root, cannot determine which one contains \"",
        "detail": "yolov5.utils.loggers.clearml.clearml_utils",
        "documentation": {}
    },
    {
        "label": "task",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.clearml.hpo",
        "description": "yolov5.utils.loggers.clearml.hpo",
        "peekOfCode": "task = Task.init(\n    project_name=\"Hyper-Parameter Optimization\",\n    task_name=\"YOLOv5\",\n    task_type=Task.TaskTypes.optimizer,\n    reuse_last_task_id=False,\n)\n# Example use case:\noptimizer = HyperParameterOptimizer(\n    # This is the experiment we want to optimize\n    base_task_id=\"<your_template_task_id>\",",
        "detail": "yolov5.utils.loggers.clearml.hpo",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.clearml.hpo",
        "description": "yolov5.utils.loggers.clearml.hpo",
        "peekOfCode": "optimizer = HyperParameterOptimizer(\n    # This is the experiment we want to optimize\n    base_task_id=\"<your_template_task_id>\",\n    # here we define the hyper-parameters to optimize\n    # Notice: The parameter name should exactly match what you see in the UI: <section_name>/<parameter>\n    # For Example, here we see in the base experiment a section Named: \"General\"\n    # under it a parameter named \"batch_size\", this becomes \"General/batch_size\"\n    # If you have `argparse` for example, then arguments will appear under the \"Args\" section,\n    # and you should instead pass \"Args/batch_size\"\n    hyper_parameters=[",
        "detail": "yolov5.utils.loggers.clearml.hpo",
        "documentation": {}
    },
    {
        "label": "download_model_checkpoint",
        "kind": 2,
        "importPath": "yolov5.utils.loggers.comet.comet_utils",
        "description": "yolov5.utils.loggers.comet.comet_utils",
        "peekOfCode": "def download_model_checkpoint(opt, experiment):\n    \"\"\"Downloads YOLOv5 model checkpoint from Comet ML experiment, updating `opt.weights` with download path.\"\"\"\n    model_dir = f\"{opt.project}/{experiment.name}\"\n    os.makedirs(model_dir, exist_ok=True)\n    model_name = COMET_MODEL_NAME\n    model_asset_list = experiment.get_model_asset_list(model_name)\n    if len(model_asset_list) == 0:\n        logger.error(f\"COMET ERROR: No checkpoints found for model name : {model_name}\")\n        return\n    model_asset_list = sorted(",
        "detail": "yolov5.utils.loggers.comet.comet_utils",
        "documentation": {}
    },
    {
        "label": "set_opt_parameters",
        "kind": 2,
        "importPath": "yolov5.utils.loggers.comet.comet_utils",
        "description": "yolov5.utils.loggers.comet.comet_utils",
        "peekOfCode": "def set_opt_parameters(opt, experiment):\n    \"\"\"\n    Update the opts Namespace with parameters from Comet's ExistingExperiment when resuming a run.\n    Args:\n        opt (argparse.Namespace): Namespace of command line options\n        experiment (comet_ml.APIExperiment): Comet API Experiment object\n    \"\"\"\n    asset_list = experiment.get_asset_list()\n    resume_string = opt.resume\n    for asset in asset_list:",
        "detail": "yolov5.utils.loggers.comet.comet_utils",
        "documentation": {}
    },
    {
        "label": "check_comet_weights",
        "kind": 2,
        "importPath": "yolov5.utils.loggers.comet.comet_utils",
        "description": "yolov5.utils.loggers.comet.comet_utils",
        "peekOfCode": "def check_comet_weights(opt):\n    \"\"\"\n    Downloads model weights from Comet and updates the weights path to point to saved weights location.\n    Args:\n        opt (argparse.Namespace): Command Line arguments passed\n            to YOLOv5 training script\n    Returns:\n        None/bool: Return True if weights are successfully downloaded\n            else return None\n    \"\"\"",
        "detail": "yolov5.utils.loggers.comet.comet_utils",
        "documentation": {}
    },
    {
        "label": "check_comet_resume",
        "kind": 2,
        "importPath": "yolov5.utils.loggers.comet.comet_utils",
        "description": "yolov5.utils.loggers.comet.comet_utils",
        "peekOfCode": "def check_comet_resume(opt):\n    \"\"\"\n    Restores run parameters to its original state based on the model checkpoint and logged Experiment parameters.\n    Args:\n        opt (argparse.Namespace): Command Line arguments passed\n            to YOLOv5 training script\n    Returns:\n        None/bool: Return True if the run is restored successfully\n            else return None\n    \"\"\"",
        "detail": "yolov5.utils.loggers.comet.comet_utils",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.comet.comet_utils",
        "description": "yolov5.utils.loggers.comet.comet_utils",
        "peekOfCode": "logger = logging.getLogger(__name__)\nCOMET_PREFIX = \"comet://\"\nCOMET_MODEL_NAME = os.getenv(\"COMET_MODEL_NAME\", \"yolov5\")\nCOMET_DEFAULT_CHECKPOINT_FILENAME = os.getenv(\"COMET_DEFAULT_CHECKPOINT_FILENAME\", \"last.pt\")\ndef download_model_checkpoint(opt, experiment):\n    \"\"\"Downloads YOLOv5 model checkpoint from Comet ML experiment, updating `opt.weights` with download path.\"\"\"\n    model_dir = f\"{opt.project}/{experiment.name}\"\n    os.makedirs(model_dir, exist_ok=True)\n    model_name = COMET_MODEL_NAME\n    model_asset_list = experiment.get_model_asset_list(model_name)",
        "detail": "yolov5.utils.loggers.comet.comet_utils",
        "documentation": {}
    },
    {
        "label": "COMET_PREFIX",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.comet.comet_utils",
        "description": "yolov5.utils.loggers.comet.comet_utils",
        "peekOfCode": "COMET_PREFIX = \"comet://\"\nCOMET_MODEL_NAME = os.getenv(\"COMET_MODEL_NAME\", \"yolov5\")\nCOMET_DEFAULT_CHECKPOINT_FILENAME = os.getenv(\"COMET_DEFAULT_CHECKPOINT_FILENAME\", \"last.pt\")\ndef download_model_checkpoint(opt, experiment):\n    \"\"\"Downloads YOLOv5 model checkpoint from Comet ML experiment, updating `opt.weights` with download path.\"\"\"\n    model_dir = f\"{opt.project}/{experiment.name}\"\n    os.makedirs(model_dir, exist_ok=True)\n    model_name = COMET_MODEL_NAME\n    model_asset_list = experiment.get_model_asset_list(model_name)\n    if len(model_asset_list) == 0:",
        "detail": "yolov5.utils.loggers.comet.comet_utils",
        "documentation": {}
    },
    {
        "label": "COMET_MODEL_NAME",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.comet.comet_utils",
        "description": "yolov5.utils.loggers.comet.comet_utils",
        "peekOfCode": "COMET_MODEL_NAME = os.getenv(\"COMET_MODEL_NAME\", \"yolov5\")\nCOMET_DEFAULT_CHECKPOINT_FILENAME = os.getenv(\"COMET_DEFAULT_CHECKPOINT_FILENAME\", \"last.pt\")\ndef download_model_checkpoint(opt, experiment):\n    \"\"\"Downloads YOLOv5 model checkpoint from Comet ML experiment, updating `opt.weights` with download path.\"\"\"\n    model_dir = f\"{opt.project}/{experiment.name}\"\n    os.makedirs(model_dir, exist_ok=True)\n    model_name = COMET_MODEL_NAME\n    model_asset_list = experiment.get_model_asset_list(model_name)\n    if len(model_asset_list) == 0:\n        logger.error(f\"COMET ERROR: No checkpoints found for model name : {model_name}\")",
        "detail": "yolov5.utils.loggers.comet.comet_utils",
        "documentation": {}
    },
    {
        "label": "COMET_DEFAULT_CHECKPOINT_FILENAME",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.comet.comet_utils",
        "description": "yolov5.utils.loggers.comet.comet_utils",
        "peekOfCode": "COMET_DEFAULT_CHECKPOINT_FILENAME = os.getenv(\"COMET_DEFAULT_CHECKPOINT_FILENAME\", \"last.pt\")\ndef download_model_checkpoint(opt, experiment):\n    \"\"\"Downloads YOLOv5 model checkpoint from Comet ML experiment, updating `opt.weights` with download path.\"\"\"\n    model_dir = f\"{opt.project}/{experiment.name}\"\n    os.makedirs(model_dir, exist_ok=True)\n    model_name = COMET_MODEL_NAME\n    model_asset_list = experiment.get_model_asset_list(model_name)\n    if len(model_asset_list) == 0:\n        logger.error(f\"COMET ERROR: No checkpoints found for model name : {model_name}\")\n        return",
        "detail": "yolov5.utils.loggers.comet.comet_utils",
        "documentation": {}
    },
    {
        "label": "get_args",
        "kind": 2,
        "importPath": "yolov5.utils.loggers.comet.hpo",
        "description": "yolov5.utils.loggers.comet.hpo",
        "peekOfCode": "def get_args(known=False):\n    \"\"\"Parses command-line arguments for YOLOv5 training, supporting configuration of weights, data paths,\n    hyperparameters, and more.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", type=str, default=ROOT / \"yolov5s.pt\", help=\"initial weights path\")\n    parser.add_argument(\"--cfg\", type=str, default=\"\", help=\"model.yaml path\")\n    parser.add_argument(\"--data\", type=str, default=ROOT / \"data/coco128.yaml\", help=\"dataset.yaml path\")\n    parser.add_argument(\"--hyp\", type=str, default=ROOT / \"data/hyps/hyp.scratch-low.yaml\", help=\"hyperparameters path\")\n    parser.add_argument(\"--epochs\", type=int, default=300, help=\"total training epochs\")",
        "detail": "yolov5.utils.loggers.comet.hpo",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.utils.loggers.comet.hpo",
        "description": "yolov5.utils.loggers.comet.hpo",
        "peekOfCode": "def run(parameters, opt):\n    \"\"\"Executes YOLOv5 training with given hyperparameters and options, setting up device and training directories.\"\"\"\n    hyp_dict = {k: v for k, v in parameters.items() if k not in [\"epochs\", \"batch_size\"]}\n    opt.save_dir = str(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok or opt.evolve))\n    opt.batch_size = parameters.get(\"batch_size\")\n    opt.epochs = parameters.get(\"epochs\")\n    device = select_device(opt.device, batch_size=opt.batch_size)\n    train(hyp_dict, opt, device, callbacks=Callbacks())\nif __name__ == \"__main__\":\n    opt = get_args(known=True)",
        "detail": "yolov5.utils.loggers.comet.hpo",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.comet.hpo",
        "description": "yolov5.utils.loggers.comet.hpo",
        "peekOfCode": "logger = logging.getLogger(__name__)\nFILE = Path(__file__).resolve()\nROOT = FILE.parents[3]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nfrom train import train\nfrom utils.callbacks import Callbacks\nfrom utils.general import increment_path\nfrom utils.torch_utils import select_device\n# Project Configuration",
        "detail": "yolov5.utils.loggers.comet.hpo",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.comet.hpo",
        "description": "yolov5.utils.loggers.comet.hpo",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[3]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nfrom train import train\nfrom utils.callbacks import Callbacks\nfrom utils.general import increment_path\nfrom utils.torch_utils import select_device\n# Project Configuration\nconfig = comet_ml.config.get_config()",
        "detail": "yolov5.utils.loggers.comet.hpo",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.comet.hpo",
        "description": "yolov5.utils.loggers.comet.hpo",
        "peekOfCode": "ROOT = FILE.parents[3]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nfrom train import train\nfrom utils.callbacks import Callbacks\nfrom utils.general import increment_path\nfrom utils.torch_utils import select_device\n# Project Configuration\nconfig = comet_ml.config.get_config()\nCOMET_PROJECT_NAME = config.get_string(os.getenv(\"COMET_PROJECT_NAME\"), \"comet.project_name\", default=\"yolov5\")",
        "detail": "yolov5.utils.loggers.comet.hpo",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.comet.hpo",
        "description": "yolov5.utils.loggers.comet.hpo",
        "peekOfCode": "config = comet_ml.config.get_config()\nCOMET_PROJECT_NAME = config.get_string(os.getenv(\"COMET_PROJECT_NAME\"), \"comet.project_name\", default=\"yolov5\")\ndef get_args(known=False):\n    \"\"\"Parses command-line arguments for YOLOv5 training, supporting configuration of weights, data paths,\n    hyperparameters, and more.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", type=str, default=ROOT / \"yolov5s.pt\", help=\"initial weights path\")\n    parser.add_argument(\"--cfg\", type=str, default=\"\", help=\"model.yaml path\")\n    parser.add_argument(\"--data\", type=str, default=ROOT / \"data/coco128.yaml\", help=\"dataset.yaml path\")",
        "detail": "yolov5.utils.loggers.comet.hpo",
        "documentation": {}
    },
    {
        "label": "COMET_PROJECT_NAME",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.comet.hpo",
        "description": "yolov5.utils.loggers.comet.hpo",
        "peekOfCode": "COMET_PROJECT_NAME = config.get_string(os.getenv(\"COMET_PROJECT_NAME\"), \"comet.project_name\", default=\"yolov5\")\ndef get_args(known=False):\n    \"\"\"Parses command-line arguments for YOLOv5 training, supporting configuration of weights, data paths,\n    hyperparameters, and more.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", type=str, default=ROOT / \"yolov5s.pt\", help=\"initial weights path\")\n    parser.add_argument(\"--cfg\", type=str, default=\"\", help=\"model.yaml path\")\n    parser.add_argument(\"--data\", type=str, default=ROOT / \"data/coco128.yaml\", help=\"dataset.yaml path\")\n    parser.add_argument(\"--hyp\", type=str, default=ROOT / \"data/hyps/hyp.scratch-low.yaml\", help=\"hyperparameters path\")",
        "detail": "yolov5.utils.loggers.comet.hpo",
        "documentation": {}
    },
    {
        "label": "WandbLogger",
        "kind": 6,
        "importPath": "yolov5.utils.loggers.wandb.wandb_utils",
        "description": "yolov5.utils.loggers.wandb.wandb_utils",
        "peekOfCode": "class WandbLogger:\n    \"\"\"\n    Log training runs, datasets, models, and predictions to Weights & Biases.\n    This logger sends information to W&B at wandb.ai. By default, this information includes hyperparameters, system\n    configuration and metrics, model metrics, and basic data metrics and analyses.\n    By providing additional command line arguments to train.py, datasets, models and predictions can also be logged.\n    For more on how this logger is used, see the Weights & Biases documentation:\n    https://docs.wandb.com/guides/integrations/yolov5\n    \"\"\"\n    def __init__(self, opt, run_id=None, job_type=\"Training\"):",
        "detail": "yolov5.utils.loggers.wandb.wandb_utils",
        "documentation": {}
    },
    {
        "label": "all_logging_disabled",
        "kind": 2,
        "importPath": "yolov5.utils.loggers.wandb.wandb_utils",
        "description": "yolov5.utils.loggers.wandb.wandb_utils",
        "peekOfCode": "def all_logging_disabled(highest_level=logging.CRITICAL):\n    \"\"\"Source - https://gist.github.com/simon-weber/7853144\n    A context manager that will prevent any logging messages triggered during the body from being processed.\n    :param highest_level: the maximum logging level in use.\n      This would only need to be changed if a custom level greater than CRITICAL is defined.\n    \"\"\"\n    previous_level = logging.root.manager.disable\n    logging.disable(highest_level)\n    try:\n        yield",
        "detail": "yolov5.utils.loggers.wandb.wandb_utils",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.wandb.wandb_utils",
        "description": "yolov5.utils.loggers.wandb.wandb_utils",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[3]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nRANK = int(os.getenv(\"RANK\", -1))\nDEPRECATION_WARNING = (\n    f\"{colorstr('wandb')}: WARNING  wandb is deprecated and will be removed in a future release. \"\n    f\"See supported integrations at https://github.com/ultralytics/yolov5#integrations.\"\n)\ntry:",
        "detail": "yolov5.utils.loggers.wandb.wandb_utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.wandb.wandb_utils",
        "description": "yolov5.utils.loggers.wandb.wandb_utils",
        "peekOfCode": "ROOT = FILE.parents[3]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nRANK = int(os.getenv(\"RANK\", -1))\nDEPRECATION_WARNING = (\n    f\"{colorstr('wandb')}: WARNING  wandb is deprecated and will be removed in a future release. \"\n    f\"See supported integrations at https://github.com/ultralytics/yolov5#integrations.\"\n)\ntry:\n    import wandb",
        "detail": "yolov5.utils.loggers.wandb.wandb_utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.wandb.wandb_utils",
        "description": "yolov5.utils.loggers.wandb.wandb_utils",
        "peekOfCode": "RANK = int(os.getenv(\"RANK\", -1))\nDEPRECATION_WARNING = (\n    f\"{colorstr('wandb')}: WARNING  wandb is deprecated and will be removed in a future release. \"\n    f\"See supported integrations at https://github.com/ultralytics/yolov5#integrations.\"\n)\ntry:\n    import wandb\n    assert hasattr(wandb, \"__version__\")  # verify package import not local dir\n    LOGGER.warning(DEPRECATION_WARNING)\nexcept (ImportError, AssertionError):",
        "detail": "yolov5.utils.loggers.wandb.wandb_utils",
        "documentation": {}
    },
    {
        "label": "DEPRECATION_WARNING",
        "kind": 5,
        "importPath": "yolov5.utils.loggers.wandb.wandb_utils",
        "description": "yolov5.utils.loggers.wandb.wandb_utils",
        "peekOfCode": "DEPRECATION_WARNING = (\n    f\"{colorstr('wandb')}: WARNING  wandb is deprecated and will be removed in a future release. \"\n    f\"See supported integrations at https://github.com/ultralytics/yolov5#integrations.\"\n)\ntry:\n    import wandb\n    assert hasattr(wandb, \"__version__\")  # verify package import not local dir\n    LOGGER.warning(DEPRECATION_WARNING)\nexcept (ImportError, AssertionError):\n    wandb = None",
        "detail": "yolov5.utils.loggers.wandb.wandb_utils",
        "documentation": {}
    },
    {
        "label": "mixup",
        "kind": 2,
        "importPath": "yolov5.utils.segment.augmentations",
        "description": "yolov5.utils.segment.augmentations",
        "peekOfCode": "def mixup(im, labels, segments, im2, labels2, segments2):\n    \"\"\"\n    Applies MixUp augmentation blending two images, labels, and segments with a random ratio.\n    See https://arxiv.org/pdf/1710.09412.pdf\n    \"\"\"\n    r = np.random.beta(32.0, 32.0)  # mixup ratio, alpha=beta=32.0\n    im = (im * r + im2 * (1 - r)).astype(np.uint8)\n    labels = np.concatenate((labels, labels2), 0)\n    segments = np.concatenate((segments, segments2), 0)\n    return im, labels, segments",
        "detail": "yolov5.utils.segment.augmentations",
        "documentation": {}
    },
    {
        "label": "random_perspective",
        "kind": 2,
        "importPath": "yolov5.utils.segment.augmentations",
        "description": "yolov5.utils.segment.augmentations",
        "peekOfCode": "def random_perspective(\n    im, targets=(), segments=(), degrees=10, translate=0.1, scale=0.1, shear=10, perspective=0.0, border=(0, 0)\n):\n    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))\n    # targets = [cls, xyxy]\n    \"\"\"Applies random perspective, rotation, scale, shear, and translation augmentations to an image and targets.\"\"\"\n    height = im.shape[0] + border[0] * 2  # shape(h,w,c)\n    width = im.shape[1] + border[1] * 2\n    # Center\n    C = np.eye(3)",
        "detail": "yolov5.utils.segment.augmentations",
        "documentation": {}
    },
    {
        "label": "LoadImagesAndLabelsAndMasks",
        "kind": 6,
        "importPath": "yolov5.utils.segment.dataloaders",
        "description": "yolov5.utils.segment.dataloaders",
        "peekOfCode": "class LoadImagesAndLabelsAndMasks(LoadImagesAndLabels):  # for training/testing\n    \"\"\"Loads images, labels, and segmentation masks for training and testing YOLO models with augmentation support.\"\"\"\n    def __init__(\n        self,\n        path,\n        img_size=640,\n        batch_size=16,\n        augment=False,\n        hyp=None,\n        rect=False,",
        "detail": "yolov5.utils.segment.dataloaders",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "kind": 2,
        "importPath": "yolov5.utils.segment.dataloaders",
        "description": "yolov5.utils.segment.dataloaders",
        "peekOfCode": "def create_dataloader(\n    path,\n    imgsz,\n    batch_size,\n    stride,\n    single_cls=False,\n    hyp=None,\n    augment=False,\n    cache=False,\n    pad=0.0,",
        "detail": "yolov5.utils.segment.dataloaders",
        "documentation": {}
    },
    {
        "label": "polygon2mask",
        "kind": 2,
        "importPath": "yolov5.utils.segment.dataloaders",
        "description": "yolov5.utils.segment.dataloaders",
        "peekOfCode": "def polygon2mask(img_size, polygons, color=1, downsample_ratio=1):\n    \"\"\"\n    Args:\n        img_size (tuple): The image size.\n        polygons (np.ndarray): [N, M], N is the number of polygons,\n            M is the number of points(Be divided by 2).\n    \"\"\"\n    mask = np.zeros(img_size, dtype=np.uint8)\n    polygons = np.asarray(polygons)\n    polygons = polygons.astype(np.int32)",
        "detail": "yolov5.utils.segment.dataloaders",
        "documentation": {}
    },
    {
        "label": "polygons2masks",
        "kind": 2,
        "importPath": "yolov5.utils.segment.dataloaders",
        "description": "yolov5.utils.segment.dataloaders",
        "peekOfCode": "def polygons2masks(img_size, polygons, color, downsample_ratio=1):\n    \"\"\"\n    Args:\n        img_size (tuple): The image size.\n        polygons (list[np.ndarray]): each polygon is [N, M],\n            N is the number of polygons,\n            M is the number of points(Be divided by 2).\n    \"\"\"\n    masks = []\n    for si in range(len(polygons)):",
        "detail": "yolov5.utils.segment.dataloaders",
        "documentation": {}
    },
    {
        "label": "polygons2masks_overlap",
        "kind": 2,
        "importPath": "yolov5.utils.segment.dataloaders",
        "description": "yolov5.utils.segment.dataloaders",
        "peekOfCode": "def polygons2masks_overlap(img_size, segments, downsample_ratio=1):\n    \"\"\"Return a (640, 640) overlap mask.\"\"\"\n    masks = np.zeros(\n        (img_size[0] // downsample_ratio, img_size[1] // downsample_ratio),\n        dtype=np.int32 if len(segments) > 255 else np.uint8,\n    )\n    areas = []\n    ms = []\n    for si in range(len(segments)):\n        mask = polygon2mask(",
        "detail": "yolov5.utils.segment.dataloaders",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolov5.utils.segment.dataloaders",
        "description": "yolov5.utils.segment.dataloaders",
        "peekOfCode": "RANK = int(os.getenv(\"RANK\", -1))\ndef create_dataloader(\n    path,\n    imgsz,\n    batch_size,\n    stride,\n    single_cls=False,\n    hyp=None,\n    augment=False,\n    cache=False,",
        "detail": "yolov5.utils.segment.dataloaders",
        "documentation": {}
    },
    {
        "label": "crop_mask",
        "kind": 2,
        "importPath": "yolov5.utils.segment.general",
        "description": "yolov5.utils.segment.general",
        "peekOfCode": "def crop_mask(masks, boxes):\n    \"\"\"\n    \"Crop\" predicted masks by zeroing out everything not in the predicted bbox. Vectorized by Chong (thanks Chong).\n    Args:\n        - masks should be a size [n, h, w] tensor of masks\n        - boxes should be a size [n, 4] tensor of bbox coords in relative point form\n    \"\"\"\n    n, h, w = masks.shape\n    x1, y1, x2, y2 = torch.chunk(boxes[:, :, None], 4, 1)  # x1 shape(1,1,n)\n    r = torch.arange(w, device=masks.device, dtype=x1.dtype)[None, None, :]  # rows shape(1,w,1)",
        "detail": "yolov5.utils.segment.general",
        "documentation": {}
    },
    {
        "label": "process_mask_upsample",
        "kind": 2,
        "importPath": "yolov5.utils.segment.general",
        "description": "yolov5.utils.segment.general",
        "peekOfCode": "def process_mask_upsample(protos, masks_in, bboxes, shape):\n    \"\"\"\n    Crop after upsample.\n    protos: [mask_dim, mask_h, mask_w]\n    masks_in: [n, mask_dim], n is number of masks after nms\n    bboxes: [n, 4], n is number of masks after nms\n    shape: input_image_size, (h, w).\n    return: h, w, n\n    \"\"\"\n    c, mh, mw = protos.shape  # CHW",
        "detail": "yolov5.utils.segment.general",
        "documentation": {}
    },
    {
        "label": "process_mask",
        "kind": 2,
        "importPath": "yolov5.utils.segment.general",
        "description": "yolov5.utils.segment.general",
        "peekOfCode": "def process_mask(protos, masks_in, bboxes, shape, upsample=False):\n    \"\"\"\n    Crop before upsample.\n    proto_out: [mask_dim, mask_h, mask_w]\n    out_masks: [n, mask_dim], n is number of masks after nms\n    bboxes: [n, 4], n is number of masks after nms\n    shape:input_image_size, (h, w).\n    return: h, w, n\n    \"\"\"\n    c, mh, mw = protos.shape  # CHW",
        "detail": "yolov5.utils.segment.general",
        "documentation": {}
    },
    {
        "label": "process_mask_native",
        "kind": 2,
        "importPath": "yolov5.utils.segment.general",
        "description": "yolov5.utils.segment.general",
        "peekOfCode": "def process_mask_native(protos, masks_in, bboxes, shape):\n    \"\"\"\n    Crop after upsample.\n    protos: [mask_dim, mask_h, mask_w]\n    masks_in: [n, mask_dim], n is number of masks after nms\n    bboxes: [n, 4], n is number of masks after nms\n    shape: input_image_size, (h, w).\n    return: h, w, n\n    \"\"\"\n    c, mh, mw = protos.shape  # CHW",
        "detail": "yolov5.utils.segment.general",
        "documentation": {}
    },
    {
        "label": "scale_image",
        "kind": 2,
        "importPath": "yolov5.utils.segment.general",
        "description": "yolov5.utils.segment.general",
        "peekOfCode": "def scale_image(im1_shape, masks, im0_shape, ratio_pad=None):\n    \"\"\"\n    img1_shape: model input shape, [h, w]\n    img0_shape: origin pic shape, [h, w, 3]\n    masks: [h, w, num].\n    \"\"\"\n    # Rescale coordinates (xyxy) from im1_shape to im0_shape\n    if ratio_pad is None:  # calculate from im0_shape\n        gain = min(im1_shape[0] / im0_shape[0], im1_shape[1] / im0_shape[1])  # gain  = old / new\n        pad = (im1_shape[1] - im0_shape[1] * gain) / 2, (im1_shape[0] - im0_shape[0] * gain) / 2  # wh padding",
        "detail": "yolov5.utils.segment.general",
        "documentation": {}
    },
    {
        "label": "mask_iou",
        "kind": 2,
        "importPath": "yolov5.utils.segment.general",
        "description": "yolov5.utils.segment.general",
        "peekOfCode": "def mask_iou(mask1, mask2, eps=1e-7):\n    \"\"\"\n    mask1: [N, n] m1 means number of predicted objects\n    mask2: [M, n] m2 means number of gt objects\n    Note: n means image_w x image_h.\n    return: masks iou, [N, M]\n    \"\"\"\n    intersection = torch.matmul(mask1, mask2.t()).clamp(0)\n    union = (mask1.sum(1)[:, None] + mask2.sum(1)[None]) - intersection  # (area1 + area2) - intersection\n    return intersection / (union + eps)",
        "detail": "yolov5.utils.segment.general",
        "documentation": {}
    },
    {
        "label": "masks_iou",
        "kind": 2,
        "importPath": "yolov5.utils.segment.general",
        "description": "yolov5.utils.segment.general",
        "peekOfCode": "def masks_iou(mask1, mask2, eps=1e-7):\n    \"\"\"\n    mask1: [N, n] m1 means number of predicted objects\n    mask2: [N, n] m2 means number of gt objects\n    Note: n means image_w x image_h.\n    return: masks iou, (N, )\n    \"\"\"\n    intersection = (mask1 * mask2).sum(1).clamp(0)  # (N, )\n    union = (mask1.sum(1) + mask2.sum(1))[None] - intersection  # (area1 + area2) - intersection\n    return intersection / (union + eps)",
        "detail": "yolov5.utils.segment.general",
        "documentation": {}
    },
    {
        "label": "masks2segments",
        "kind": 2,
        "importPath": "yolov5.utils.segment.general",
        "description": "yolov5.utils.segment.general",
        "peekOfCode": "def masks2segments(masks, strategy=\"largest\"):\n    \"\"\"Converts binary (n,160,160) masks to polygon segments with options for concatenation or selecting the largest\n    segment.\n    \"\"\"\n    segments = []\n    for x in masks.int().cpu().numpy().astype(\"uint8\"):\n        c = cv2.findContours(x, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n        if c:\n            if strategy == \"concat\":  # concatenate all segments\n                c = np.concatenate([x.reshape(-1, 2) for x in c])",
        "detail": "yolov5.utils.segment.general",
        "documentation": {}
    },
    {
        "label": "ComputeLoss",
        "kind": 6,
        "importPath": "yolov5.utils.segment.loss",
        "description": "yolov5.utils.segment.loss",
        "peekOfCode": "class ComputeLoss:\n    \"\"\"Computes the YOLOv5 model's loss components including classification, objectness, box, and mask losses.\"\"\"\n    def __init__(self, model, autobalance=False, overlap=False):\n        \"\"\"Initializes the compute loss function for YOLOv5 models with options for autobalancing and overlap\n        handling.\n        \"\"\"\n        self.sort_obj_iou = False\n        self.overlap = overlap\n        device = next(model.parameters()).device  # get model device\n        h = model.hyp  # hyperparameters",
        "detail": "yolov5.utils.segment.loss",
        "documentation": {}
    },
    {
        "label": "Metric",
        "kind": 6,
        "importPath": "yolov5.utils.segment.metrics",
        "description": "yolov5.utils.segment.metrics",
        "peekOfCode": "class Metric:\n    \"\"\"Computes performance metrics like precision, recall, F1 score, and average precision for model evaluation.\"\"\"\n    def __init__(self) -> None:\n        \"\"\"Initializes performance metric attributes for precision, recall, F1 score, average precision, and class\n        indices.\n        \"\"\"\n        self.p = []  # (nc, )\n        self.r = []  # (nc, )\n        self.f1 = []  # (nc, )\n        self.all_ap = []  # (nc, 10)",
        "detail": "yolov5.utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "Metrics",
        "kind": 6,
        "importPath": "yolov5.utils.segment.metrics",
        "description": "yolov5.utils.segment.metrics",
        "peekOfCode": "class Metrics:\n    \"\"\"Metric for boxes and masks.\"\"\"\n    def __init__(self) -> None:\n        \"\"\"Initializes Metric objects for bounding boxes and masks to compute performance metrics in the Metrics\n        class.\n        \"\"\"\n        self.metric_box = Metric()\n        self.metric_mask = Metric()\n    def update(self, results):\n        \"\"\"",
        "detail": "yolov5.utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "fitness",
        "kind": 2,
        "importPath": "yolov5.utils.segment.metrics",
        "description": "yolov5.utils.segment.metrics",
        "peekOfCode": "def fitness(x):\n    \"\"\"Evaluates model fitness by a weighted sum of 8 metrics, `x`: [N,8] array, weights: [0.1, 0.9] for mAP and F1.\"\"\"\n    w = [0.0, 0.0, 0.1, 0.9, 0.0, 0.0, 0.1, 0.9]\n    return (x[:, :8] * w).sum(1)\ndef ap_per_class_box_and_mask(\n    tp_m,\n    tp_b,\n    conf,\n    pred_cls,\n    target_cls,",
        "detail": "yolov5.utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "ap_per_class_box_and_mask",
        "kind": 2,
        "importPath": "yolov5.utils.segment.metrics",
        "description": "yolov5.utils.segment.metrics",
        "peekOfCode": "def ap_per_class_box_and_mask(\n    tp_m,\n    tp_b,\n    conf,\n    pred_cls,\n    target_cls,\n    plot=False,\n    save_dir=\".\",\n    names=(),\n):",
        "detail": "yolov5.utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "KEYS",
        "kind": 5,
        "importPath": "yolov5.utils.segment.metrics",
        "description": "yolov5.utils.segment.metrics",
        "peekOfCode": "KEYS = [\n    \"train/box_loss\",\n    \"train/seg_loss\",  # train loss\n    \"train/obj_loss\",\n    \"train/cls_loss\",\n    \"metrics/precision(B)\",\n    \"metrics/recall(B)\",\n    \"metrics/mAP_0.5(B)\",\n    \"metrics/mAP_0.5:0.95(B)\",  # metrics\n    \"metrics/precision(M)\",",
        "detail": "yolov5.utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "BEST_KEYS",
        "kind": 5,
        "importPath": "yolov5.utils.segment.metrics",
        "description": "yolov5.utils.segment.metrics",
        "peekOfCode": "BEST_KEYS = [\n    \"best/epoch\",\n    \"best/precision(B)\",\n    \"best/recall(B)\",\n    \"best/mAP_0.5(B)\",\n    \"best/mAP_0.5:0.95(B)\",\n    \"best/precision(M)\",\n    \"best/recall(M)\",\n    \"best/mAP_0.5(M)\",\n    \"best/mAP_0.5:0.95(M)\",",
        "detail": "yolov5.utils.segment.metrics",
        "documentation": {}
    },
    {
        "label": "plot_images_and_masks",
        "kind": 2,
        "importPath": "yolov5.utils.segment.plots",
        "description": "yolov5.utils.segment.plots",
        "peekOfCode": "def plot_images_and_masks(images, targets, masks, paths=None, fname=\"images.jpg\", names=None):\n    \"\"\"Plots a grid of images, their labels, and masks with optional resizing and annotations, saving to fname.\"\"\"\n    if isinstance(images, torch.Tensor):\n        images = images.cpu().float().numpy()\n    if isinstance(targets, torch.Tensor):\n        targets = targets.cpu().numpy()\n    if isinstance(masks, torch.Tensor):\n        masks = masks.cpu().numpy().astype(int)\n    max_size = 1920  # max image size\n    max_subplots = 16  # max image subplots, i.e. 4x4",
        "detail": "yolov5.utils.segment.plots",
        "documentation": {}
    },
    {
        "label": "plot_results_with_masks",
        "kind": 2,
        "importPath": "yolov5.utils.segment.plots",
        "description": "yolov5.utils.segment.plots",
        "peekOfCode": "def plot_results_with_masks(file=\"path/to/results.csv\", dir=\"\", best=True):\n    \"\"\"\n    Plots training results from CSV files, plotting best or last result highlights based on `best` parameter.\n    Example: from utils.plots import *; plot_results('path/to/results.csv')\n    \"\"\"\n    save_dir = Path(file).parent if file else Path(dir)\n    fig, ax = plt.subplots(2, 8, figsize=(18, 6), tight_layout=True)\n    ax = ax.ravel()\n    files = list(save_dir.glob(\"results*.csv\"))\n    assert len(files), f\"No results.csv files found in {save_dir.resolve()}, nothing to plot.\"",
        "detail": "yolov5.utils.segment.plots",
        "documentation": {}
    },
    {
        "label": "SiLU",
        "kind": 6,
        "importPath": "yolov5.utils.activations",
        "description": "yolov5.utils.activations",
        "peekOfCode": "class SiLU(nn.Module):\n    \"\"\"Applies the Sigmoid-weighted Linear Unit (SiLU) activation function, also known as Swish.\"\"\"\n    @staticmethod\n    def forward(x):\n        \"\"\"\n        Applies the Sigmoid-weighted Linear Unit (SiLU) activation function.\n        https://arxiv.org/pdf/1606.08415.pdf.\n        \"\"\"\n        return x * torch.sigmoid(x)\nclass Hardswish(nn.Module):",
        "detail": "yolov5.utils.activations",
        "documentation": {}
    },
    {
        "label": "Hardswish",
        "kind": 6,
        "importPath": "yolov5.utils.activations",
        "description": "yolov5.utils.activations",
        "peekOfCode": "class Hardswish(nn.Module):\n    \"\"\"Applies the Hardswish activation function, which is efficient for mobile and embedded devices.\"\"\"\n    @staticmethod\n    def forward(x):\n        \"\"\"\n        Applies the Hardswish activation function, compatible with TorchScript, CoreML, and ONNX.\n        Equivalent to x * F.hardsigmoid(x)\n        \"\"\"\n        return x * F.hardtanh(x + 3, 0.0, 6.0) / 6.0  # for TorchScript, CoreML and ONNX\nclass Mish(nn.Module):",
        "detail": "yolov5.utils.activations",
        "documentation": {}
    },
    {
        "label": "Mish",
        "kind": 6,
        "importPath": "yolov5.utils.activations",
        "description": "yolov5.utils.activations",
        "peekOfCode": "class Mish(nn.Module):\n    \"\"\"Mish activation https://github.com/digantamisra98/Mish.\"\"\"\n    @staticmethod\n    def forward(x):\n        \"\"\"Applies the Mish activation function, a smooth alternative to ReLU.\"\"\"\n        return x * F.softplus(x).tanh()\nclass MemoryEfficientMish(nn.Module):\n    \"\"\"Efficiently applies the Mish activation function using custom autograd for reduced memory usage.\"\"\"\n    class F(torch.autograd.Function):\n        \"\"\"Implements a custom autograd function for memory-efficient Mish activation.\"\"\"",
        "detail": "yolov5.utils.activations",
        "documentation": {}
    },
    {
        "label": "MemoryEfficientMish",
        "kind": 6,
        "importPath": "yolov5.utils.activations",
        "description": "yolov5.utils.activations",
        "peekOfCode": "class MemoryEfficientMish(nn.Module):\n    \"\"\"Efficiently applies the Mish activation function using custom autograd for reduced memory usage.\"\"\"\n    class F(torch.autograd.Function):\n        \"\"\"Implements a custom autograd function for memory-efficient Mish activation.\"\"\"\n        @staticmethod\n        def forward(ctx, x):\n            \"\"\"Applies the Mish activation function, a smooth ReLU alternative, to the input tensor `x`.\"\"\"\n            ctx.save_for_backward(x)\n            return x.mul(torch.tanh(F.softplus(x)))  # x * tanh(ln(1 + exp(x)))\n        @staticmethod",
        "detail": "yolov5.utils.activations",
        "documentation": {}
    },
    {
        "label": "FReLU",
        "kind": 6,
        "importPath": "yolov5.utils.activations",
        "description": "yolov5.utils.activations",
        "peekOfCode": "class FReLU(nn.Module):\n    \"\"\"FReLU activation https://arxiv.org/abs/2007.11824.\"\"\"\n    def __init__(self, c1, k=3):  # ch_in, kernel\n        \"\"\"Initializes FReLU activation with channel `c1` and kernel size `k`.\"\"\"\n        super().__init__()\n        self.conv = nn.Conv2d(c1, c1, k, 1, 1, groups=c1, bias=False)\n        self.bn = nn.BatchNorm2d(c1)\n    def forward(self, x):\n        \"\"\"\n        Applies FReLU activation with max operation between input and BN-convolved input.",
        "detail": "yolov5.utils.activations",
        "documentation": {}
    },
    {
        "label": "AconC",
        "kind": 6,
        "importPath": "yolov5.utils.activations",
        "description": "yolov5.utils.activations",
        "peekOfCode": "class AconC(nn.Module):\n    \"\"\"\n    ACON activation (activate or not) function.\n    AconC: (p1*x-p2*x) * sigmoid(beta*(p1*x-p2*x)) + p2*x, beta is a learnable parameter\n    See \"Activate or Not: Learning Customized Activation\" https://arxiv.org/pdf/2009.04759.pdf.\n    \"\"\"\n    def __init__(self, c1):\n        \"\"\"Initializes AconC with learnable parameters p1, p2, and beta for channel-wise activation control.\"\"\"\n        super().__init__()\n        self.p1 = nn.Parameter(torch.randn(1, c1, 1, 1))",
        "detail": "yolov5.utils.activations",
        "documentation": {}
    },
    {
        "label": "MetaAconC",
        "kind": 6,
        "importPath": "yolov5.utils.activations",
        "description": "yolov5.utils.activations",
        "peekOfCode": "class MetaAconC(nn.Module):\n    \"\"\"\n    ACON activation (activate or not) function.\n    AconC: (p1*x-p2*x) * sigmoid(beta*(p1*x-p2*x)) + p2*x, beta is a learnable parameter\n    See \"Activate or Not: Learning Customized Activation\" https://arxiv.org/pdf/2009.04759.pdf.\n    \"\"\"\n    def __init__(self, c1, k=1, s=1, r=16):\n        \"\"\"Initializes MetaAconC with params: channel_in (c1), kernel size (k=1), stride (s=1), reduction (r=16).\"\"\"\n        super().__init__()\n        c2 = max(r, c1 // r)",
        "detail": "yolov5.utils.activations",
        "documentation": {}
    },
    {
        "label": "Albumentations",
        "kind": 6,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "class Albumentations:\n    \"\"\"Provides optional data augmentation for YOLOv5 using Albumentations library if installed.\"\"\"\n    def __init__(self, size=640):\n        \"\"\"Initializes Albumentations class for optional data augmentation in YOLOv5 with specified input size.\"\"\"\n        self.transform = None\n        prefix = colorstr(\"albumentations: \")\n        try:\n            import albumentations as A\n            check_version(A.__version__, \"1.0.3\", hard=True)  # version requirement\n            T = [",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "kind": 6,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "class LetterBox:\n    \"\"\"Resizes and pads images to specified dimensions while maintaining aspect ratio for YOLOv5 preprocessing.\"\"\"\n    def __init__(self, size=(640, 640), auto=False, stride=32):\n        \"\"\"Initializes a LetterBox object for YOLOv5 image preprocessing with optional auto sizing and stride\n        adjustment.\n        \"\"\"\n        super().__init__()\n        self.h, self.w = (size, size) if isinstance(size, int) else size\n        self.auto = auto  # pass max size integer, automatically solve for short side using stride\n        self.stride = stride  # used with auto",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "CenterCrop",
        "kind": 6,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "class CenterCrop:\n    \"\"\"Applies center crop to an image, resizing it to the specified size while maintaining aspect ratio.\"\"\"\n    def __init__(self, size=640):\n        \"\"\"Initializes CenterCrop for image preprocessing, accepting single int or tuple for size, defaults to 640.\"\"\"\n        super().__init__()\n        self.h, self.w = (size, size) if isinstance(size, int) else size\n    def __call__(self, im):\n        \"\"\"\n        Applies center crop to the input image and resizes it to a specified size, maintaining aspect ratio.\n        im = np.array HWC",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "kind": 6,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "class ToTensor:\n    \"\"\"Converts BGR np.array image from HWC to RGB CHW format, normalizes to [0, 1], and supports FP16 if half=True.\"\"\"\n    def __init__(self, half=False):\n        \"\"\"Initializes ToTensor for YOLOv5 image preprocessing, with optional half precision (half=True for FP16).\"\"\"\n        super().__init__()\n        self.half = half\n    def __call__(self, im):\n        \"\"\"\n        Converts BGR np.array image from HWC to RGB CHW format, and normalizes to [0, 1], with support for FP16 if\n        `half=True`.",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def normalize(x, mean=IMAGENET_MEAN, std=IMAGENET_STD, inplace=False):\n    \"\"\"\n    Applies ImageNet normalization to RGB images in BCHW format, modifying them in-place if specified.\n    Example: y = (x - mean) / std\n    \"\"\"\n    return TF.normalize(x, mean, std, inplace=inplace)\ndef denormalize(x, mean=IMAGENET_MEAN, std=IMAGENET_STD):\n    \"\"\"Reverses ImageNet normalization for BCHW format RGB images by applying `x = x * std + mean`.\"\"\"\n    for i in range(3):\n        x[:, i] = x[:, i] * std[i] + mean[i]",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "denormalize",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def denormalize(x, mean=IMAGENET_MEAN, std=IMAGENET_STD):\n    \"\"\"Reverses ImageNet normalization for BCHW format RGB images by applying `x = x * std + mean`.\"\"\"\n    for i in range(3):\n        x[:, i] = x[:, i] * std[i] + mean[i]\n    return x\ndef augment_hsv(im, hgain=0.5, sgain=0.5, vgain=0.5):\n    \"\"\"Applies HSV color-space augmentation to an image with random gains for hue, saturation, and value.\"\"\"\n    if hgain or sgain or vgain:\n        r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains\n        hue, sat, val = cv2.split(cv2.cvtColor(im, cv2.COLOR_BGR2HSV))",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "augment_hsv",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def augment_hsv(im, hgain=0.5, sgain=0.5, vgain=0.5):\n    \"\"\"Applies HSV color-space augmentation to an image with random gains for hue, saturation, and value.\"\"\"\n    if hgain or sgain or vgain:\n        r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains\n        hue, sat, val = cv2.split(cv2.cvtColor(im, cv2.COLOR_BGR2HSV))\n        dtype = im.dtype  # uint8\n        x = np.arange(0, 256, dtype=r.dtype)\n        lut_hue = ((x * r[0]) % 180).astype(dtype)\n        lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)\n        lut_val = np.clip(x * r[2], 0, 255).astype(dtype)",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "hist_equalize",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def hist_equalize(im, clahe=True, bgr=False):\n    \"\"\"Equalizes image histogram, with optional CLAHE, for BGR or RGB image with shape (n,m,3) and range 0-255.\"\"\"\n    yuv = cv2.cvtColor(im, cv2.COLOR_BGR2YUV if bgr else cv2.COLOR_RGB2YUV)\n    if clahe:\n        c = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        yuv[:, :, 0] = c.apply(yuv[:, :, 0])\n    else:\n        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])  # equalize Y channel histogram\n    return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR if bgr else cv2.COLOR_YUV2RGB)  # convert YUV image to RGB\ndef replicate(im, labels):",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "replicate",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def replicate(im, labels):\n    \"\"\"\n    Replicates half of the smallest object labels in an image for data augmentation.\n    Returns augmented image and labels.\n    \"\"\"\n    h, w = im.shape[:2]\n    boxes = labels[:, 1:].astype(int)\n    x1, y1, x2, y2 = boxes.T\n    s = ((x2 - x1) + (y2 - y1)) / 2  # side length (pixels)\n    for i in s.argsort()[: round(s.size * 0.5)]:  # smallest indices",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "letterbox",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n    \"\"\"Resizes and pads image to new_shape with stride-multiple constraints, returns resized image, ratio, padding.\"\"\"\n    shape = im.shape[:2]  # current shape [height, width]\n    if isinstance(new_shape, int):\n        new_shape = (new_shape, new_shape)\n    # Scale ratio (new / old)\n    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n        r = min(r, 1.0)\n    # Compute padding",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "random_perspective",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def random_perspective(\n    im, targets=(), segments=(), degrees=10, translate=0.1, scale=0.1, shear=10, perspective=0.0, border=(0, 0)\n):\n    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(0.1, 0.1), scale=(0.9, 1.1), shear=(-10, 10))\n    # targets = [cls, xyxy]\n    \"\"\"Applies random perspective transformation to an image, modifying the image and corresponding labels.\"\"\"\n    height = im.shape[0] + border[0] * 2  # shape(h,w,c)\n    width = im.shape[1] + border[1] * 2\n    # Center\n    C = np.eye(3)",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "copy_paste",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def copy_paste(im, labels, segments, p=0.5):\n    \"\"\"\n    Applies Copy-Paste augmentation by flipping and merging segments and labels on an image.\n    Details at https://arxiv.org/abs/2012.07177.\n    \"\"\"\n    n = len(segments)\n    if p and n:\n        h, w, c = im.shape  # height, width, channels\n        im_new = np.zeros(im.shape, np.uint8)\n        for j in random.sample(range(n), k=round(p * n)):",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "cutout",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def cutout(im, labels, p=0.5):\n    \"\"\"\n    Applies cutout augmentation to an image with optional label adjustment, using random masks of varying sizes.\n    Details at https://arxiv.org/abs/1708.04552.\n    \"\"\"\n    if random.random() < p:\n        h, w = im.shape[:2]\n        scales = [0.5] * 1 + [0.25] * 2 + [0.125] * 4 + [0.0625] * 8 + [0.03125] * 16  # image size fraction\n        for s in scales:\n            mask_h = random.randint(1, int(h * s))  # create random masks",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "mixup",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def mixup(im, labels, im2, labels2):\n    \"\"\"\n    Applies MixUp augmentation by blending images and labels.\n    See https://arxiv.org/pdf/1710.09412.pdf for details.\n    \"\"\"\n    r = np.random.beta(32.0, 32.0)  # mixup ratio, alpha=beta=32.0\n    im = (im * r + im2 * (1 - r)).astype(np.uint8)\n    labels = np.concatenate((labels, labels2), 0)\n    return im, labels\ndef box_candidates(box1, box2, wh_thr=2, ar_thr=100, area_thr=0.1, eps=1e-16):",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "box_candidates",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def box_candidates(box1, box2, wh_thr=2, ar_thr=100, area_thr=0.1, eps=1e-16):\n    \"\"\"\n    Filters bounding box candidates by minimum width-height threshold `wh_thr` (pixels), aspect ratio threshold\n    `ar_thr`, and area ratio threshold `area_thr`.\n    box1(4,n) is before augmentation, box2(4,n) is after augmentation.\n    \"\"\"\n    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]\n    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]\n    ar = np.maximum(w2 / (h2 + eps), h2 / (w2 + eps))  # aspect ratio\n    return (w2 > wh_thr) & (h2 > wh_thr) & (w2 * h2 / (w1 * h1 + eps) > area_thr) & (ar < ar_thr)  # candidates",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "classify_albumentations",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def classify_albumentations(\n    augment=True,\n    size=224,\n    scale=(0.08, 1.0),\n    ratio=(0.75, 1.0 / 0.75),  # 0.75, 1.33\n    hflip=0.5,\n    vflip=0.0,\n    jitter=0.4,\n    mean=IMAGENET_MEAN,\n    std=IMAGENET_STD,",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "classify_transforms",
        "kind": 2,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "def classify_transforms(size=224):\n    \"\"\"Applies a series of transformations including center crop, ToTensor, and normalization for classification.\"\"\"\n    assert isinstance(size, int), f\"ERROR: classify_transforms size {size} must be integer, not (list, tuple)\"\n    # T.Compose([T.ToTensor(), T.Resize(size), T.CenterCrop(size), T.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\n    return T.Compose([CenterCrop(size), ToTensor(), T.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\nclass LetterBox:\n    \"\"\"Resizes and pads images to specified dimensions while maintaining aspect ratio for YOLOv5 preprocessing.\"\"\"\n    def __init__(self, size=(640, 640), auto=False, stride=32):\n        \"\"\"Initializes a LetterBox object for YOLOv5 image preprocessing with optional auto sizing and stride\n        adjustment.",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "IMAGENET_MEAN",
        "kind": 5,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "IMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean\nIMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\nclass Albumentations:\n    \"\"\"Provides optional data augmentation for YOLOv5 using Albumentations library if installed.\"\"\"\n    def __init__(self, size=640):\n        \"\"\"Initializes Albumentations class for optional data augmentation in YOLOv5 with specified input size.\"\"\"\n        self.transform = None\n        prefix = colorstr(\"albumentations: \")\n        try:\n            import albumentations as A",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "IMAGENET_STD",
        "kind": 5,
        "importPath": "yolov5.utils.augmentations",
        "description": "yolov5.utils.augmentations",
        "peekOfCode": "IMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\nclass Albumentations:\n    \"\"\"Provides optional data augmentation for YOLOv5 using Albumentations library if installed.\"\"\"\n    def __init__(self, size=640):\n        \"\"\"Initializes Albumentations class for optional data augmentation in YOLOv5 with specified input size.\"\"\"\n        self.transform = None\n        prefix = colorstr(\"albumentations: \")\n        try:\n            import albumentations as A\n            check_version(A.__version__, \"1.0.3\", hard=True)  # version requirement",
        "detail": "yolov5.utils.augmentations",
        "documentation": {}
    },
    {
        "label": "check_anchor_order",
        "kind": 2,
        "importPath": "yolov5.utils.autoanchor",
        "description": "yolov5.utils.autoanchor",
        "peekOfCode": "def check_anchor_order(m):\n    \"\"\"Checks and corrects anchor order against stride in YOLOv5 Detect() module if necessary.\"\"\"\n    a = m.anchors.prod(-1).mean(-1).view(-1)  # mean anchor area per output layer\n    da = a[-1] - a[0]  # delta a\n    ds = m.stride[-1] - m.stride[0]  # delta s\n    if da and (da.sign() != ds.sign()):  # same order\n        LOGGER.info(f\"{PREFIX}Reversing anchor order\")\n        m.anchors[:] = m.anchors.flip(0)\n@TryExcept(f\"{PREFIX}ERROR\")\ndef check_anchors(dataset, model, thr=4.0, imgsz=640):",
        "detail": "yolov5.utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "check_anchors",
        "kind": 2,
        "importPath": "yolov5.utils.autoanchor",
        "description": "yolov5.utils.autoanchor",
        "peekOfCode": "def check_anchors(dataset, model, thr=4.0, imgsz=640):\n    \"\"\"Evaluates anchor fit to dataset and adjusts if necessary, supporting customizable threshold and image size.\"\"\"\n    m = model.module.model[-1] if hasattr(model, \"module\") else model.model[-1]  # Detect()\n    shapes = imgsz * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n    scale = np.random.uniform(0.9, 1.1, size=(shapes.shape[0], 1))  # augment scale\n    wh = torch.tensor(np.concatenate([l[:, 3:5] * s for s, l in zip(shapes * scale, dataset.labels)])).float()  # wh\n    def metric(k):  # compute metric\n        \"\"\"Computes ratio metric, anchors above threshold, and best possible recall for YOLOv5 anchor evaluation.\"\"\"\n        r = wh[:, None] / k[None]\n        x = torch.min(r, 1 / r).min(2)[0]  # ratio metric",
        "detail": "yolov5.utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "kmean_anchors",
        "kind": 2,
        "importPath": "yolov5.utils.autoanchor",
        "description": "yolov5.utils.autoanchor",
        "peekOfCode": "def kmean_anchors(dataset=\"./data/coco128.yaml\", n=9, img_size=640, thr=4.0, gen=1000, verbose=True):\n    \"\"\"\n    Creates kmeans-evolved anchors from training dataset.\n    Arguments:\n        dataset: path to data.yaml, or a loaded dataset\n        n: number of anchors\n        img_size: image size used for training\n        thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0\n        gen: generations to evolve anchors using genetic algorithm\n        verbose: print all results",
        "detail": "yolov5.utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "PREFIX",
        "kind": 5,
        "importPath": "yolov5.utils.autoanchor",
        "description": "yolov5.utils.autoanchor",
        "peekOfCode": "PREFIX = colorstr(\"AutoAnchor: \")\ndef check_anchor_order(m):\n    \"\"\"Checks and corrects anchor order against stride in YOLOv5 Detect() module if necessary.\"\"\"\n    a = m.anchors.prod(-1).mean(-1).view(-1)  # mean anchor area per output layer\n    da = a[-1] - a[0]  # delta a\n    ds = m.stride[-1] - m.stride[0]  # delta s\n    if da and (da.sign() != ds.sign()):  # same order\n        LOGGER.info(f\"{PREFIX}Reversing anchor order\")\n        m.anchors[:] = m.anchors.flip(0)\n@TryExcept(f\"{PREFIX}ERROR\")",
        "detail": "yolov5.utils.autoanchor",
        "documentation": {}
    },
    {
        "label": "check_train_batch_size",
        "kind": 2,
        "importPath": "yolov5.utils.autobatch",
        "description": "yolov5.utils.autobatch",
        "peekOfCode": "def check_train_batch_size(model, imgsz=640, amp=True):\n    \"\"\"Checks and computes optimal training batch size for YOLOv5 model, given image size and AMP setting.\"\"\"\n    with torch.cuda.amp.autocast(amp):\n        return autobatch(deepcopy(model).train(), imgsz)  # compute optimal batch size\ndef autobatch(model, imgsz=640, fraction=0.8, batch_size=16):\n    \"\"\"Estimates optimal YOLOv5 batch size using `fraction` of CUDA memory.\"\"\"\n    # Usage:\n    #     import torch\n    #     from utils.autobatch import autobatch\n    #     model = torch.hub.load('ultralytics/yolov5', 'yolov5s', autoshape=False)",
        "detail": "yolov5.utils.autobatch",
        "documentation": {}
    },
    {
        "label": "autobatch",
        "kind": 2,
        "importPath": "yolov5.utils.autobatch",
        "description": "yolov5.utils.autobatch",
        "peekOfCode": "def autobatch(model, imgsz=640, fraction=0.8, batch_size=16):\n    \"\"\"Estimates optimal YOLOv5 batch size using `fraction` of CUDA memory.\"\"\"\n    # Usage:\n    #     import torch\n    #     from utils.autobatch import autobatch\n    #     model = torch.hub.load('ultralytics/yolov5', 'yolov5s', autoshape=False)\n    #     print(autobatch(model))\n    # Check device\n    prefix = colorstr(\"AutoBatch: \")\n    LOGGER.info(f\"{prefix}Computing optimal batch size for --imgsz {imgsz}\")",
        "detail": "yolov5.utils.autobatch",
        "documentation": {}
    },
    {
        "label": "Callbacks",
        "kind": 6,
        "importPath": "yolov5.utils.callbacks",
        "description": "yolov5.utils.callbacks",
        "peekOfCode": "class Callbacks:\n    \"\"\"Handles all registered callbacks for YOLOv5 Hooks.\"\"\"\n    def __init__(self):\n        \"\"\"Initializes a Callbacks object to manage registered YOLOv5 training event hooks.\"\"\"\n        self._callbacks = {\n            \"on_pretrain_routine_start\": [],\n            \"on_pretrain_routine_end\": [],\n            \"on_train_start\": [],\n            \"on_train_epoch_start\": [],\n            \"on_train_batch_start\": [],",
        "detail": "yolov5.utils.callbacks",
        "documentation": {}
    },
    {
        "label": "SmartDistributedSampler",
        "kind": 6,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "class SmartDistributedSampler(distributed.DistributedSampler):\n    \"\"\"A distributed sampler ensuring deterministic shuffling and balanced data distribution across GPUs.\"\"\"\n    def __iter__(self):\n        \"\"\"Yields indices for distributed data sampling, shuffled deterministically based on epoch and seed.\"\"\"\n        g = torch.Generator()\n        g.manual_seed(self.seed + self.epoch)\n        # determine the eventual size (n) of self.indices (DDP indices)\n        n = int((len(self.dataset) - self.rank - 1) / self.num_replicas) + 1  # num_replicas == WORLD_SIZE\n        idx = torch.randperm(n, generator=g)\n        if not self.shuffle:",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "InfiniteDataLoader",
        "kind": 6,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "class InfiniteDataLoader(dataloader.DataLoader):\n    \"\"\"\n    Dataloader that reuses workers.\n    Uses same syntax as vanilla DataLoader\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        \"\"\"Initializes an InfiniteDataLoader that reuses workers with standard DataLoader syntax, augmenting with a\n        repeating sampler.\n        \"\"\"\n        super().__init__(*args, **kwargs)",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "_RepeatSampler",
        "kind": 6,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "class _RepeatSampler:\n    \"\"\"\n    Sampler that repeats forever.\n    Args:\n        sampler (Sampler)\n    \"\"\"\n    def __init__(self, sampler):\n        \"\"\"Initializes a perpetual sampler wrapping a provided `Sampler` instance for endless data iteration.\"\"\"\n        self.sampler = sampler\n    def __iter__(self):",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadScreenshots",
        "kind": 6,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "class LoadScreenshots:\n    \"\"\"Loads and processes screenshots for YOLOv5 detection from specified screen regions using mss.\"\"\"\n    def __init__(self, source, img_size=640, stride=32, auto=True, transforms=None):\n        \"\"\"\n        Initializes a screenshot dataloader for YOLOv5 with specified source region, image size, stride, auto, and\n        transforms.\n        Source = [screen_number left top width height] (pixels)\n        \"\"\"\n        check_requirements(\"mss\")\n        import mss",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "kind": 6,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "class LoadImages:\n    \"\"\"YOLOv5 image/video dataloader, i.e. `python detect.py --source image.jpg/vid.mp4`.\"\"\"\n    def __init__(self, path, img_size=640, stride=32, auto=True, transforms=None, vid_stride=1):\n        \"\"\"Initializes YOLOv5 loader for images/videos, supporting glob patterns, directories, and lists of paths.\"\"\"\n        if isinstance(path, str) and Path(path).suffix == \".txt\":  # *.txt file with img/vid/dir on each line\n            path = Path(path).read_text().rsplit()\n        files = []\n        for p in sorted(path) if isinstance(path, (list, tuple)) else [path]:\n            p = str(Path(p).resolve())\n            if \"*\" in p:",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "kind": 6,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "class LoadStreams:\n    \"\"\"Loads and processes video streams for YOLOv5, supporting various sources including YouTube and IP cameras.\"\"\"\n    def __init__(self, sources=\"file.streams\", img_size=640, stride=32, auto=True, transforms=None, vid_stride=1):\n        \"\"\"Initializes a stream loader for processing video streams with YOLOv5, supporting various sources including\n        YouTube.\n        \"\"\"\n        torch.backends.cudnn.benchmark = True  # faster for fixed-size inference\n        self.mode = \"stream\"\n        self.img_size = img_size\n        self.stride = stride",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LoadImagesAndLabels",
        "kind": 6,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "class LoadImagesAndLabels(Dataset):\n    \"\"\"Loads images and their corresponding labels for training and validation in YOLOv5.\"\"\"\n    cache_version = 0.6  # dataset labels *.cache version\n    rand_interp_methods = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4]\n    def __init__(\n        self,\n        path,\n        img_size=640,\n        batch_size=16,\n        augment=False,",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "HUBDatasetStats",
        "kind": 6,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "class HUBDatasetStats:\n    \"\"\"\n    Class for generating HUB dataset JSON and `-hub` dataset directory.\n    Arguments:\n        path:           Path to data.yaml or data.zip (with data.yaml inside data.zip)\n        autodownload:   Attempt to download dataset if not found locally\n    Usage\n        from utils.dataloaders import HUBDatasetStats\n        stats = HUBDatasetStats('coco128.yaml', autodownload=True)  # usage 1\n        stats = HUBDatasetStats('path/to/coco128.zip')  # usage 2",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "ClassificationDataset",
        "kind": 6,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "class ClassificationDataset(torchvision.datasets.ImageFolder):\n    \"\"\"\n    YOLOv5 Classification Dataset.\n    Arguments:\n        root:  Dataset path\n        transform:  torchvision transforms, used by default\n        album_transform: Albumentations transforms, used if installed\n    \"\"\"\n    def __init__(self, root, augment, imgsz, cache=False):\n        \"\"\"Initializes YOLOv5 Classification Dataset with optional caching, augmentations, and transforms for image",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "get_hash",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def get_hash(paths):\n    \"\"\"Generates a single SHA256 hash for a list of file or directory paths by combining their sizes and paths.\"\"\"\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.sha256(str(size).encode())  # hash sizes\n    h.update(\"\".join(paths).encode())  # hash paths\n    return h.hexdigest()  # return hash\ndef exif_size(img):\n    \"\"\"Returns corrected PIL image size (width, height) considering EXIF orientation.\"\"\"\n    s = img.size  # (width, height)\n    with contextlib.suppress(Exception):",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "exif_size",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def exif_size(img):\n    \"\"\"Returns corrected PIL image size (width, height) considering EXIF orientation.\"\"\"\n    s = img.size  # (width, height)\n    with contextlib.suppress(Exception):\n        rotation = dict(img._getexif().items())[orientation]\n        if rotation in [6, 8]:  # rotation 270 or 90\n            s = (s[1], s[0])\n    return s\ndef exif_transpose(image):\n    \"\"\"",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "exif_transpose",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def exif_transpose(image):\n    \"\"\"\n    Transpose a PIL image accordingly if it has an EXIF Orientation tag.\n    Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose().\n    :param image: The image to transpose.\n    :return: An image.\n    \"\"\"\n    exif = image.getexif()\n    orientation = exif.get(0x0112, 1)  # default 1\n    if orientation > 1:",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "seed_worker",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def seed_worker(worker_id):\n    \"\"\"\n    Sets the seed for a dataloader worker to ensure reproducibility, based on PyTorch's randomness notes.\n    See https://pytorch.org/docs/stable/notes/randomness.html#dataloader.\n    \"\"\"\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n# Inherit from DistributedSampler and override iterator\n# https://github.com/pytorch/pytorch/blob/master/torch/utils/data/distributed.py",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def create_dataloader(\n    path,\n    imgsz,\n    batch_size,\n    stride,\n    single_cls=False,\n    hyp=None,\n    augment=False,\n    cache=False,\n    pad=0.0,",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "img2label_paths",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def img2label_paths(img_paths):\n    \"\"\"Generates label file paths from corresponding image file paths by replacing `/images/` with `/labels/` and\n    extension with `.txt`.\n    \"\"\"\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]\nclass LoadImagesAndLabels(Dataset):\n    \"\"\"Loads images and their corresponding labels for training and validation in YOLOv5.\"\"\"\n    cache_version = 0.6  # dataset labels *.cache version\n    rand_interp_methods = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4]",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "flatten_recursive",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def flatten_recursive(path=DATASETS_DIR / \"coco128\"):\n    \"\"\"Flattens a directory by copying all files from subdirectories to a new top-level directory, preserving\n    filenames.\n    \"\"\"\n    new_path = Path(f\"{str(path)}_flat\")\n    if os.path.exists(new_path):\n        shutil.rmtree(new_path)  # delete output folder\n    os.makedirs(new_path)  # make new output folder\n    for file in tqdm(glob.glob(f\"{str(Path(path))}/**/*.*\", recursive=True)):\n        shutil.copyfile(file, new_path / Path(file).name)",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "extract_boxes",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def extract_boxes(path=DATASETS_DIR / \"coco128\"):\n    \"\"\"\n    Converts a detection dataset to a classification dataset, creating a directory for each class and extracting\n    bounding boxes.\n    Example: from utils.dataloaders import *; extract_boxes()\n    \"\"\"\n    path = Path(path)  # images dir\n    shutil.rmtree(path / \"classification\") if (path / \"classification\").is_dir() else None  # remove existing\n    files = list(path.rglob(\"*.*\"))\n    n = len(files)  # number of files",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "autosplit",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def autosplit(path=DATASETS_DIR / \"coco128/images\", weights=(0.9, 0.1, 0.0), annotated_only=False):\n    \"\"\"Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files\n    Usage: from utils.dataloaders import *; autosplit().\n    Arguments:\n        path:            Path to images directory\n        weights:         Train, val, test weights (list, tuple)\n        annotated_only:  Only use images with an annotated txt file\n    \"\"\"\n    path = Path(path)  # images dir\n    files = sorted(x for x in path.rglob(\"*.*\") if x.suffix[1:].lower() in IMG_FORMATS)  # image files only",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "verify_image_label",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def verify_image_label(args):\n    \"\"\"Verifies a single image-label pair, ensuring image format, size, and legal label values.\"\"\"\n    im_file, lb_file, prefix = args\n    nm, nf, ne, nc, msg, segments = 0, 0, 0, 0, \"\", []  # number (missing, found, empty, corrupt), message, segments\n    try:\n        # verify images\n        im = Image.open(im_file)\n        im.verify()  # PIL verify\n        shape = exif_size(im)  # image size\n        assert (shape[0] > 9) & (shape[1] > 9), f\"image size {shape} <10 pixels\"",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "create_classification_dataloader",
        "kind": 2,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "def create_classification_dataloader(\n    path, imgsz=224, batch_size=16, augment=True, cache=False, rank=-1, workers=8, shuffle=True\n):\n    # Returns Dataloader object to be used with YOLOv5 Classifier\n    \"\"\"Creates a DataLoader for image classification, supporting caching, augmentation, and distributed training.\"\"\"\n    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP\n        dataset = ClassificationDataset(root=path, imgsz=imgsz, augment=augment, cache=cache)\n    batch_size = min(batch_size, len(dataset))\n    nd = torch.cuda.device_count()\n    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "HELP_URL",
        "kind": 5,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "HELP_URL = \"See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data\"\nIMG_FORMATS = \"bmp\", \"dng\", \"jpeg\", \"jpg\", \"mpo\", \"png\", \"tif\", \"tiff\", \"webp\", \"pfm\"  # include image suffixes\nVID_FORMATS = \"asf\", \"avi\", \"gif\", \"m4v\", \"mkv\", \"mov\", \"mp4\", \"mpeg\", \"mpg\", \"ts\", \"wmv\"  # include video suffixes\nLOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "kind": 5,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "IMG_FORMATS = \"bmp\", \"dng\", \"jpeg\", \"jpg\", \"mpo\", \"png\", \"tif\", \"tiff\", \"webp\", \"pfm\"  # include image suffixes\nVID_FORMATS = \"asf\", \"avi\", \"gif\", \"m4v\", \"mkv\", \"mov\", \"mp4\", \"mpeg\", \"mpg\", \"ts\", \"wmv\"  # include video suffixes\nLOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "kind": 5,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "VID_FORMATS = \"asf\", \"avi\", \"gif\", \"m4v\", \"mkv\", \"mov\", \"mp4\", \"mpeg\", \"mpg\", \"ts\", \"wmv\"  # include video suffixes\nLOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef get_hash(paths):",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "kind": 5,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "LOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef get_hash(paths):\n    \"\"\"Generates a single SHA256 hash for a list of file or directory paths by combining their sizes and paths.\"\"\"",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "RANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef get_hash(paths):\n    \"\"\"Generates a single SHA256 hash for a list of file or directory paths by combining their sizes and paths.\"\"\"\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "WORLD_SIZE",
        "kind": 5,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "WORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef get_hash(paths):\n    \"\"\"Generates a single SHA256 hash for a list of file or directory paths by combining their sizes and paths.\"\"\"\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.sha256(str(size).encode())  # hash sizes",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "PIN_MEMORY",
        "kind": 5,
        "importPath": "yolov5.utils.dataloaders",
        "description": "yolov5.utils.dataloaders",
        "peekOfCode": "PIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef get_hash(paths):\n    \"\"\"Generates a single SHA256 hash for a list of file or directory paths by combining their sizes and paths.\"\"\"\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.sha256(str(size).encode())  # hash sizes\n    h.update(\"\".join(paths).encode())  # hash paths",
        "detail": "yolov5.utils.dataloaders",
        "documentation": {}
    },
    {
        "label": "is_url",
        "kind": 2,
        "importPath": "yolov5.utils.downloads",
        "description": "yolov5.utils.downloads",
        "peekOfCode": "def is_url(url, check=True):\n    \"\"\"Determines if a string is a URL and optionally checks its existence online, returning a boolean.\"\"\"\n    try:\n        url = str(url)\n        result = urllib.parse.urlparse(url)\n        assert all([result.scheme, result.netloc])  # check if is url\n        return (urllib.request.urlopen(url).getcode() == 200) if check else True  # check if exists online\n    except (AssertionError, urllib.request.HTTPError):\n        return False\ndef gsutil_getsize(url=\"\"):",
        "detail": "yolov5.utils.downloads",
        "documentation": {}
    },
    {
        "label": "gsutil_getsize",
        "kind": 2,
        "importPath": "yolov5.utils.downloads",
        "description": "yolov5.utils.downloads",
        "peekOfCode": "def gsutil_getsize(url=\"\"):\n    \"\"\"\n    Returns the size in bytes of a file at a Google Cloud Storage URL using `gsutil du`.\n    Returns 0 if the command fails or output is empty.\n    \"\"\"\n    output = subprocess.check_output([\"gsutil\", \"du\", url], shell=True, encoding=\"utf-8\")\n    return int(output.split()[0]) if output else 0\ndef url_getsize(url=\"https://ultralytics.com/images/bus.jpg\"):\n    \"\"\"Returns the size in bytes of a downloadable file at a given URL; defaults to -1 if not found.\"\"\"\n    response = requests.head(url, allow_redirects=True)",
        "detail": "yolov5.utils.downloads",
        "documentation": {}
    },
    {
        "label": "url_getsize",
        "kind": 2,
        "importPath": "yolov5.utils.downloads",
        "description": "yolov5.utils.downloads",
        "peekOfCode": "def url_getsize(url=\"https://ultralytics.com/images/bus.jpg\"):\n    \"\"\"Returns the size in bytes of a downloadable file at a given URL; defaults to -1 if not found.\"\"\"\n    response = requests.head(url, allow_redirects=True)\n    return int(response.headers.get(\"content-length\", -1))\ndef curl_download(url, filename, *, silent: bool = False) -> bool:\n    \"\"\"Download a file from a url to a filename using curl.\"\"\"\n    silent_option = \"sS\" if silent else \"\"  # silent\n    proc = subprocess.run(\n        [\n            \"curl\",",
        "detail": "yolov5.utils.downloads",
        "documentation": {}
    },
    {
        "label": "curl_download",
        "kind": 2,
        "importPath": "yolov5.utils.downloads",
        "description": "yolov5.utils.downloads",
        "peekOfCode": "def curl_download(url, filename, *, silent: bool = False) -> bool:\n    \"\"\"Download a file from a url to a filename using curl.\"\"\"\n    silent_option = \"sS\" if silent else \"\"  # silent\n    proc = subprocess.run(\n        [\n            \"curl\",\n            \"-#\",\n            f\"-{silent_option}L\",\n            url,\n            \"--output\",",
        "detail": "yolov5.utils.downloads",
        "documentation": {}
    },
    {
        "label": "safe_download",
        "kind": 2,
        "importPath": "yolov5.utils.downloads",
        "description": "yolov5.utils.downloads",
        "peekOfCode": "def safe_download(file, url, url2=None, min_bytes=1e0, error_msg=\"\"):\n    \"\"\"\n    Downloads a file from a URL (or alternate URL) to a specified path if file is above a minimum size.\n    Removes incomplete downloads.\n    \"\"\"\n    from utils.general import LOGGER\n    file = Path(file)\n    assert_msg = f\"Downloaded file '{file}' does not exist or size is < min_bytes={min_bytes}\"\n    try:  # url1\n        LOGGER.info(f\"Downloading {url} to {file}...\")",
        "detail": "yolov5.utils.downloads",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "kind": 2,
        "importPath": "yolov5.utils.downloads",
        "description": "yolov5.utils.downloads",
        "peekOfCode": "def attempt_download(file, repo=\"ultralytics/yolov5\", release=\"v7.0\"):\n    \"\"\"Downloads a file from GitHub release assets or via direct URL if not found locally, supporting backup\n    versions.\n    \"\"\"\n    from utils.general import LOGGER\n    def github_assets(repository, version=\"latest\"):\n        \"\"\"Fetches GitHub repository release tag and asset names using the GitHub API.\"\"\"\n        if version != \"latest\":\n            version = f\"tags/{version}\"  # i.e. tags/v7.0\n        response = requests.get(f\"https://api.github.com/repos/{repository}/releases/{version}\").json()  # github api",
        "detail": "yolov5.utils.downloads",
        "documentation": {}
    },
    {
        "label": "Profile",
        "kind": 6,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "class Profile(contextlib.ContextDecorator):\n    \"\"\"Context manager and decorator for profiling code execution time, with optional CUDA synchronization.\"\"\"\n    def __init__(self, t=0.0, device: torch.device = None):\n        \"\"\"Initializes a profiling context for YOLOv5 with optional timing threshold and device specification.\"\"\"\n        self.t = t\n        self.device = device\n        self.cuda = bool(device and str(device).startswith(\"cuda\"))\n    def __enter__(self):\n        \"\"\"Initializes timing at the start of a profiling context block for performance measurement.\"\"\"\n        self.start = self.time()",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "Timeout",
        "kind": 6,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "class Timeout(contextlib.ContextDecorator):\n    \"\"\"Enforces a timeout on code execution, raising TimeoutError if the specified duration is exceeded.\"\"\"\n    def __init__(self, seconds, *, timeout_msg=\"\", suppress_timeout_errors=True):\n        \"\"\"Initializes a timeout context/decorator with defined seconds, optional message, and error suppression.\"\"\"\n        self.seconds = int(seconds)\n        self.timeout_message = timeout_msg\n        self.suppress = bool(suppress_timeout_errors)\n    def _timeout_handler(self, signum, frame):\n        \"\"\"Raises a TimeoutError with a custom message when a timeout event occurs.\"\"\"\n        raise TimeoutError(self.timeout_message)",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "WorkingDirectory",
        "kind": 6,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "class WorkingDirectory(contextlib.ContextDecorator):\n    \"\"\"Context manager/decorator to temporarily change the working directory within a 'with' statement or decorator.\"\"\"\n    def __init__(self, new_dir):\n        \"\"\"Initializes a context manager/decorator to temporarily change the working directory.\"\"\"\n        self.dir = new_dir  # new dir\n        self.cwd = Path.cwd().resolve()  # current dir\n    def __enter__(self):\n        \"\"\"Temporarily changes the working directory within a 'with' statement context.\"\"\"\n        os.chdir(self.dir)\n    def __exit__(self, exc_type, exc_val, exc_tb):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "is_ascii",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def is_ascii(s=\"\"):\n    \"\"\"Checks if input string `s` contains only ASCII characters; returns `True` if so, otherwise `False`.\"\"\"\n    s = str(s)  # convert list, tuple, None, etc. to str\n    return len(s.encode().decode(\"ascii\", \"ignore\")) == len(s)\ndef is_chinese(s=\"\"):\n    \"\"\"Determines if a string `s` contains any Chinese characters; returns `True` if so, otherwise `False`.\"\"\"\n    return bool(re.search(\"[\\u4e00-\\u9fff]\", str(s)))\ndef is_colab():\n    \"\"\"Checks if the current environment is a Google Colab instance; returns `True` for Colab, otherwise `False`.\"\"\"\n    return \"google.colab\" in sys.modules",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "is_chinese",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def is_chinese(s=\"\"):\n    \"\"\"Determines if a string `s` contains any Chinese characters; returns `True` if so, otherwise `False`.\"\"\"\n    return bool(re.search(\"[\\u4e00-\\u9fff]\", str(s)))\ndef is_colab():\n    \"\"\"Checks if the current environment is a Google Colab instance; returns `True` for Colab, otherwise `False`.\"\"\"\n    return \"google.colab\" in sys.modules\ndef is_jupyter():\n    \"\"\"\n    Check if the current script is running inside a Jupyter Notebook. Verified on Colab, Jupyterlab, Kaggle, Paperspace.\n    Returns:",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "is_colab",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def is_colab():\n    \"\"\"Checks if the current environment is a Google Colab instance; returns `True` for Colab, otherwise `False`.\"\"\"\n    return \"google.colab\" in sys.modules\ndef is_jupyter():\n    \"\"\"\n    Check if the current script is running inside a Jupyter Notebook. Verified on Colab, Jupyterlab, Kaggle, Paperspace.\n    Returns:\n        bool: True if running inside a Jupyter Notebook, False otherwise.\n    \"\"\"\n    with contextlib.suppress(Exception):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "is_jupyter",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def is_jupyter():\n    \"\"\"\n    Check if the current script is running inside a Jupyter Notebook. Verified on Colab, Jupyterlab, Kaggle, Paperspace.\n    Returns:\n        bool: True if running inside a Jupyter Notebook, False otherwise.\n    \"\"\"\n    with contextlib.suppress(Exception):\n        from IPython import get_ipython\n        return get_ipython() is not None\n    return False",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "is_kaggle",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def is_kaggle():\n    \"\"\"Checks if the current environment is a Kaggle Notebook by validating environment variables.\"\"\"\n    return os.environ.get(\"PWD\") == \"/kaggle/working\" and os.environ.get(\"KAGGLE_URL_BASE\") == \"https://www.kaggle.com\"\ndef is_docker() -> bool:\n    \"\"\"Check if the process runs inside a docker container.\"\"\"\n    if Path(\"/.dockerenv\").exists():\n        return True\n    try:  # check if docker is in control groups\n        with open(\"/proc/self/cgroup\") as file:\n            return any(\"docker\" in line for line in file)",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "is_docker",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def is_docker() -> bool:\n    \"\"\"Check if the process runs inside a docker container.\"\"\"\n    if Path(\"/.dockerenv\").exists():\n        return True\n    try:  # check if docker is in control groups\n        with open(\"/proc/self/cgroup\") as file:\n            return any(\"docker\" in line for line in file)\n    except OSError:\n        return False\ndef is_writeable(dir, test=False):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "is_writeable",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def is_writeable(dir, test=False):\n    \"\"\"Checks if a directory is writable, optionally testing by creating a temporary file if `test=True`.\"\"\"\n    if not test:\n        return os.access(dir, os.W_OK)  # possible issues on Windows\n    file = Path(dir) / \"tmp.txt\"\n    try:\n        with open(file, \"w\"):  # open file with write permissions\n            pass\n        file.unlink()  # remove file\n        return True",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "set_logging",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def set_logging(name=LOGGING_NAME, verbose=True):\n    \"\"\"Configures logging with specified verbosity; `name` sets the logger's name, `verbose` controls logging level.\"\"\"\n    rank = int(os.getenv(\"RANK\", -1))  # rank in world for Multi-GPU trainings\n    level = logging.INFO if verbose and rank in {-1, 0} else logging.ERROR\n    logging.config.dictConfig(\n        {\n            \"version\": 1,\n            \"disable_existing_loggers\": False,\n            \"formatters\": {name: {\"format\": \"%(message)s\"}},\n            \"handlers\": {",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "user_config_dir",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def user_config_dir(dir=\"Ultralytics\", env_var=\"YOLOV5_CONFIG_DIR\"):\n    \"\"\"Returns user configuration directory path, preferring environment variable `YOLOV5_CONFIG_DIR` if set, else OS-\n    specific.\n    \"\"\"\n    if env := os.getenv(env_var):\n        path = Path(env)  # use environment variable\n    else:\n        cfg = {\"Windows\": \"AppData/Roaming\", \"Linux\": \".config\", \"Darwin\": \"Library/Application Support\"}  # 3 OS dirs\n        path = Path.home() / cfg.get(platform.system(), \"\")  # OS-specific config dir\n        path = (path if is_writeable(path) else Path(\"/tmp\")) / dir  # GCP and AWS lambda fix, only /tmp is writeable",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "methods",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def methods(instance):\n    \"\"\"Returns list of method names for a class/instance excluding dunder methods.\"\"\"\n    return [f for f in dir(instance) if callable(getattr(instance, f)) and not f.startswith(\"__\")]\ndef print_args(args: Optional[dict] = None, show_file=True, show_func=False):\n    \"\"\"Logs the arguments of the calling function, with options to include the filename and function name.\"\"\"\n    x = inspect.currentframe().f_back  # previous frame\n    file, _, func, _, _ = inspect.getframeinfo(x)\n    if args is None:  # get args automatically\n        args, _, _, frm = inspect.getargvalues(x)\n        args = {k: v for k, v in frm.items() if k in args}",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "print_args",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def print_args(args: Optional[dict] = None, show_file=True, show_func=False):\n    \"\"\"Logs the arguments of the calling function, with options to include the filename and function name.\"\"\"\n    x = inspect.currentframe().f_back  # previous frame\n    file, _, func, _, _ = inspect.getframeinfo(x)\n    if args is None:  # get args automatically\n        args, _, _, frm = inspect.getargvalues(x)\n        args = {k: v for k, v in frm.items() if k in args}\n    try:\n        file = Path(file).resolve().relative_to(ROOT).with_suffix(\"\")\n    except ValueError:",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def init_seeds(seed=0, deterministic=False):\n    \"\"\"\n    Initializes RNG seeds and sets deterministic options if specified.\n    See https://pytorch.org/docs/stable/notes/randomness.html\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # for Multi-GPU, exception safe",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def intersect_dicts(da, db, exclude=()):\n    \"\"\"Returns intersection of `da` and `db` dicts with matching keys and shapes, excluding `exclude` keys; uses `da`\n    values.\n    \"\"\"\n    return {k: v for k, v in da.items() if k in db and all(x not in k for x in exclude) and v.shape == db[k].shape}\ndef get_default_args(func):\n    \"\"\"Returns a dict of `func` default arguments by inspecting its signature.\"\"\"\n    signature = inspect.signature(func)\n    return {k: v.default for k, v in signature.parameters.items() if v.default is not inspect.Parameter.empty}\ndef get_latest_run(search_dir=\".\"):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "get_default_args",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def get_default_args(func):\n    \"\"\"Returns a dict of `func` default arguments by inspecting its signature.\"\"\"\n    signature = inspect.signature(func)\n    return {k: v.default for k, v in signature.parameters.items() if v.default is not inspect.Parameter.empty}\ndef get_latest_run(search_dir=\".\"):\n    \"\"\"Returns the path to the most recent 'last.pt' file in /runs to resume from, searches in `search_dir`.\"\"\"\n    last_list = glob.glob(f\"{search_dir}/**/last*.pt\", recursive=True)\n    return max(last_list, key=os.path.getctime) if last_list else \"\"\ndef file_age(path=__file__):\n    \"\"\"Calculates and returns the age of a file in days based on its last modification time.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "get_latest_run",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def get_latest_run(search_dir=\".\"):\n    \"\"\"Returns the path to the most recent 'last.pt' file in /runs to resume from, searches in `search_dir`.\"\"\"\n    last_list = glob.glob(f\"{search_dir}/**/last*.pt\", recursive=True)\n    return max(last_list, key=os.path.getctime) if last_list else \"\"\ndef file_age(path=__file__):\n    \"\"\"Calculates and returns the age of a file in days based on its last modification time.\"\"\"\n    dt = datetime.now() - datetime.fromtimestamp(Path(path).stat().st_mtime)  # delta\n    return dt.days  # + dt.seconds / 86400  # fractional days\ndef file_date(path=__file__):\n    \"\"\"Returns a human-readable file modification date in 'YYYY-M-D' format, given a file path.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "file_age",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def file_age(path=__file__):\n    \"\"\"Calculates and returns the age of a file in days based on its last modification time.\"\"\"\n    dt = datetime.now() - datetime.fromtimestamp(Path(path).stat().st_mtime)  # delta\n    return dt.days  # + dt.seconds / 86400  # fractional days\ndef file_date(path=__file__):\n    \"\"\"Returns a human-readable file modification date in 'YYYY-M-D' format, given a file path.\"\"\"\n    t = datetime.fromtimestamp(Path(path).stat().st_mtime)\n    return f\"{t.year}-{t.month}-{t.day}\"\ndef file_size(path):\n    \"\"\"Returns file or directory size in megabytes (MB) for a given path, where directories are recursively summed.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "file_date",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def file_date(path=__file__):\n    \"\"\"Returns a human-readable file modification date in 'YYYY-M-D' format, given a file path.\"\"\"\n    t = datetime.fromtimestamp(Path(path).stat().st_mtime)\n    return f\"{t.year}-{t.month}-{t.day}\"\ndef file_size(path):\n    \"\"\"Returns file or directory size in megabytes (MB) for a given path, where directories are recursively summed.\"\"\"\n    mb = 1 << 20  # bytes to MiB (1024 ** 2)\n    path = Path(path)\n    if path.is_file():\n        return path.stat().st_size / mb",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "file_size",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def file_size(path):\n    \"\"\"Returns file or directory size in megabytes (MB) for a given path, where directories are recursively summed.\"\"\"\n    mb = 1 << 20  # bytes to MiB (1024 ** 2)\n    path = Path(path)\n    if path.is_file():\n        return path.stat().st_size / mb\n    elif path.is_dir():\n        return sum(f.stat().st_size for f in path.glob(\"**/*\") if f.is_file()) / mb\n    else:\n        return 0.0",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_online",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_online():\n    \"\"\"Checks internet connectivity by attempting to create a connection to \"1.1.1.1\" on port 443, retries once if the\n    first attempt fails.\n    \"\"\"\n    import socket\n    def run_once():\n        \"\"\"Checks internet connectivity by attempting to create a connection to \"1.1.1.1\" on port 443.\"\"\"\n        try:\n            socket.create_connection((\"1.1.1.1\", 443), 5)  # check host accessibility\n            return True",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "git_describe",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def git_describe(path=ROOT):\n    \"\"\"\n    Returns a human-readable git description of the repository at `path`, or an empty string on failure.\n    Example output is 'fv5.0-5-g3e25f1e'. See https://git-scm.com/docs/git-describe.\n    \"\"\"\n    try:\n        assert (Path(path) / \".git\").is_dir()\n        return check_output(f\"git -C {path} describe --tags --long --always\", shell=True).decode()[:-1]\n    except Exception:\n        return \"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_git_status",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_git_status(repo=\"ultralytics/yolov5\", branch=\"master\"):\n    \"\"\"Checks if YOLOv5 code is up-to-date with the repository, advising 'git pull' if behind; errors return informative\n    messages.\n    \"\"\"\n    url = f\"https://github.com/{repo}\"\n    msg = f\", for updates see {url}\"\n    s = colorstr(\"github: \")  # string\n    assert Path(\".git\").exists(), s + \"skipping check (not a git repository)\" + msg\n    assert check_online(), s + \"skipping check (offline)\" + msg\n    splits = re.split(pattern=r\"\\s\", string=check_output(\"git remote -v\", shell=True).decode())",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_git_info",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_git_info(path=\".\"):\n    \"\"\"Checks YOLOv5 git info, returning a dict with remote URL, branch name, and commit hash.\"\"\"\n    check_requirements(\"gitpython\")\n    import git\n    try:\n        repo = git.Repo(path)\n        remote = repo.remotes.origin.url.replace(\".git\", \"\")  # i.e. 'https://github.com/ultralytics/yolov5'\n        commit = repo.head.commit.hexsha  # i.e. '3134699c73af83aac2a481435550b968d5792c0d'\n        try:\n            branch = repo.active_branch.name  # i.e. 'main'",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_python",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_python(minimum=\"3.8.0\"):\n    \"\"\"Checks if current Python version meets the minimum required version, exits if not.\"\"\"\n    check_version(platform.python_version(), minimum, name=\"Python \", hard=True)\ndef check_version(current=\"0.0.0\", minimum=\"0.0.0\", name=\"version \", pinned=False, hard=False, verbose=False):\n    \"\"\"Checks if the current version meets the minimum required version, exits or warns based on parameters.\"\"\"\n    current, minimum = (pkg.parse_version(x) for x in (current, minimum))\n    result = (current == minimum) if pinned else (current >= minimum)  # bool\n    s = f\"WARNING  {name}{minimum} is required by YOLOv5, but {name}{current} is currently installed\"  # string\n    if hard:\n        assert result, emojis(s)  # assert min requirements met",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_version",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_version(current=\"0.0.0\", minimum=\"0.0.0\", name=\"version \", pinned=False, hard=False, verbose=False):\n    \"\"\"Checks if the current version meets the minimum required version, exits or warns based on parameters.\"\"\"\n    current, minimum = (pkg.parse_version(x) for x in (current, minimum))\n    result = (current == minimum) if pinned else (current >= minimum)  # bool\n    s = f\"WARNING  {name}{minimum} is required by YOLOv5, but {name}{current} is currently installed\"  # string\n    if hard:\n        assert result, emojis(s)  # assert min requirements met\n    if verbose and not result:\n        LOGGER.warning(s)\n    return result",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_img_size",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_img_size(imgsz, s=32, floor=0):\n    \"\"\"Adjusts image size to be divisible by stride `s`, supports int or list/tuple input, returns adjusted size.\"\"\"\n    if isinstance(imgsz, int):  # integer i.e. img_size=640\n        new_size = max(make_divisible(imgsz, int(s)), floor)\n    else:  # list i.e. img_size=[640, 480]\n        imgsz = list(imgsz)  # convert to list if tuple\n        new_size = [max(make_divisible(x, int(s)), floor) for x in imgsz]\n    if new_size != imgsz:\n        LOGGER.warning(f\"WARNING  --img-size {imgsz} must be multiple of max stride {s}, updating to {new_size}\")\n    return new_size",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_imshow(warn=False):\n    \"\"\"Checks environment support for image display; warns on failure if `warn=True`.\"\"\"\n    try:\n        assert not is_jupyter()\n        assert not is_docker()\n        cv2.imshow(\"test\", np.zeros((1, 1, 3)))\n        cv2.waitKey(1)\n        cv2.destroyAllWindows()\n        cv2.waitKey(1)\n        return True",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_suffix",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_suffix(file=\"yolov5s.pt\", suffix=(\".pt\",), msg=\"\"):\n    \"\"\"Validates if a file or files have an acceptable suffix, raising an error if not.\"\"\"\n    if file and suffix:\n        if isinstance(suffix, str):\n            suffix = [suffix]\n        for f in file if isinstance(file, (list, tuple)) else [file]:\n            s = Path(f).suffix.lower()  # file suffix\n            if len(s):\n                assert s in suffix, f\"{msg}{f} acceptable suffix is {suffix}\"\ndef check_yaml(file, suffix=(\".yaml\", \".yml\")):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_yaml(file, suffix=(\".yaml\", \".yml\")):\n    \"\"\"Searches/downloads a YAML file, verifies its suffix (.yaml or .yml), and returns the file path.\"\"\"\n    return check_file(file, suffix)\ndef check_file(file, suffix=\"\"):\n    \"\"\"Searches/downloads a file, checks its suffix (if provided), and returns the file path.\"\"\"\n    check_suffix(file, suffix)  # optional\n    file = str(file)  # convert to str()\n    if os.path.isfile(file) or not file:  # exists\n        return file\n    elif file.startswith((\"http:/\", \"https:/\")):  # download",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_file",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_file(file, suffix=\"\"):\n    \"\"\"Searches/downloads a file, checks its suffix (if provided), and returns the file path.\"\"\"\n    check_suffix(file, suffix)  # optional\n    file = str(file)  # convert to str()\n    if os.path.isfile(file) or not file:  # exists\n        return file\n    elif file.startswith((\"http:/\", \"https:/\")):  # download\n        url = file  # warning: Pathlib turns :// -> :/\n        file = Path(urllib.parse.unquote(file).split(\"?\")[0]).name  # '%2F' to '/', split https://url.com/file.txt?auth\n        if os.path.isfile(file):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_font",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_font(font=FONT, progress=False):\n    \"\"\"Ensures specified font exists or downloads it from Ultralytics assets, optionally displaying progress.\"\"\"\n    font = Path(font)\n    file = CONFIG_DIR / font.name\n    if not font.exists() and not file.exists():\n        url = f\"https://github.com/ultralytics/assets/releases/download/v0.0.0/{font.name}\"\n        LOGGER.info(f\"Downloading {url} to {file}...\")\n        torch.hub.download_url_to_file(url, str(file), progress=progress)\ndef check_dataset(data, autodownload=True):\n    \"\"\"Validates and/or auto-downloads a dataset, returning its configuration as a dictionary.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_dataset(data, autodownload=True):\n    \"\"\"Validates and/or auto-downloads a dataset, returning its configuration as a dictionary.\"\"\"\n    # Download (optional)\n    extract_dir = \"\"\n    if isinstance(data, (str, Path)) and (is_zipfile(data) or is_tarfile(data)):\n        download(data, dir=f\"{DATASETS_DIR}/{Path(data).stem}\", unzip=True, delete=False, curl=False, threads=1)\n        data = next((DATASETS_DIR / Path(data).stem).rglob(\"*.yaml\"))\n        extract_dir, autodownload = data.parent, False\n    # Read yaml (optional)\n    if isinstance(data, (str, Path)):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "check_amp",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def check_amp(model):\n    \"\"\"Checks PyTorch AMP functionality for a model, returns True if AMP operates correctly, otherwise False.\"\"\"\n    from models.common import AutoShape, DetectMultiBackend\n    def amp_allclose(model, im):\n        \"\"\"Compares FP32 and AMP model inference outputs, ensuring they are close within a 10% absolute tolerance.\"\"\"\n        m = AutoShape(model, verbose=False)  # model\n        a = m(im).xywhn[0]  # FP32 inference\n        m.amp = True\n        b = m(im).xywhn[0]  # AMP inference\n        return a.shape == b.shape and torch.allclose(a, b, atol=0.1)  # close to 10% absolute tolerance",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def yaml_load(file=\"data.yaml\"):\n    \"\"\"Safely loads and returns the contents of a YAML file specified by `file` argument.\"\"\"\n    with open(file, errors=\"ignore\") as f:\n        return yaml.safe_load(f)\ndef yaml_save(file=\"data.yaml\", data=None):\n    \"\"\"Safely saves `data` to a YAML file specified by `file`, converting `Path` objects to strings; `data` is a\n    dictionary.\n    \"\"\"\n    if data is None:\n        data = {}",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def yaml_save(file=\"data.yaml\", data=None):\n    \"\"\"Safely saves `data` to a YAML file specified by `file`, converting `Path` objects to strings; `data` is a\n    dictionary.\n    \"\"\"\n    if data is None:\n        data = {}\n    with open(file, \"w\") as f:\n        yaml.safe_dump({k: str(v) if isinstance(v, Path) else v for k, v in data.items()}, f, sort_keys=False)\ndef unzip_file(file, path=None, exclude=(\".DS_Store\", \"__MACOSX\")):\n    \"\"\"Unzips `file` to `path` (default: file's parent), excluding filenames containing any in `exclude` (`.DS_Store`,",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "unzip_file",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def unzip_file(file, path=None, exclude=(\".DS_Store\", \"__MACOSX\")):\n    \"\"\"Unzips `file` to `path` (default: file's parent), excluding filenames containing any in `exclude` (`.DS_Store`,\n    `__MACOSX`).\n    \"\"\"\n    if path is None:\n        path = Path(file).parent  # default path\n    with ZipFile(file) as zipObj:\n        for f in zipObj.namelist():  # list all archived filenames in the zip\n            if all(x not in f for x in exclude):\n                zipObj.extract(f, path=path)",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "url2file",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def url2file(url):\n    \"\"\"\n    Converts a URL string to a valid filename by stripping protocol, domain, and any query parameters.\n    Example https://url.com/file.txt?auth -> file.txt\n    \"\"\"\n    url = str(Path(url)).replace(\":/\", \"://\")  # Pathlib turns :// -> :/\n    return Path(urllib.parse.unquote(url)).name.split(\"?\")[0]  # '%2F' to '/', split https://url.com/file.txt?auth\ndef download(url, dir=\".\", unzip=True, delete=True, curl=False, threads=1, retry=3):\n    \"\"\"Downloads and optionally unzips files concurrently, supporting retries and curl fallback.\"\"\"\n    def download_one(url, dir):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "download",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def download(url, dir=\".\", unzip=True, delete=True, curl=False, threads=1, retry=3):\n    \"\"\"Downloads and optionally unzips files concurrently, supporting retries and curl fallback.\"\"\"\n    def download_one(url, dir):\n        \"\"\"Downloads a single file from `url` to `dir`, with retry support and optional curl fallback.\"\"\"\n        success = True\n        if os.path.isfile(url):\n            f = Path(url)  # filename\n        else:  # does not exist\n            f = dir / Path(url).name\n            LOGGER.info(f\"Downloading {url} to {f}...\")",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def make_divisible(x, divisor):\n    \"\"\"Adjusts `x` to be divisible by `divisor`, returning the nearest greater or equal value.\"\"\"\n    if isinstance(divisor, torch.Tensor):\n        divisor = int(divisor.max())  # to int\n    return math.ceil(x / divisor) * divisor\ndef clean_str(s):\n    \"\"\"Cleans a string by replacing special characters with underscore, e.g., `clean_str('#example!')` returns\n    '_example_'.\n    \"\"\"\n    return re.sub(pattern=\"[|@#!$%&()=?^*;:,><+]\", repl=\"_\", string=s)",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "clean_str",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def clean_str(s):\n    \"\"\"Cleans a string by replacing special characters with underscore, e.g., `clean_str('#example!')` returns\n    '_example_'.\n    \"\"\"\n    return re.sub(pattern=\"[|@#!$%&()=?^*;:,><+]\", repl=\"_\", string=s)\ndef one_cycle(y1=0.0, y2=1.0, steps=100):\n    \"\"\"\n    Generates a lambda for a sinusoidal ramp from y1 to y2 over 'steps'.\n    See https://arxiv.org/pdf/1812.01187.pdf for details.\n    \"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "one_cycle",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def one_cycle(y1=0.0, y2=1.0, steps=100):\n    \"\"\"\n    Generates a lambda for a sinusoidal ramp from y1 to y2 over 'steps'.\n    See https://arxiv.org/pdf/1812.01187.pdf for details.\n    \"\"\"\n    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\ndef colorstr(*input):\n    \"\"\"\n    Colors a string using ANSI escape codes, e.g., colorstr('blue', 'hello world').\n    See https://en.wikipedia.org/wiki/ANSI_escape_code.",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def colorstr(*input):\n    \"\"\"\n    Colors a string using ANSI escape codes, e.g., colorstr('blue', 'hello world').\n    See https://en.wikipedia.org/wiki/ANSI_escape_code.\n    \"\"\"\n    *args, string = input if len(input) > 1 else (\"blue\", \"bold\", input[0])  # color arguments, string\n    colors = {\n        \"black\": \"\\033[30m\",  # basic colors\n        \"red\": \"\\033[31m\",\n        \"green\": \"\\033[32m\",",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_class_weights",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def labels_to_class_weights(labels, nc=80):\n    \"\"\"Calculates class weights from labels to handle class imbalance in training; input shape: (n, 5).\"\"\"\n    if labels[0] is None:  # no labels loaded\n        return torch.Tensor()\n    labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) for COCO\n    classes = labels[:, 0].astype(int)  # labels = [class xywh]\n    weights = np.bincount(classes, minlength=nc)  # occurrences per class\n    # Prepend gridpoint count (for uCE training)\n    # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # gridpoints per image\n    # weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # prepend gridpoints to start",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "labels_to_image_weights",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):\n    \"\"\"Calculates image weights from labels using class weights for weighted sampling.\"\"\"\n    # Usage: index = random.choices(range(n), weights=image_weights, k=1)  # weighted image sample\n    class_counts = np.array([np.bincount(x[:, 0].astype(int), minlength=nc) for x in labels])\n    return (class_weights.reshape(1, nc) * class_counts).sum(1)\ndef coco80_to_coco91_class():\n    \"\"\"\n    Converts COCO 80-class index to COCO 91-class index used in the paper.\n    Reference: https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n    \"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "coco80_to_coco91_class",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def coco80_to_coco91_class():\n    \"\"\"\n    Converts COCO 80-class index to COCO 91-class index used in the paper.\n    Reference: https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n    \"\"\"\n    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n')\n    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n')\n    # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco\n    # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet\n    return [",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def xyxy2xywh(x):\n    \"\"\"Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] where xy1=top-left, xy2=bottom-right.\"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 0] = (x[..., 0] + x[..., 2]) / 2  # x center\n    y[..., 1] = (x[..., 1] + x[..., 3]) / 2  # y center\n    y[..., 2] = x[..., 2] - x[..., 0]  # width\n    y[..., 3] = x[..., 3] - x[..., 1]  # height\n    return y\ndef xywh2xyxy(x):\n    \"\"\"Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def xywh2xyxy(x):\n    \"\"\"Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right.\"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 0] = x[..., 0] - x[..., 2] / 2  # top left x\n    y[..., 1] = x[..., 1] - x[..., 3] / 2  # top left y\n    y[..., 2] = x[..., 0] + x[..., 2] / 2  # bottom right x\n    y[..., 3] = x[..., 1] + x[..., 3] / 2  # bottom right y\n    return y\ndef xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):\n    \"\"\"Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "xywhn2xyxy",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):\n    \"\"\"Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right.\"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 0] = w * (x[..., 0] - x[..., 2] / 2) + padw  # top left x\n    y[..., 1] = h * (x[..., 1] - x[..., 3] / 2) + padh  # top left y\n    y[..., 2] = w * (x[..., 0] + x[..., 2] / 2) + padw  # bottom right x\n    y[..., 3] = h * (x[..., 1] + x[..., 3] / 2) + padh  # bottom right y\n    return y\ndef xyxy2xywhn(x, w=640, h=640, clip=False, eps=0.0):\n    \"\"\"Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "xyxy2xywhn",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def xyxy2xywhn(x, w=640, h=640, clip=False, eps=0.0):\n    \"\"\"Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right.\"\"\"\n    if clip:\n        clip_boxes(x, (h - eps, w - eps))  # warning: inplace clip\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 0] = ((x[..., 0] + x[..., 2]) / 2) / w  # x center\n    y[..., 1] = ((x[..., 1] + x[..., 3]) / 2) / h  # y center\n    y[..., 2] = (x[..., 2] - x[..., 0]) / w  # width\n    y[..., 3] = (x[..., 3] - x[..., 1]) / h  # height\n    return y",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "xyn2xy",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def xyn2xy(x, w=640, h=640, padw=0, padh=0):\n    \"\"\"Convert normalized segments into pixel segments, shape (n,2).\"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 0] = w * x[..., 0] + padw  # top left x\n    y[..., 1] = h * x[..., 1] + padh  # top left y\n    return y\ndef segment2box(segment, width=640, height=640):\n    \"\"\"Convert 1 segment label to 1 box label, applying inside-image constraint, i.e. (xy1, xy2, ...) to (xyxy).\"\"\"\n    x, y = segment.T  # segment xy\n    inside = (x >= 0) & (y >= 0) & (x <= width) & (y <= height)",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "segment2box",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def segment2box(segment, width=640, height=640):\n    \"\"\"Convert 1 segment label to 1 box label, applying inside-image constraint, i.e. (xy1, xy2, ...) to (xyxy).\"\"\"\n    x, y = segment.T  # segment xy\n    inside = (x >= 0) & (y >= 0) & (x <= width) & (y <= height)\n    (\n        x,\n        y,\n    ) = x[inside], y[inside]\n    return np.array([x.min(), y.min(), x.max(), y.max()]) if any(x) else np.zeros((1, 4))  # xyxy\ndef segments2boxes(segments):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "segments2boxes",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def segments2boxes(segments):\n    \"\"\"Convert segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh).\"\"\"\n    boxes = []\n    for s in segments:\n        x, y = s.T  # segment xy\n        boxes.append([x.min(), y.min(), x.max(), y.max()])  # cls, xyxy\n    return xyxy2xywh(np.array(boxes))  # cls, xywh\ndef resample_segments(segments, n=1000):\n    \"\"\"Resamples an (n,2) segment to a fixed number of points for consistent representation.\"\"\"\n    for i, s in enumerate(segments):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "resample_segments",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def resample_segments(segments, n=1000):\n    \"\"\"Resamples an (n,2) segment to a fixed number of points for consistent representation.\"\"\"\n    for i, s in enumerate(segments):\n        s = np.concatenate((s, s[0:1, :]), axis=0)\n        x = np.linspace(0, len(s) - 1, n)\n        xp = np.arange(len(s))\n        segments[i] = np.concatenate([np.interp(x, xp, s[:, i]) for i in range(2)]).reshape(2, -1).T  # segment xy\n    return segments\ndef scale_boxes(img1_shape, boxes, img0_shape, ratio_pad=None):\n    \"\"\"Rescales (xyxy) bounding boxes from img1_shape to img0_shape, optionally using provided `ratio_pad`.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "scale_boxes",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def scale_boxes(img1_shape, boxes, img0_shape, ratio_pad=None):\n    \"\"\"Rescales (xyxy) bounding boxes from img1_shape to img0_shape, optionally using provided `ratio_pad`.\"\"\"\n    if ratio_pad is None:  # calculate from img0_shape\n        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n    else:\n        gain = ratio_pad[0][0]\n        pad = ratio_pad[1]\n    boxes[..., [0, 2]] -= pad[0]  # x padding\n    boxes[..., [1, 3]] -= pad[1]  # y padding",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "scale_segments",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def scale_segments(img1_shape, segments, img0_shape, ratio_pad=None, normalize=False):\n    \"\"\"Rescales segment coordinates from img1_shape to img0_shape, optionally normalizing them with custom padding.\"\"\"\n    if ratio_pad is None:  # calculate from img0_shape\n        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n    else:\n        gain = ratio_pad[0][0]\n        pad = ratio_pad[1]\n    segments[:, 0] -= pad[0]  # x padding\n    segments[:, 1] -= pad[1]  # y padding",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "clip_boxes",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def clip_boxes(boxes, shape):\n    \"\"\"Clips bounding box coordinates (xyxy) to fit within the specified image shape (height, width).\"\"\"\n    if isinstance(boxes, torch.Tensor):  # faster individually\n        boxes[..., 0].clamp_(0, shape[1])  # x1\n        boxes[..., 1].clamp_(0, shape[0])  # y1\n        boxes[..., 2].clamp_(0, shape[1])  # x2\n        boxes[..., 3].clamp_(0, shape[0])  # y2\n    else:  # np.array (faster grouped)\n        boxes[..., [0, 2]] = boxes[..., [0, 2]].clip(0, shape[1])  # x1, x2\n        boxes[..., [1, 3]] = boxes[..., [1, 3]].clip(0, shape[0])  # y1, y2",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "clip_segments",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def clip_segments(segments, shape):\n    \"\"\"Clips segment coordinates (xy1, xy2, ...) to an image's boundaries given its shape (height, width).\"\"\"\n    if isinstance(segments, torch.Tensor):  # faster individually\n        segments[:, 0].clamp_(0, shape[1])  # x\n        segments[:, 1].clamp_(0, shape[0])  # y\n    else:  # np.array (faster grouped)\n        segments[:, 0] = segments[:, 0].clip(0, shape[1])  # x\n        segments[:, 1] = segments[:, 1].clip(0, shape[0])  # y\ndef non_max_suppression(\n    prediction,",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def non_max_suppression(\n    prediction,\n    conf_thres=0.25,\n    iou_thres=0.45,\n    classes=None,\n    agnostic=False,\n    multi_label=False,\n    labels=(),\n    max_det=300,\n    nm=0,  # number of masks",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def strip_optimizer(f=\"best.pt\", s=\"\"):\n    \"\"\"\n    Strips optimizer and optionally saves checkpoint to finalize training; arguments are file path 'f' and save path\n    's'.\n    Example: from utils.general import *; strip_optimizer()\n    \"\"\"\n    x = torch.load(f, map_location=torch.device(\"cpu\"))\n    if x.get(\"ema\"):\n        x[\"model\"] = x[\"ema\"]  # replace model with ema\n    for k in \"optimizer\", \"best_fitness\", \"ema\", \"updates\":  # keys",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "print_mutation",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def print_mutation(keys, results, hyp, save_dir, bucket, prefix=colorstr(\"evolve: \")):\n    \"\"\"Logs evolution results and saves to CSV and YAML in `save_dir`, optionally syncs with `bucket`.\"\"\"\n    evolve_csv = save_dir / \"evolve.csv\"\n    evolve_yaml = save_dir / \"hyp_evolve.yaml\"\n    keys = tuple(keys) + tuple(hyp.keys())  # [results + hyps]\n    keys = tuple(x.strip() for x in keys)\n    vals = results + tuple(hyp.values())\n    n = len(keys)\n    # Download (optional)\n    if bucket:",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "apply_classifier",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def apply_classifier(x, model, img, im0):\n    \"\"\"Applies second-stage classifier to YOLO outputs, filtering detections by class match.\"\"\"\n    # Example model = torchvision.models.__dict__['efficientnet_b0'](pretrained=True).to(device).eval()\n    im0 = [im0] if isinstance(im0, np.ndarray) else im0\n    for i, d in enumerate(x):  # per image\n        if d is not None and len(d):\n            d = d.clone()\n            # Reshape and pad cutouts\n            b = xyxy2xywh(d[:, :4])  # boxes\n            b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # rectangle to square",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def increment_path(path, exist_ok=False, sep=\"\", mkdir=False):\n    \"\"\"\n    Generates an incremented file or directory path if it exists, with optional mkdir; args: path, exist_ok=False,\n    sep=\"\", mkdir=False.\n    Example: runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc\n    \"\"\"\n    path = Path(path)  # os-agnostic\n    if path.exists() and not exist_ok:\n        path, suffix = (path.with_suffix(\"\"), path.suffix) if path.is_file() else (path, \"\")\n        # Method 1",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "imread",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def imread(filename, flags=cv2.IMREAD_COLOR):\n    \"\"\"Reads an image from a file and returns it as a numpy array, using OpenCV's imdecode to support multilanguage\n    paths.\n    \"\"\"\n    return cv2.imdecode(np.fromfile(filename, np.uint8), flags)\ndef imwrite(filename, img):\n    \"\"\"Writes an image to a file, returns True on success and False on failure, supports multilanguage paths.\"\"\"\n    try:\n        cv2.imencode(Path(filename).suffix, img)[1].tofile(filename)\n        return True",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "imwrite",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def imwrite(filename, img):\n    \"\"\"Writes an image to a file, returns True on success and False on failure, supports multilanguage paths.\"\"\"\n    try:\n        cv2.imencode(Path(filename).suffix, img)[1].tofile(filename)\n        return True\n    except Exception:\n        return False\ndef imshow(path, im):\n    \"\"\"Displays an image using Unicode path, requires encoded path and image matrix as input.\"\"\"\n    imshow_(path.encode(\"unicode_escape\").decode(), im)",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "imshow",
        "kind": 2,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "def imshow(path, im):\n    \"\"\"Displays an image using Unicode path, requires encoded path and image matrix as input.\"\"\"\n    imshow_(path.encode(\"unicode_escape\").decode(), im)\nif Path(inspect.stack()[0].filename).parent.parent.as_posix() in inspect.stack()[-1].filename:\n    cv2.imread, cv2.imwrite, cv2.imshow = imread, imwrite, imshow  # redefine\n# Variables ------------------------------------------------------------------------------------------------------------",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[1]  # YOLOv5 root directory\nRANK = int(os.getenv(\"RANK\", -1))\n# Settings\nNUM_THREADS = min(8, max(1, os.cpu_count() - 1))  # number of YOLOv5 multiprocessing threads\nDATASETS_DIR = Path(os.getenv(\"YOLOv5_DATASETS_DIR\", ROOT.parent / \"datasets\"))  # global datasets directory\nAUTOINSTALL = str(os.getenv(\"YOLOv5_AUTOINSTALL\", True)).lower() == \"true\"  # global auto-install mode\nVERBOSE = str(os.getenv(\"YOLOv5_VERBOSE\", True)).lower() == \"true\"  # global verbose mode\nTQDM_BAR_FORMAT = \"{l_bar}{bar:10}{r_bar}\"  # tqdm bar format\nFONT = \"Arial.ttf\"  # https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "ROOT = FILE.parents[1]  # YOLOv5 root directory\nRANK = int(os.getenv(\"RANK\", -1))\n# Settings\nNUM_THREADS = min(8, max(1, os.cpu_count() - 1))  # number of YOLOv5 multiprocessing threads\nDATASETS_DIR = Path(os.getenv(\"YOLOv5_DATASETS_DIR\", ROOT.parent / \"datasets\"))  # global datasets directory\nAUTOINSTALL = str(os.getenv(\"YOLOv5_AUTOINSTALL\", True)).lower() == \"true\"  # global auto-install mode\nVERBOSE = str(os.getenv(\"YOLOv5_VERBOSE\", True)).lower() == \"true\"  # global verbose mode\nTQDM_BAR_FORMAT = \"{l_bar}{bar:10}{r_bar}\"  # tqdm bar format\nFONT = \"Arial.ttf\"  # https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf\ntorch.set_printoptions(linewidth=320, precision=5, profile=\"long\")",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "RANK = int(os.getenv(\"RANK\", -1))\n# Settings\nNUM_THREADS = min(8, max(1, os.cpu_count() - 1))  # number of YOLOv5 multiprocessing threads\nDATASETS_DIR = Path(os.getenv(\"YOLOv5_DATASETS_DIR\", ROOT.parent / \"datasets\"))  # global datasets directory\nAUTOINSTALL = str(os.getenv(\"YOLOv5_AUTOINSTALL\", True)).lower() == \"true\"  # global auto-install mode\nVERBOSE = str(os.getenv(\"YOLOv5_VERBOSE\", True)).lower() == \"true\"  # global verbose mode\nTQDM_BAR_FORMAT = \"{l_bar}{bar:10}{r_bar}\"  # tqdm bar format\nFONT = \"Arial.ttf\"  # https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf\ntorch.set_printoptions(linewidth=320, precision=5, profile=\"long\")\nnp.set_printoptions(linewidth=320, formatter={\"float_kind\": \"{:11.5g}\".format})  # format short g, %precision=5",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "NUM_THREADS = min(8, max(1, os.cpu_count() - 1))  # number of YOLOv5 multiprocessing threads\nDATASETS_DIR = Path(os.getenv(\"YOLOv5_DATASETS_DIR\", ROOT.parent / \"datasets\"))  # global datasets directory\nAUTOINSTALL = str(os.getenv(\"YOLOv5_AUTOINSTALL\", True)).lower() == \"true\"  # global auto-install mode\nVERBOSE = str(os.getenv(\"YOLOv5_VERBOSE\", True)).lower() == \"true\"  # global verbose mode\nTQDM_BAR_FORMAT = \"{l_bar}{bar:10}{r_bar}\"  # tqdm bar format\nFONT = \"Arial.ttf\"  # https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf\ntorch.set_printoptions(linewidth=320, precision=5, profile=\"long\")\nnp.set_printoptions(linewidth=320, formatter={\"float_kind\": \"{:11.5g}\".format})  # format short g, %precision=5\npd.options.display.max_columns = 10\ncv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "DATASETS_DIR",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "DATASETS_DIR = Path(os.getenv(\"YOLOv5_DATASETS_DIR\", ROOT.parent / \"datasets\"))  # global datasets directory\nAUTOINSTALL = str(os.getenv(\"YOLOv5_AUTOINSTALL\", True)).lower() == \"true\"  # global auto-install mode\nVERBOSE = str(os.getenv(\"YOLOv5_VERBOSE\", True)).lower() == \"true\"  # global verbose mode\nTQDM_BAR_FORMAT = \"{l_bar}{bar:10}{r_bar}\"  # tqdm bar format\nFONT = \"Arial.ttf\"  # https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf\ntorch.set_printoptions(linewidth=320, precision=5, profile=\"long\")\nnp.set_printoptions(linewidth=320, formatter={\"float_kind\": \"{:11.5g}\".format})  # format short g, %precision=5\npd.options.display.max_columns = 10\ncv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)\nos.environ[\"NUMEXPR_MAX_THREADS\"] = str(NUM_THREADS)  # NumExpr max threads",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "AUTOINSTALL",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "AUTOINSTALL = str(os.getenv(\"YOLOv5_AUTOINSTALL\", True)).lower() == \"true\"  # global auto-install mode\nVERBOSE = str(os.getenv(\"YOLOv5_VERBOSE\", True)).lower() == \"true\"  # global verbose mode\nTQDM_BAR_FORMAT = \"{l_bar}{bar:10}{r_bar}\"  # tqdm bar format\nFONT = \"Arial.ttf\"  # https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf\ntorch.set_printoptions(linewidth=320, precision=5, profile=\"long\")\nnp.set_printoptions(linewidth=320, formatter={\"float_kind\": \"{:11.5g}\".format})  # format short g, %precision=5\npd.options.display.max_columns = 10\ncv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)\nos.environ[\"NUMEXPR_MAX_THREADS\"] = str(NUM_THREADS)  # NumExpr max threads\nos.environ[\"OMP_NUM_THREADS\"] = \"1\" if platform.system() == \"darwin\" else str(NUM_THREADS)  # OpenMP (PyTorch and SciPy)",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "VERBOSE",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "VERBOSE = str(os.getenv(\"YOLOv5_VERBOSE\", True)).lower() == \"true\"  # global verbose mode\nTQDM_BAR_FORMAT = \"{l_bar}{bar:10}{r_bar}\"  # tqdm bar format\nFONT = \"Arial.ttf\"  # https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf\ntorch.set_printoptions(linewidth=320, precision=5, profile=\"long\")\nnp.set_printoptions(linewidth=320, formatter={\"float_kind\": \"{:11.5g}\".format})  # format short g, %precision=5\npd.options.display.max_columns = 10\ncv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)\nos.environ[\"NUMEXPR_MAX_THREADS\"] = str(NUM_THREADS)  # NumExpr max threads\nos.environ[\"OMP_NUM_THREADS\"] = \"1\" if platform.system() == \"darwin\" else str(NUM_THREADS)  # OpenMP (PyTorch and SciPy)\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # suppress verbose TF compiler warnings in Colab",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "TQDM_BAR_FORMAT = \"{l_bar}{bar:10}{r_bar}\"  # tqdm bar format\nFONT = \"Arial.ttf\"  # https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf\ntorch.set_printoptions(linewidth=320, precision=5, profile=\"long\")\nnp.set_printoptions(linewidth=320, formatter={\"float_kind\": \"{:11.5g}\".format})  # format short g, %precision=5\npd.options.display.max_columns = 10\ncv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)\nos.environ[\"NUMEXPR_MAX_THREADS\"] = str(NUM_THREADS)  # NumExpr max threads\nos.environ[\"OMP_NUM_THREADS\"] = \"1\" if platform.system() == \"darwin\" else str(NUM_THREADS)  # OpenMP (PyTorch and SciPy)\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # suppress verbose TF compiler warnings in Colab\nos.environ[\"TORCH_CPP_LOG_LEVEL\"] = \"ERROR\"  # suppress \"NNPACK.cpp could not initialize NNPACK\" warnings",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "FONT",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "FONT = \"Arial.ttf\"  # https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf\ntorch.set_printoptions(linewidth=320, precision=5, profile=\"long\")\nnp.set_printoptions(linewidth=320, formatter={\"float_kind\": \"{:11.5g}\".format})  # format short g, %precision=5\npd.options.display.max_columns = 10\ncv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)\nos.environ[\"NUMEXPR_MAX_THREADS\"] = str(NUM_THREADS)  # NumExpr max threads\nos.environ[\"OMP_NUM_THREADS\"] = \"1\" if platform.system() == \"darwin\" else str(NUM_THREADS)  # OpenMP (PyTorch and SciPy)\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # suppress verbose TF compiler warnings in Colab\nos.environ[\"TORCH_CPP_LOG_LEVEL\"] = \"ERROR\"  # suppress \"NNPACK.cpp could not initialize NNPACK\" warnings\nos.environ[\"KINETO_LOG_LEVEL\"] = \"5\"  # suppress verbose PyTorch profiler output when computing FLOPs",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "pd.options.display.max_columns",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "pd.options.display.max_columns = 10\ncv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)\nos.environ[\"NUMEXPR_MAX_THREADS\"] = str(NUM_THREADS)  # NumExpr max threads\nos.environ[\"OMP_NUM_THREADS\"] = \"1\" if platform.system() == \"darwin\" else str(NUM_THREADS)  # OpenMP (PyTorch and SciPy)\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # suppress verbose TF compiler warnings in Colab\nos.environ[\"TORCH_CPP_LOG_LEVEL\"] = \"ERROR\"  # suppress \"NNPACK.cpp could not initialize NNPACK\" warnings\nos.environ[\"KINETO_LOG_LEVEL\"] = \"5\"  # suppress verbose PyTorch profiler output when computing FLOPs\ndef is_ascii(s=\"\"):\n    \"\"\"Checks if input string `s` contains only ASCII characters; returns `True` if so, otherwise `False`.\"\"\"\n    s = str(s)  # convert list, tuple, None, etc. to str",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "os.environ[\"NUMEXPR_MAX_THREADS\"]",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "os.environ[\"NUMEXPR_MAX_THREADS\"] = str(NUM_THREADS)  # NumExpr max threads\nos.environ[\"OMP_NUM_THREADS\"] = \"1\" if platform.system() == \"darwin\" else str(NUM_THREADS)  # OpenMP (PyTorch and SciPy)\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # suppress verbose TF compiler warnings in Colab\nos.environ[\"TORCH_CPP_LOG_LEVEL\"] = \"ERROR\"  # suppress \"NNPACK.cpp could not initialize NNPACK\" warnings\nos.environ[\"KINETO_LOG_LEVEL\"] = \"5\"  # suppress verbose PyTorch profiler output when computing FLOPs\ndef is_ascii(s=\"\"):\n    \"\"\"Checks if input string `s` contains only ASCII characters; returns `True` if so, otherwise `False`.\"\"\"\n    s = str(s)  # convert list, tuple, None, etc. to str\n    return len(s.encode().decode(\"ascii\", \"ignore\")) == len(s)\ndef is_chinese(s=\"\"):",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "os.environ[\"OMP_NUM_THREADS\"]",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "os.environ[\"OMP_NUM_THREADS\"] = \"1\" if platform.system() == \"darwin\" else str(NUM_THREADS)  # OpenMP (PyTorch and SciPy)\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # suppress verbose TF compiler warnings in Colab\nos.environ[\"TORCH_CPP_LOG_LEVEL\"] = \"ERROR\"  # suppress \"NNPACK.cpp could not initialize NNPACK\" warnings\nos.environ[\"KINETO_LOG_LEVEL\"] = \"5\"  # suppress verbose PyTorch profiler output when computing FLOPs\ndef is_ascii(s=\"\"):\n    \"\"\"Checks if input string `s` contains only ASCII characters; returns `True` if so, otherwise `False`.\"\"\"\n    s = str(s)  # convert list, tuple, None, etc. to str\n    return len(s.encode().decode(\"ascii\", \"ignore\")) == len(s)\ndef is_chinese(s=\"\"):\n    \"\"\"Determines if a string `s` contains any Chinese characters; returns `True` if so, otherwise `False`.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # suppress verbose TF compiler warnings in Colab\nos.environ[\"TORCH_CPP_LOG_LEVEL\"] = \"ERROR\"  # suppress \"NNPACK.cpp could not initialize NNPACK\" warnings\nos.environ[\"KINETO_LOG_LEVEL\"] = \"5\"  # suppress verbose PyTorch profiler output when computing FLOPs\ndef is_ascii(s=\"\"):\n    \"\"\"Checks if input string `s` contains only ASCII characters; returns `True` if so, otherwise `False`.\"\"\"\n    s = str(s)  # convert list, tuple, None, etc. to str\n    return len(s.encode().decode(\"ascii\", \"ignore\")) == len(s)\ndef is_chinese(s=\"\"):\n    \"\"\"Determines if a string `s` contains any Chinese characters; returns `True` if so, otherwise `False`.\"\"\"\n    return bool(re.search(\"[\\u4e00-\\u9fff]\", str(s)))",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TORCH_CPP_LOG_LEVEL\"]",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "os.environ[\"TORCH_CPP_LOG_LEVEL\"] = \"ERROR\"  # suppress \"NNPACK.cpp could not initialize NNPACK\" warnings\nos.environ[\"KINETO_LOG_LEVEL\"] = \"5\"  # suppress verbose PyTorch profiler output when computing FLOPs\ndef is_ascii(s=\"\"):\n    \"\"\"Checks if input string `s` contains only ASCII characters; returns `True` if so, otherwise `False`.\"\"\"\n    s = str(s)  # convert list, tuple, None, etc. to str\n    return len(s.encode().decode(\"ascii\", \"ignore\")) == len(s)\ndef is_chinese(s=\"\"):\n    \"\"\"Determines if a string `s` contains any Chinese characters; returns `True` if so, otherwise `False`.\"\"\"\n    return bool(re.search(\"[\\u4e00-\\u9fff]\", str(s)))\ndef is_colab():",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "os.environ[\"KINETO_LOG_LEVEL\"]",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "os.environ[\"KINETO_LOG_LEVEL\"] = \"5\"  # suppress verbose PyTorch profiler output when computing FLOPs\ndef is_ascii(s=\"\"):\n    \"\"\"Checks if input string `s` contains only ASCII characters; returns `True` if so, otherwise `False`.\"\"\"\n    s = str(s)  # convert list, tuple, None, etc. to str\n    return len(s.encode().decode(\"ascii\", \"ignore\")) == len(s)\ndef is_chinese(s=\"\"):\n    \"\"\"Determines if a string `s` contains any Chinese characters; returns `True` if so, otherwise `False`.\"\"\"\n    return bool(re.search(\"[\\u4e00-\\u9fff]\", str(s)))\ndef is_colab():\n    \"\"\"Checks if the current environment is a Google Colab instance; returns `True` for Colab, otherwise `False`.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGING_NAME",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "LOGGING_NAME = \"yolov5\"\ndef set_logging(name=LOGGING_NAME, verbose=True):\n    \"\"\"Configures logging with specified verbosity; `name` sets the logger's name, `verbose` controls logging level.\"\"\"\n    rank = int(os.getenv(\"RANK\", -1))  # rank in world for Multi-GPU trainings\n    level = logging.INFO if verbose and rank in {-1, 0} else logging.ERROR\n    logging.config.dictConfig(\n        {\n            \"version\": 1,\n            \"disable_existing_loggers\": False,\n            \"formatters\": {name: {\"format\": \"%(message)s\"}},",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "LOGGER = logging.getLogger(LOGGING_NAME)  # define globally (used in train.py, val.py, detect.py, etc.)\nif platform.system() == \"Windows\":\n    for fn in LOGGER.info, LOGGER.warning:\n        setattr(LOGGER, fn.__name__, lambda x: fn(emojis(x)))  # emoji safe logging\ndef user_config_dir(dir=\"Ultralytics\", env_var=\"YOLOV5_CONFIG_DIR\"):\n    \"\"\"Returns user configuration directory path, preferring environment variable `YOLOV5_CONFIG_DIR` if set, else OS-\n    specific.\n    \"\"\"\n    if env := os.getenv(env_var):\n        path = Path(env)  # use environment variable",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "CONFIG_DIR",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "CONFIG_DIR = user_config_dir()  # Ultralytics settings dir\nclass Profile(contextlib.ContextDecorator):\n    \"\"\"Context manager and decorator for profiling code execution time, with optional CUDA synchronization.\"\"\"\n    def __init__(self, t=0.0, device: torch.device = None):\n        \"\"\"Initializes a profiling context for YOLOv5 with optional timing threshold and device specification.\"\"\"\n        self.t = t\n        self.device = device\n        self.cuda = bool(device and str(device).startswith(\"cuda\"))\n    def __enter__(self):\n        \"\"\"Initializes timing at the start of a profiling context block for performance measurement.\"\"\"",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "imshow_",
        "kind": 5,
        "importPath": "yolov5.utils.general",
        "description": "yolov5.utils.general",
        "peekOfCode": "imshow_ = cv2.imshow  # copy to avoid recursion errors\ndef imread(filename, flags=cv2.IMREAD_COLOR):\n    \"\"\"Reads an image from a file and returns it as a numpy array, using OpenCV's imdecode to support multilanguage\n    paths.\n    \"\"\"\n    return cv2.imdecode(np.fromfile(filename, np.uint8), flags)\ndef imwrite(filename, img):\n    \"\"\"Writes an image to a file, returns True on success and False on failure, supports multilanguage paths.\"\"\"\n    try:\n        cv2.imencode(Path(filename).suffix, img)[1].tofile(filename)",
        "detail": "yolov5.utils.general",
        "documentation": {}
    },
    {
        "label": "BCEBlurWithLogitsLoss",
        "kind": 6,
        "importPath": "yolov5.utils.loss",
        "description": "yolov5.utils.loss",
        "peekOfCode": "class BCEBlurWithLogitsLoss(nn.Module):\n    \"\"\"Modified BCEWithLogitsLoss to reduce missing label effects in YOLOv5 training with optional alpha smoothing.\"\"\"\n    def __init__(self, alpha=0.05):\n        \"\"\"Initializes a modified BCEWithLogitsLoss with reduced missing label effects, taking optional alpha smoothing\n        parameter.\n        \"\"\"\n        super().__init__()\n        self.loss_fcn = nn.BCEWithLogitsLoss(reduction=\"none\")  # must be nn.BCEWithLogitsLoss()\n        self.alpha = alpha\n    def forward(self, pred, true):",
        "detail": "yolov5.utils.loss",
        "documentation": {}
    },
    {
        "label": "FocalLoss",
        "kind": 6,
        "importPath": "yolov5.utils.loss",
        "description": "yolov5.utils.loss",
        "peekOfCode": "class FocalLoss(nn.Module):\n    \"\"\"Applies focal loss to address class imbalance by modifying BCEWithLogitsLoss with gamma and alpha parameters.\"\"\"\n    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):\n        \"\"\"Initializes FocalLoss with specified loss function, gamma, and alpha values; modifies loss reduction to\n        'none'.\n        \"\"\"\n        super().__init__()\n        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()\n        self.gamma = gamma\n        self.alpha = alpha",
        "detail": "yolov5.utils.loss",
        "documentation": {}
    },
    {
        "label": "QFocalLoss",
        "kind": 6,
        "importPath": "yolov5.utils.loss",
        "description": "yolov5.utils.loss",
        "peekOfCode": "class QFocalLoss(nn.Module):\n    \"\"\"Implements Quality Focal Loss to address class imbalance by modulating loss based on prediction confidence.\"\"\"\n    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):\n        \"\"\"Initializes Quality Focal Loss with given loss function, gamma, alpha; modifies reduction to 'none'.\"\"\"\n        super().__init__()\n        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = loss_fcn.reduction\n        self.loss_fcn.reduction = \"none\"  # required to apply FL to each element",
        "detail": "yolov5.utils.loss",
        "documentation": {}
    },
    {
        "label": "ComputeLoss",
        "kind": 6,
        "importPath": "yolov5.utils.loss",
        "description": "yolov5.utils.loss",
        "peekOfCode": "class ComputeLoss:\n    \"\"\"Computes the total loss for YOLOv5 model predictions, including classification, box, and objectness losses.\"\"\"\n    sort_obj_iou = False\n    # Compute losses\n    def __init__(self, model, autobalance=False):\n        \"\"\"Initializes ComputeLoss with model and autobalance option, autobalances losses if True.\"\"\"\n        device = next(model.parameters()).device  # get model device\n        h = model.hyp  # hyperparameters\n        # Define criteria\n        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h[\"cls_pw\"]], device=device))",
        "detail": "yolov5.utils.loss",
        "documentation": {}
    },
    {
        "label": "smooth_BCE",
        "kind": 2,
        "importPath": "yolov5.utils.loss",
        "description": "yolov5.utils.loss",
        "peekOfCode": "def smooth_BCE(eps=0.1):\n    \"\"\"Returns label smoothing BCE targets for reducing overfitting; pos: `1.0 - 0.5*eps`, neg: `0.5*eps`. For details see https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441.\"\"\"\n    return 1.0 - 0.5 * eps, 0.5 * eps\nclass BCEBlurWithLogitsLoss(nn.Module):\n    \"\"\"Modified BCEWithLogitsLoss to reduce missing label effects in YOLOv5 training with optional alpha smoothing.\"\"\"\n    def __init__(self, alpha=0.05):\n        \"\"\"Initializes a modified BCEWithLogitsLoss with reduced missing label effects, taking optional alpha smoothing\n        parameter.\n        \"\"\"\n        super().__init__()",
        "detail": "yolov5.utils.loss",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "kind": 6,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "class ConfusionMatrix:\n    \"\"\"Generates and visualizes a confusion matrix for evaluating object detection classification performance.\"\"\"\n    def __init__(self, nc, conf=0.25, iou_thres=0.45):\n        \"\"\"Initializes ConfusionMatrix with given number of classes, confidence, and IoU threshold.\"\"\"\n        self.matrix = np.zeros((nc + 1, nc + 1))\n        self.nc = nc  # number of classes\n        self.conf = conf\n        self.iou_thres = iou_thres\n    def process_batch(self, detections, labels):\n        \"\"\"",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "fitness",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def fitness(x):\n    \"\"\"Calculates fitness of a model using weighted sum of metrics P, R, mAP@0.5, mAP@0.5:0.95.\"\"\"\n    w = [0.0, 0.0, 0.1, 0.9]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]\n    return (x[:, :4] * w).sum(1)\ndef smooth(y, f=0.05):\n    \"\"\"Applies box filter smoothing to array `y` with fraction `f`, yielding a smoothed array.\"\"\"\n    nf = round(len(y) * f * 2) // 2 + 1  # number of filter elements (must be odd)\n    p = np.ones(nf // 2)  # ones padding\n    yp = np.concatenate((p * y[0], y, p * y[-1]), 0)  # y padded\n    return np.convolve(yp, np.ones(nf) / nf, mode=\"valid\")  # y-smoothed",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "smooth",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def smooth(y, f=0.05):\n    \"\"\"Applies box filter smoothing to array `y` with fraction `f`, yielding a smoothed array.\"\"\"\n    nf = round(len(y) * f * 2) // 2 + 1  # number of filter elements (must be odd)\n    p = np.ones(nf // 2)  # ones padding\n    yp = np.concatenate((p * y[0], y, p * y[-1]), 0)  # y padded\n    return np.convolve(yp, np.ones(nf) / nf, mode=\"valid\")  # y-smoothed\ndef ap_per_class(tp, conf, pred_cls, target_cls, plot=False, save_dir=\".\", names=(), eps=1e-16, prefix=\"\"):\n    \"\"\"\n    Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ap_per_class",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def ap_per_class(tp, conf, pred_cls, target_cls, plot=False, save_dir=\".\", names=(), eps=1e-16, prefix=\"\"):\n    \"\"\"\n    Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n    # Arguments\n        tp:  True positives (nparray, nx1 or nx10).\n        conf:  Objectness value from 0-1 (nparray).\n        pred_cls:  Predicted object classes (nparray).\n        target_cls:  True object classes (nparray).\n        plot:  Plot precision-recall curve at mAP@0.5",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "compute_ap",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def compute_ap(recall, precision):\n    \"\"\"Compute the average precision, given the recall and precision curves\n    # Arguments\n        recall:    The recall curve (list)\n        precision: The precision curve (list)\n    # Returns\n        Average precision, precision curve, recall curve.\n    \"\"\"\n    # Append sentinel values to beginning and end\n    mrec = np.concatenate(([0.0], recall, [1.0]))",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_iou",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def bbox_iou(box1, box2, xywh=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):\n    \"\"\"\n    Calculates IoU, GIoU, DIoU, or CIoU between two boxes, supporting xywh/xyxy formats.\n    Input shapes are box1(1,4) to box2(n,4).\n    \"\"\"\n    # Get the coordinates of bounding boxes\n    if xywh:  # transform from xywh to xyxy\n        (x1, y1, w1, h1), (x2, y2, w2, h2) = box1.chunk(4, -1), box2.chunk(4, -1)\n        w1_, h1_, w2_, h2_ = w1 / 2, h1 / 2, w2 / 2, h2 / 2\n        b1_x1, b1_x2, b1_y1, b1_y2 = x1 - w1_, x1 + w1_, y1 - h1_, y1 + h1_",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def box_iou(box1, box2, eps=1e-7):\n    # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n    \"\"\"\n    Return intersection-over-union (Jaccard index) of boxes.\n    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n    Arguments:\n        box1 (Tensor[N, 4])\n        box2 (Tensor[M, 4])\n    Returns:\n        iou (Tensor[N, M]): the NxM matrix containing the pairwise",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_ioa",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def bbox_ioa(box1, box2, eps=1e-7):\n    \"\"\"\n    Returns the intersection over box2 area given box1, box2.\n    Boxes are x1y1x2y2\n    box1:       np.array of shape(4)\n    box2:       np.array of shape(nx4)\n    returns:    np.array of shape(n)\n    \"\"\"\n    # Get the coordinates of bounding boxes\n    b1_x1, b1_y1, b1_x2, b1_y2 = box1",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "wh_iou",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def wh_iou(wh1, wh2, eps=1e-7):\n    \"\"\"Calculates the Intersection over Union (IoU) for two sets of widths and heights; `wh1` and `wh2` should be nx2\n    and mx2 tensors.\n    \"\"\"\n    wh1 = wh1[:, None]  # [N,1,2]\n    wh2 = wh2[None]  # [1,M,2]\n    inter = torch.min(wh1, wh2).prod(2)  # [N,M]\n    return inter / (wh1.prod(2) + wh2.prod(2) - inter + eps)  # iou = inter / (area1 + area2 - inter)\n# Plots ----------------------------------------------------------------------------------------------------------------\n@threaded",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "plot_pr_curve",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def plot_pr_curve(px, py, ap, save_dir=Path(\"pr_curve.png\"), names=()):\n    \"\"\"Plots precision-recall curve, optionally per class, saving to `save_dir`; `px`, `py` are lists, `ap` is Nx2\n    array, `names` optional.\n    \"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    py = np.stack(py, axis=1)\n    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n        for i, y in enumerate(py.T):\n            ax.plot(px, y, linewidth=1, label=f\"{names[i]} {ap[i, 0]:.3f}\")  # plot(recall, precision)\n    else:",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "plot_mc_curve",
        "kind": 2,
        "importPath": "yolov5.utils.metrics",
        "description": "yolov5.utils.metrics",
        "peekOfCode": "def plot_mc_curve(px, py, save_dir=Path(\"mc_curve.png\"), names=(), xlabel=\"Confidence\", ylabel=\"Metric\"):\n    \"\"\"Plots a metric-confidence curve for model predictions, supporting per-class visualization and smoothing.\"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n        for i, y in enumerate(py):\n            ax.plot(px, y, linewidth=1, label=f\"{names[i]}\")  # plot(confidence, metric)\n    else:\n        ax.plot(px, py.T, linewidth=1, color=\"grey\")  # plot(confidence, metric)\n    y = smooth(py.mean(0), 0.05)\n    ax.plot(px, y, linewidth=3, color=\"blue\", label=f\"all classes {y.max():.2f} at {px[y.argmax()]:.3f}\")",
        "detail": "yolov5.utils.metrics",
        "documentation": {}
    },
    {
        "label": "Colors",
        "kind": 6,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "class Colors:\n    \"\"\"Provides an RGB color palette derived from Ultralytics color scheme for visualization tasks.\"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the Colors class with a palette derived from Ultralytics color scheme, converting hex codes to RGB.\n        Colors derived from `hex = matplotlib.colors.TABLEAU_COLORS.values()`.\n        \"\"\"\n        hexs = (\n            \"FF3838\",\n            \"FF9D97\",",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "feature_visualization",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def feature_visualization(x, module_type, stage, n=32, save_dir=Path(\"runs/detect/exp\")):\n    \"\"\"\n    x:              Features to be visualized\n    module_type:    Module type\n    stage:          Module stage within model\n    n:              Maximum number of feature maps to plot\n    save_dir:       Directory to save results.\n    \"\"\"\n    if (\"Detect\" not in module_type) and (\n        \"Segment\" not in module_type",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "hist2d",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def hist2d(x, y, n=100):\n    \"\"\"\n    Generates a logarithmic 2D histogram, useful for visualizing label or evolution distributions.\n    Used in used in labels.png and evolve.png.\n    \"\"\"\n    xedges, yedges = np.linspace(x.min(), x.max(), n), np.linspace(y.min(), y.max(), n)\n    hist, xedges, yedges = np.histogram2d(x, y, (xedges, yedges))\n    xidx = np.clip(np.digitize(x, xedges) - 1, 0, hist.shape[0] - 1)\n    yidx = np.clip(np.digitize(y, yedges) - 1, 0, hist.shape[1] - 1)\n    return np.log(hist[xidx, yidx])",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "butter_lowpass_filtfilt",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def butter_lowpass_filtfilt(data, cutoff=1500, fs=50000, order=5):\n    \"\"\"Applies a low-pass Butterworth filter to `data` with specified `cutoff`, `fs`, and `order`.\"\"\"\n    from scipy.signal import butter, filtfilt\n    # https://stackoverflow.com/questions/28536191/how-to-filter-smooth-with-scipy-numpy\n    def butter_lowpass(cutoff, fs, order):\n        \"\"\"Applies a low-pass Butterworth filter to a signal with specified cutoff frequency, sample rate, and filter\n        order.\n        \"\"\"\n        nyq = 0.5 * fs\n        normal_cutoff = cutoff / nyq",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def output_to_target(output, max_det=300):\n    \"\"\"Converts YOLOv5 model output to [batch_id, class_id, x, y, w, h, conf] format for plotting, limiting detections\n    to `max_det`.\n    \"\"\"\n    targets = []\n    for i, o in enumerate(output):\n        box, conf, cls = o[:max_det, :6].cpu().split((4, 1, 1), 1)\n        j = torch.full((conf.shape[0], 1), i)\n        targets.append(torch.cat((j, cls, xyxy2xywh(box), conf), 1))\n    return torch.cat(targets, 0).numpy()",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def plot_images(images, targets, paths=None, fname=\"images.jpg\", names=None):\n    \"\"\"Plots an image grid with labels from YOLOv5 predictions or targets, saving to `fname`.\"\"\"\n    if isinstance(images, torch.Tensor):\n        images = images.cpu().float().numpy()\n    if isinstance(targets, torch.Tensor):\n        targets = targets.cpu().numpy()\n    max_size = 1920  # max image size\n    max_subplots = 16  # max image subplots, i.e. 4x4\n    bs, _, h, w = images.shape  # batch size, _, height, width\n    bs = min(bs, max_subplots)  # limit plot images",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_lr_scheduler",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def plot_lr_scheduler(optimizer, scheduler, epochs=300, save_dir=\"\"):\n    \"\"\"Plots learning rate schedule for given optimizer and scheduler, saving plot to `save_dir`.\"\"\"\n    optimizer, scheduler = copy(optimizer), copy(scheduler)  # do not modify originals\n    y = []\n    for _ in range(epochs):\n        scheduler.step()\n        y.append(optimizer.param_groups[0][\"lr\"])\n    plt.plot(y, \".-\", label=\"LR\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"LR\")",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_val_txt",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def plot_val_txt():\n    \"\"\"\n    Plots 2D and 1D histograms of bounding box centers from 'val.txt' using matplotlib, saving as 'hist2d.png' and\n    'hist1d.png'.\n    Example: from utils.plots import *; plot_val()\n    \"\"\"\n    x = np.loadtxt(\"val.txt\", dtype=np.float32)\n    box = xyxy2xywh(x[:, :4])\n    cx, cy = box[:, 0], box[:, 1]\n    fig, ax = plt.subplots(1, 1, figsize=(6, 6), tight_layout=True)",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_targets_txt",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def plot_targets_txt():\n    \"\"\"\n    Plots histograms of object detection targets from 'targets.txt', saving the figure as 'targets.jpg'.\n    Example: from utils.plots import *; plot_targets_txt()\n    \"\"\"\n    x = np.loadtxt(\"targets.txt\", dtype=np.float32).T\n    s = [\"x targets\", \"y targets\", \"width targets\", \"height targets\"]\n    fig, ax = plt.subplots(2, 2, figsize=(8, 8), tight_layout=True)\n    ax = ax.ravel()\n    for i in range(4):",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_val_study",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def plot_val_study(file=\"\", dir=\"\", x=None):\n    \"\"\"\n    Plots validation study results from 'study*.txt' files in a directory or a specific file, comparing model\n    performance and speed.\n    Example: from utils.plots import *; plot_val_study()\n    \"\"\"\n    save_dir = Path(file).parent if file else Path(dir)\n    plot2 = False  # plot additional results\n    if plot2:\n        ax = plt.subplots(2, 4, figsize=(10, 6), tight_layout=True)[1].ravel()",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_labels",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def plot_labels(labels, names=(), save_dir=Path(\"\")):\n    \"\"\"Plots dataset labels, saving correlogram and label images, handles classes, and visualizes bounding boxes.\"\"\"\n    LOGGER.info(f\"Plotting labels to {save_dir / 'labels.jpg'}... \")\n    c, b = labels[:, 0], labels[:, 1:].transpose()  # classes, boxes\n    nc = int(c.max() + 1)  # number of classes\n    x = pd.DataFrame(b.transpose(), columns=[\"x\", \"y\", \"width\", \"height\"])\n    # seaborn correlogram\n    sn.pairplot(x, corner=True, diag_kind=\"auto\", kind=\"hist\", diag_kws=dict(bins=50), plot_kws=dict(pmax=0.9))\n    plt.savefig(save_dir / \"labels_correlogram.jpg\", dpi=200)\n    plt.close()",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "imshow_cls",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def imshow_cls(im, labels=None, pred=None, names=None, nmax=25, verbose=False, f=Path(\"images.jpg\")):\n    \"\"\"Displays a grid of images with optional labels and predictions, saving to a file.\"\"\"\n    from utils.augmentations import denormalize\n    names = names or [f\"class{i}\" for i in range(1000)]\n    blocks = torch.chunk(\n        denormalize(im.clone()).cpu().float(), len(im), dim=0\n    )  # select batch index 0, block by channels\n    n = min(len(blocks), nmax)  # number of plots\n    m = min(8, round(n**0.5))  # 8 x 8 default\n    fig, ax = plt.subplots(math.ceil(n / m), m)  # 8 rows x n/8 cols",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_evolve",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def plot_evolve(evolve_csv=\"path/to/evolve.csv\"):\n    \"\"\"\n    Plots hyperparameter evolution results from a given CSV, saving the plot and displaying best results.\n    Example: from utils.plots import *; plot_evolve()\n    \"\"\"\n    evolve_csv = Path(evolve_csv)\n    data = pd.read_csv(evolve_csv)\n    keys = [x.strip() for x in data.columns]\n    x = data.values\n    f = fitness(x)",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def plot_results(file=\"path/to/results.csv\", dir=\"\"):\n    \"\"\"\n    Plots training results from a 'results.csv' file; accepts file path and directory as arguments.\n    Example: from utils.plots import *; plot_results('path/to/results.csv')\n    \"\"\"\n    save_dir = Path(file).parent if file else Path(dir)\n    fig, ax = plt.subplots(2, 5, figsize=(12, 6), tight_layout=True)\n    ax = ax.ravel()\n    files = list(save_dir.glob(\"results*.csv\"))\n    assert len(files), f\"No results.csv files found in {save_dir.resolve()}, nothing to plot.\"",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "profile_idetection",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def profile_idetection(start=0, stop=0, labels=(), save_dir=\"\"):\n    \"\"\"\n    Plots per-image iDetection logs, comparing metrics like storage and performance over time.\n    Example: from utils.plots import *; profile_idetection()\n    \"\"\"\n    ax = plt.subplots(2, 4, figsize=(12, 6), tight_layout=True)[1].ravel()\n    s = [\"Images\", \"Free Storage (GB)\", \"RAM Usage (GB)\", \"Battery\", \"dt_raw (ms)\", \"dt_smooth (ms)\", \"real-world FPS\"]\n    files = list(Path(save_dir).glob(\"frames*.txt\"))\n    for fi, f in enumerate(files):\n        try:",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "kind": 2,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "def save_one_box(xyxy, im, file=Path(\"im.jpg\"), gain=1.02, pad=10, square=False, BGR=False, save=True):\n    \"\"\"Crops and saves an image from bounding box `xyxy`, applied with `gain` and `pad`, optionally squares and adjusts\n    for BGR.\n    \"\"\"\n    xyxy = torch.tensor(xyxy).view(-1, 4)\n    b = xyxy2xywh(xyxy)  # boxes\n    if square:\n        b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # attempt rectangle to square\n    b[:, 2:] = b[:, 2:] * gain + pad  # box wh * gain + pad\n    xyxy = xywh2xyxy(b).long()",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "RANK = int(os.getenv(\"RANK\", -1))\nmatplotlib.rc(\"font\", **{\"size\": 11})\nmatplotlib.use(\"Agg\")  # for writing to files only\nclass Colors:\n    \"\"\"Provides an RGB color palette derived from Ultralytics color scheme for visualization tasks.\"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the Colors class with a palette derived from Ultralytics color scheme, converting hex codes to RGB.\n        Colors derived from `hex = matplotlib.colors.TABLEAU_COLORS.values()`.\n        \"\"\"",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "colors",
        "kind": 5,
        "importPath": "yolov5.utils.plots",
        "description": "yolov5.utils.plots",
        "peekOfCode": "colors = Colors()  # create instance for 'from utils.plots import colors'\ndef feature_visualization(x, module_type, stage, n=32, save_dir=Path(\"runs/detect/exp\")):\n    \"\"\"\n    x:              Features to be visualized\n    module_type:    Module type\n    stage:          Module stage within model\n    n:              Maximum number of feature maps to plot\n    save_dir:       Directory to save results.\n    \"\"\"\n    if (\"Detect\" not in module_type) and (",
        "detail": "yolov5.utils.plots",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "kind": 6,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "class EarlyStopping:\n    \"\"\"Implements early stopping to halt training when no improvement is observed for a specified number of epochs.\"\"\"\n    def __init__(self, patience=30):\n        \"\"\"Initializes simple early stopping mechanism for YOLOv5, with adjustable patience for non-improving epochs.\"\"\"\n        self.best_fitness = 0.0  # i.e. mAP\n        self.best_epoch = 0\n        self.patience = patience or float(\"inf\")  # epochs to wait after fitness stops improving to stop\n        self.possible_stop = False  # possible stop may occur next epoch\n    def __call__(self, epoch, fitness):\n        \"\"\"Evaluates if training should stop based on fitness improvement and patience, returning a boolean.\"\"\"",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "kind": 6,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "class ModelEMA:\n    \"\"\"Updated Exponential Moving Average (EMA) from https://github.com/rwightman/pytorch-image-models\n    Keeps a moving average of everything in the model state_dict (parameters and buffers)\n    For EMA details see https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage.\n    \"\"\"\n    def __init__(self, model, decay=0.9999, tau=2000, updates=0):\n        \"\"\"Initializes EMA with model parameters, decay rate, tau for decay adjustment, and update count; sets model to\n        evaluation mode.\n        \"\"\"\n        self.ema = deepcopy(de_parallel(model)).eval()  # FP32 EMA",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def smart_inference_mode(torch_1_9=check_version(torch.__version__, \"1.9.0\")):\n    \"\"\"Applies torch.inference_mode() if torch>=1.9.0, else torch.no_grad() as a decorator for functions.\"\"\"\n    def decorate(fn):\n        \"\"\"Applies torch.inference_mode() if torch>=1.9.0, else torch.no_grad() to the decorated function.\"\"\"\n        return (torch.inference_mode if torch_1_9 else torch.no_grad)()(fn)\n    return decorate\ndef smartCrossEntropyLoss(label_smoothing=0.0):\n    \"\"\"Returns a CrossEntropyLoss with optional label smoothing for torch>=1.10.0; warns if smoothing on lower\n    versions.\n    \"\"\"",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smartCrossEntropyLoss",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def smartCrossEntropyLoss(label_smoothing=0.0):\n    \"\"\"Returns a CrossEntropyLoss with optional label smoothing for torch>=1.10.0; warns if smoothing on lower\n    versions.\n    \"\"\"\n    if check_version(torch.__version__, \"1.10.0\"):\n        return nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n    if label_smoothing > 0:\n        LOGGER.warning(f\"WARNING  label smoothing {label_smoothing} requires torch>=1.10.0\")\n    return nn.CrossEntropyLoss()\ndef smart_DDP(model):",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_DDP",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def smart_DDP(model):\n    \"\"\"Initializes DistributedDataParallel (DDP) for model training, respecting torch version constraints.\"\"\"\n    assert not check_version(torch.__version__, \"1.12.0\", pinned=True), (\n        \"torch==1.12.0 torchvision==0.13.0 DDP training is not supported due to a known issue. \"\n        \"Please upgrade or downgrade torch to use DDP. See https://github.com/ultralytics/yolov5/issues/8395\"\n    )\n    if check_version(torch.__version__, \"1.11.0\"):\n        return DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK, static_graph=True)\n    else:\n        return DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK)",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "reshape_classifier_output",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def reshape_classifier_output(model, n=1000):\n    \"\"\"Reshapes last layer of model to match class count 'n', supporting Classify, Linear, Sequential types.\"\"\"\n    from models.common import Classify\n    name, m = list((model.model if hasattr(model, \"model\") else model).named_children())[-1]  # last module\n    if isinstance(m, Classify):  # YOLOv5 Classify() head\n        if m.linear.out_features != n:\n            m.linear = nn.Linear(m.linear.in_features, n)\n    elif isinstance(m, nn.Linear):  # ResNet, EfficientNet\n        if m.out_features != n:\n            setattr(model, name, nn.Linear(m.in_features, n))",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def torch_distributed_zero_first(local_rank: int):\n    \"\"\"Context manager ensuring ordered operations in distributed training by making all processes wait for the leading\n    process.\n    \"\"\"\n    if local_rank not in [-1, 0]:\n        dist.barrier(device_ids=[local_rank])\n    yield\n    if local_rank == 0:\n        dist.barrier(device_ids=[0])\ndef device_count():",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "device_count",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def device_count():\n    \"\"\"Returns the number of available CUDA devices; works on Linux and Windows by invoking `nvidia-smi`.\"\"\"\n    assert platform.system() in (\"Linux\", \"Windows\"), \"device_count() only supported on Linux or Windows\"\n    try:\n        cmd = \"nvidia-smi -L | wc -l\" if platform.system() == \"Linux\" else 'nvidia-smi -L | find /c /v \"\"'  # Windows\n        return int(subprocess.run(cmd, shell=True, capture_output=True, check=True).stdout.decode().split()[-1])\n    except Exception:\n        return 0\ndef select_device(device=\"\", batch_size=0, newline=True):\n    \"\"\"Selects computing device (CPU, CUDA GPU, MPS) for YOLOv5 model deployment, logging device info.\"\"\"",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def select_device(device=\"\", batch_size=0, newline=True):\n    \"\"\"Selects computing device (CPU, CUDA GPU, MPS) for YOLOv5 model deployment, logging device info.\"\"\"\n    s = f\"YOLOv5  {git_describe() or file_date()} Python-{platform.python_version()} torch-{torch.__version__} \"\n    device = str(device).strip().lower().replace(\"cuda:\", \"\").replace(\"none\", \"\")  # to string, 'cuda:0' to '0'\n    cpu = device == \"cpu\"\n    mps = device == \"mps\"  # Apple Metal Performance Shaders (MPS)\n    if cpu or mps:\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # force torch.cuda.is_available() = False\n    elif device:  # non-cpu device requested\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = device  # set environment variable - must be before assert is_available()",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_sync",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def time_sync():\n    \"\"\"Synchronizes PyTorch for accurate timing, leveraging CUDA if available, and returns the current time.\"\"\"\n    if torch.cuda.is_available():\n        torch.cuda.synchronize()\n    return time.time()\ndef profile(input, ops, n=10, device=None):\n    \"\"\"YOLOv5 speed/memory/FLOPs profiler\n    Usage:\n        input = torch.randn(16, 3, 640, 640)\n        m1 = lambda x: x * torch.sigmoid(x)",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "profile",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def profile(input, ops, n=10, device=None):\n    \"\"\"YOLOv5 speed/memory/FLOPs profiler\n    Usage:\n        input = torch.randn(16, 3, 640, 640)\n        m1 = lambda x: x * torch.sigmoid(x)\n        m2 = nn.SiLU()\n        profile(input, [m1, m2], n=100)  # profile over 100 iterations.\n    \"\"\"\n    results = []\n    if not isinstance(device, torch.device):",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "is_parallel",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def is_parallel(model):\n    \"\"\"Checks if the model is using Data Parallelism (DP) or Distributed Data Parallelism (DDP).\"\"\"\n    return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)\ndef de_parallel(model):\n    \"\"\"Returns a single-GPU model by removing Data Parallelism (DP) or Distributed Data Parallelism (DDP) if applied.\"\"\"\n    return model.module if is_parallel(model) else model\ndef initialize_weights(model):\n    \"\"\"Initializes weights of Conv2d, BatchNorm2d, and activations (Hardswish, LeakyReLU, ReLU, ReLU6, SiLU) in the\n    model.\n    \"\"\"",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def de_parallel(model):\n    \"\"\"Returns a single-GPU model by removing Data Parallelism (DP) or Distributed Data Parallelism (DDP) if applied.\"\"\"\n    return model.module if is_parallel(model) else model\ndef initialize_weights(model):\n    \"\"\"Initializes weights of Conv2d, BatchNorm2d, and activations (Hardswish, LeakyReLU, ReLU, ReLU6, SiLU) in the\n    model.\n    \"\"\"\n    for m in model.modules():\n        t = type(m)\n        if t is nn.Conv2d:",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "initialize_weights",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def initialize_weights(model):\n    \"\"\"Initializes weights of Conv2d, BatchNorm2d, and activations (Hardswish, LeakyReLU, ReLU, ReLU6, SiLU) in the\n    model.\n    \"\"\"\n    for m in model.modules():\n        t = type(m)\n        if t is nn.Conv2d:\n            pass  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n        elif t is nn.BatchNorm2d:\n            m.eps = 1e-3",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "find_modules",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def find_modules(model, mclass=nn.Conv2d):\n    \"\"\"Finds and returns list of layer indices in `model.module_list` matching the specified `mclass`.\"\"\"\n    return [i for i, m in enumerate(model.module_list) if isinstance(m, mclass)]\ndef sparsity(model):\n    \"\"\"Calculates and returns the global sparsity of a model as the ratio of zero-valued parameters to total\n    parameters.\n    \"\"\"\n    a, b = 0, 0\n    for p in model.parameters():\n        a += p.numel()",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "sparsity",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def sparsity(model):\n    \"\"\"Calculates and returns the global sparsity of a model as the ratio of zero-valued parameters to total\n    parameters.\n    \"\"\"\n    a, b = 0, 0\n    for p in model.parameters():\n        a += p.numel()\n        b += (p == 0).sum()\n    return b / a\ndef prune(model, amount=0.3):",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "prune",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def prune(model, amount=0.3):\n    \"\"\"Prunes Conv2d layers in a model to a specified sparsity using L1 unstructured pruning.\"\"\"\n    import torch.nn.utils.prune as prune\n    for name, m in model.named_modules():\n        if isinstance(m, nn.Conv2d):\n            prune.l1_unstructured(m, name=\"weight\", amount=amount)  # prune\n            prune.remove(m, \"weight\")  # make permanent\n    LOGGER.info(f\"Model pruned to {sparsity(model):.3g} global sparsity\")\ndef fuse_conv_and_bn(conv, bn):\n    \"\"\"",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_conv_and_bn",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def fuse_conv_and_bn(conv, bn):\n    \"\"\"\n    Fuses Conv2d and BatchNorm2d layers into a single Conv2d layer.\n    See https://tehnokv.com/posts/fusing-batchnorm-and-conv/.\n    \"\"\"\n    fusedconv = (\n        nn.Conv2d(\n            conv.in_channels,\n            conv.out_channels,\n            kernel_size=conv.kernel_size,",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def model_info(model, verbose=False, imgsz=640):\n    \"\"\"\n    Prints model summary including layers, parameters, gradients, and FLOPs; imgsz may be int or list.\n    Example: img_size=640 or img_size=[640, 320]\n    \"\"\"\n    n_p = sum(x.numel() for x in model.parameters())  # number parameters\n    n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  # number gradients\n    if verbose:\n        print(f\"{'layer':>5} {'name':>40} {'gradient':>9} {'parameters':>12} {'shape':>20} {'mu':>10} {'sigma':>10}\")\n        for i, (name, p) in enumerate(model.named_parameters()):",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "scale_img",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def scale_img(img, ratio=1.0, same_shape=False, gs=32):  # img(16,3,256,416)\n    \"\"\"Scales an image tensor `img` of shape (bs,3,y,x) by `ratio`, optionally maintaining the original shape, padded to\n    multiples of `gs`.\n    \"\"\"\n    if ratio == 1.0:\n        return img\n    h, w = img.shape[2:]\n    s = (int(h * ratio), int(w * ratio))  # new size\n    img = F.interpolate(img, size=s, mode=\"bilinear\", align_corners=False)  # resize\n    if not same_shape:  # pad/crop img",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "copy_attr",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def copy_attr(a, b, include=(), exclude=()):\n    \"\"\"Copies attributes from object b to a, optionally filtering with include and exclude lists.\"\"\"\n    for k, v in b.__dict__.items():\n        if (len(include) and k not in include) or k.startswith(\"_\") or k in exclude:\n            continue\n        else:\n            setattr(a, k, v)\ndef smart_optimizer(model, name=\"Adam\", lr=0.001, momentum=0.9, decay=1e-5):\n    \"\"\"\n    Initializes YOLOv5 smart optimizer with 3 parameter groups for different decay configurations.",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_optimizer",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def smart_optimizer(model, name=\"Adam\", lr=0.001, momentum=0.9, decay=1e-5):\n    \"\"\"\n    Initializes YOLOv5 smart optimizer with 3 parameter groups for different decay configurations.\n    Groups are 0) weights with decay, 1) weights no decay, 2) biases no decay.\n    \"\"\"\n    g = [], [], []  # optimizer parameter groups\n    bn = tuple(v for k, v in nn.__dict__.items() if \"Norm\" in k)  # normalization layers, i.e. BatchNorm2d()\n    for v in model.modules():\n        for p_name, p in v.named_parameters(recurse=0):\n            if p_name == \"bias\":  # bias (no decay)",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_hub_load",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def smart_hub_load(repo=\"ultralytics/yolov5\", model=\"yolov5s\", **kwargs):\n    \"\"\"YOLOv5 torch.hub.load() wrapper with smart error handling, adjusting torch arguments for compatibility.\"\"\"\n    if check_version(torch.__version__, \"1.9.1\"):\n        kwargs[\"skip_validation\"] = True  # validation causes GitHub API rate limit errors\n    if check_version(torch.__version__, \"1.12.0\"):\n        kwargs[\"trust_repo\"] = True  # argument required starting in torch 0.12\n    try:\n        return torch.hub.load(repo, model, **kwargs)\n    except Exception:\n        return torch.hub.load(repo, model, force_reload=True, **kwargs)",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_resume",
        "kind": 2,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "def smart_resume(ckpt, optimizer, ema=None, weights=\"yolov5s.pt\", epochs=300, resume=True):\n    \"\"\"Resumes training from a checkpoint, updating optimizer, ema, and epochs, with optional resume verification.\"\"\"\n    best_fitness = 0.0\n    start_epoch = ckpt[\"epoch\"] + 1\n    if ckpt[\"optimizer\"] is not None:\n        optimizer.load_state_dict(ckpt[\"optimizer\"])  # optimizer\n        best_fitness = ckpt[\"best_fitness\"]\n    if ema and ckpt.get(\"ema\"):\n        ema.ema.load_state_dict(ckpt[\"ema\"].float().state_dict())  # EMA\n        ema.updates = ckpt[\"updates\"]",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "kind": 5,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "LOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\ntry:\n    import thop  # for FLOPs computation\nexcept ImportError:\n    thop = None\n# Suppress PyTorch warnings\nwarnings.filterwarnings(\"ignore\", message=\"User provided device_type of 'cuda', but CUDA is not available. Disabling\")\nwarnings.filterwarnings(\"ignore\", category=UserWarning)",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "RANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\ntry:\n    import thop  # for FLOPs computation\nexcept ImportError:\n    thop = None\n# Suppress PyTorch warnings\nwarnings.filterwarnings(\"ignore\", message=\"User provided device_type of 'cuda', but CUDA is not available. Disabling\")\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\ndef smart_inference_mode(torch_1_9=check_version(torch.__version__, \"1.9.0\")):",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "WORLD_SIZE",
        "kind": 5,
        "importPath": "yolov5.utils.torch_utils",
        "description": "yolov5.utils.torch_utils",
        "peekOfCode": "WORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\ntry:\n    import thop  # for FLOPs computation\nexcept ImportError:\n    thop = None\n# Suppress PyTorch warnings\nwarnings.filterwarnings(\"ignore\", message=\"User provided device_type of 'cuda', but CUDA is not available. Disabling\")\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\ndef smart_inference_mode(torch_1_9=check_version(torch.__version__, \"1.9.0\")):\n    \"\"\"Applies torch.inference_mode() if torch>=1.9.0, else torch.no_grad() as a decorator for functions.\"\"\"",
        "detail": "yolov5.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TritonRemoteModel",
        "kind": 6,
        "importPath": "yolov5.utils.triton",
        "description": "yolov5.utils.triton",
        "peekOfCode": "class TritonRemoteModel:\n    \"\"\"\n    A wrapper over a model served by the Triton Inference Server.\n    It can be configured to communicate over GRPC or HTTP. It accepts Torch Tensors as input and returns them as\n    outputs.\n    \"\"\"\n    def __init__(self, url: str):\n        \"\"\"\n        Keyword Arguments:\n        url: Fully qualified address of the Triton server - for e.g. grpc://localhost:8000.",
        "detail": "yolov5.utils.triton",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.benchmarks",
        "description": "yolov5.benchmarks",
        "peekOfCode": "def run(\n    weights=ROOT / \"yolov5s.pt\",  # weights path\n    imgsz=640,  # inference size (pixels)\n    batch_size=1,  # batch size\n    data=ROOT / \"data/coco128.yaml\",  # dataset.yaml path\n    device=\"\",  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n    half=False,  # use FP16 half-precision inference\n    test=False,  # test exports only\n    pt_only=False,  # test PyTorch only\n    hard_fail=False,  # throw error on benchmark failure",
        "detail": "yolov5.benchmarks",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "yolov5.benchmarks",
        "description": "yolov5.benchmarks",
        "peekOfCode": "def test(\n    weights=ROOT / \"yolov5s.pt\",  # weights path\n    imgsz=640,  # inference size (pixels)\n    batch_size=1,  # batch size\n    data=ROOT / \"data/coco128.yaml\",  # dataset.yaml path\n    device=\"\",  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n    half=False,  # use FP16 half-precision inference\n    test=False,  # test exports only\n    pt_only=False,  # test PyTorch only\n    hard_fail=False,  # throw error on benchmark failure",
        "detail": "yolov5.benchmarks",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.benchmarks",
        "description": "yolov5.benchmarks",
        "peekOfCode": "def parse_opt():\n    \"\"\"\n    Parses command-line arguments for YOLOv5 model inference configuration.\n    Args:\n        weights (str): The path to the weights file. Defaults to 'ROOT / \"yolov5s.pt\"'.\n        imgsz (int): Inference size in pixels. Defaults to 640.\n        batch_size (int): Batch size. Defaults to 1.\n        data (str): Path to the dataset YAML file. Defaults to 'ROOT / \"data/coco128.yaml\"'.\n        device (str): CUDA device, e.g., '0' or '0,1,2,3' or 'cpu'. Defaults to an empty string (auto-select).\n        half (bool): Use FP16 half-precision inference. This is a flag and defaults to False.",
        "detail": "yolov5.benchmarks",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.benchmarks",
        "description": "yolov5.benchmarks",
        "peekOfCode": "def main(opt):\n    \"\"\"\n    Executes YOLOv5 benchmark tests or main training/inference routines based on the provided command-line arguments.\n    Args:\n        opt (argparse.Namespace): Parsed command-line arguments including options for weights, image size, batch size, data\n            configuration, device, and other flags for inference settings.\n    Returns:\n        None: This function does not return any value. It leverages side-effects such as logging and running benchmarks.\n    Example:\n        ```python",
        "detail": "yolov5.benchmarks",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.benchmarks",
        "description": "yolov5.benchmarks",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\n# ROOT = ROOT.relative_to(Path.cwd())  # relative\nimport export\nfrom models.experimental import attempt_load\nfrom models.yolo import SegmentationModel\nfrom segment.val import run as val_seg\nfrom utils import notebook_init",
        "detail": "yolov5.benchmarks",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.benchmarks",
        "description": "yolov5.benchmarks",
        "peekOfCode": "ROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\n# ROOT = ROOT.relative_to(Path.cwd())  # relative\nimport export\nfrom models.experimental import attempt_load\nfrom models.yolo import SegmentationModel\nfrom segment.val import run as val_seg\nfrom utils import notebook_init\nfrom utils.general import LOGGER, check_yaml, file_size, print_args",
        "detail": "yolov5.benchmarks",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.detect",
        "description": "yolov5.detect",
        "peekOfCode": "def run(\n    weights=ROOT / \"yolov5s.pt\",  # model path or triton URL\n    source=ROOT / \"data/images\",  # file/dir/URL/glob/screen/0(webcam)\n    data=ROOT / \"data/coco128.yaml\",  # dataset.yaml path\n    imgsz=(640, 640),  # inference size (height, width)\n    conf_thres=0.25,  # confidence threshold\n    iou_thres=0.45,  # NMS IOU threshold\n    max_det=1000,  # maximum detections per image\n    device=\"\",  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n    view_img=False,  # show results",
        "detail": "yolov5.detect",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.detect",
        "description": "yolov5.detect",
        "peekOfCode": "def parse_opt():\n    \"\"\"\n    Parse command-line arguments for YOLOv5 detection, allowing custom inference options and model configurations.\n    Args:\n        --weights (str | list[str], optional): Model path or Triton URL. Defaults to ROOT / 'yolov5s.pt'.\n        --source (str, optional): File/dir/URL/glob/screen/0(webcam). Defaults to ROOT / 'data/images'.\n        --data (str, optional): Dataset YAML path. Provides dataset configuration information.\n        --imgsz (list[int], optional): Inference size (height, width). Defaults to [640].\n        --conf-thres (float, optional): Confidence threshold. Defaults to 0.25.\n        --iou-thres (float, optional): NMS IoU threshold. Defaults to 0.45.",
        "detail": "yolov5.detect",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.detect",
        "description": "yolov5.detect",
        "peekOfCode": "def main(opt):\n    \"\"\"\n    Executes YOLOv5 model inference based on provided command-line arguments, validating dependencies before running.\n    Args:\n        opt (argparse.Namespace): Command-line arguments for YOLOv5 detection. See function `parse_opt` for details.\n    Returns:\n        None\n    Note:\n        This function performs essential pre-execution checks and initiates the YOLOv5 detection process based on user-specified\n        options. Refer to the usage guide and examples for more information about different sources and formats at:",
        "detail": "yolov5.detect",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.detect",
        "description": "yolov5.detect",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom ultralytics.utils.plotting import Annotator, colors, save_one_box\nfrom models.common import DetectMultiBackend\nfrom utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\nfrom utils.general import (\n    LOGGER,",
        "detail": "yolov5.detect",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.detect",
        "description": "yolov5.detect",
        "peekOfCode": "ROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom ultralytics.utils.plotting import Annotator, colors, save_one_box\nfrom models.common import DetectMultiBackend\nfrom utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\nfrom utils.general import (\n    LOGGER,\n    Profile,",
        "detail": "yolov5.detect",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.detect",
        "description": "yolov5.detect",
        "peekOfCode": "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom ultralytics.utils.plotting import Annotator, colors, save_one_box\nfrom models.common import DetectMultiBackend\nfrom utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\nfrom utils.general import (\n    LOGGER,\n    Profile,\n    check_file,\n    check_img_size,\n    check_imshow,",
        "detail": "yolov5.detect",
        "documentation": {}
    },
    {
        "label": "iOSModel",
        "kind": 6,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "class iOSModel(torch.nn.Module):\n    \"\"\"An iOS-compatible wrapper for YOLOv5 models that normalizes input images based on their dimensions.\"\"\"\n    def __init__(self, model, im):\n        \"\"\"\n        Initializes an iOS compatible model with normalization based on image dimensions.\n        Args:\n            model (torch.nn.Module): The PyTorch model to be adapted for iOS compatibility.\n            im (torch.Tensor): An input tensor representing a batch of images with shape (B, C, H, W).\n        Returns:\n            None: This method does not return any value.",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_formats",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_formats():\n    r\"\"\"\n    Returns a DataFrame of supported YOLOv5 model export formats and their properties.\n    Returns:\n        pandas.DataFrame: A DataFrame containing supported export formats and their properties. The DataFrame\n        includes columns for format name, CLI argument suffix, file extension or directory name, and boolean flags\n        indicating if the export format supports training and detection.\n    Examples:\n        ```python\n        formats = export_formats()",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "try_export",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def try_export(inner_func):\n    \"\"\"\n    Log success or failure, execution time, and file size for YOLOv5 model export functions wrapped with @try_export.\n    Args:\n        inner_func (Callable): The model export function to be wrapped by the decorator.\n    Returns:\n        Callable: The wrapped function that logs execution details. When executed, this wrapper function returns either:\n            - Tuple (str | torch.nn.Module): On success  the file path of the exported model and the model instance.\n            - Tuple (None, None): On failure  None values indicating export failure.\n    Examples:",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_torchscript",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\")):\n    \"\"\"\n    Export a YOLOv5 model to the TorchScript format.\n    Args:\n        model (torch.nn.Module): The YOLOv5 model to be exported.\n        im (torch.Tensor): Example input tensor to be used for tracing the TorchScript model.\n        file (Path): File path where the exported TorchScript model will be saved.\n        optimize (bool): If True, applies optimizations for mobile deployment.\n        prefix (str): Optional prefix for log messages. Default is 'TorchScript:'.\n    Returns:",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_onnx",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_onnx(model, im, file, opset, dynamic, simplify, prefix=colorstr(\"ONNX:\")):\n    \"\"\"\n    Export a YOLOv5 model to ONNX format with dynamic axes support and optional model simplification.\n    Args:\n        model (torch.nn.Module): The YOLOv5 model to be exported.\n        im (torch.Tensor): A sample input tensor for model tracing, usually the shape is (1, 3, height, width).\n        file (pathlib.Path | str): The output file path where the ONNX model will be saved.\n        opset (int): The ONNX opset version to use for export.\n        dynamic (bool): If True, enables dynamic axes for batch, height, and width dimensions.\n        simplify (bool): If True, applies ONNX model simplification for optimization.",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_openvino",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_openvino(file, metadata, half, int8, data, prefix=colorstr(\"OpenVINO:\")):\n    \"\"\"\n    Export a YOLOv5 model to OpenVINO format with optional FP16 and INT8 quantization.\n    Args:\n        file (Path): Path to the output file where the OpenVINO model will be saved.\n        metadata (dict): Dictionary including model metadata such as names and strides.\n        half (bool): If True, export the model with FP16 precision.\n        int8 (bool): If True, export the model with INT8 quantization.\n        data (str): Path to the dataset YAML file required for INT8 quantization.\n        prefix (str): Prefix string for logging purposes (default is \"OpenVINO:\").",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_paddle",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_paddle(model, im, file, metadata, prefix=colorstr(\"PaddlePaddle:\")):\n    \"\"\"\n    Export a YOLOv5 PyTorch model to PaddlePaddle format using X2Paddle, saving the converted model and metadata.\n    Args:\n        model (torch.nn.Module): The YOLOv5 model to be exported.\n        im (torch.Tensor): Input tensor used for model tracing during export.\n        file (pathlib.Path): Path to the source file to be converted.\n        metadata (dict): Additional metadata to be saved alongside the model.\n        prefix (str): Prefix for logging information.\n    Returns:",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_coreml",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_coreml(model, im, file, int8, half, nms, mlmodel, prefix=colorstr(\"CoreML:\")):\n    \"\"\"\n    Export a YOLOv5 model to CoreML format with optional NMS, INT8, and FP16 support.\n    Args:\n        model (torch.nn.Module): The YOLOv5 model to be exported.\n        im (torch.Tensor): Example input tensor to trace the model.\n        file (pathlib.Path): Path object where the CoreML model will be saved.\n        int8 (bool): Flag indicating whether to use INT8 quantization (default is False).\n        half (bool): Flag indicating whether to use FP16 quantization (default is False).\n        nms (bool): Flag indicating whether to include Non-Maximum Suppression (default is False).",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_engine",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_engine(\n    model, im, file, half, dynamic, simplify, workspace=4, verbose=False, cache=\"\", prefix=colorstr(\"TensorRT:\")\n):\n    \"\"\"\n    Export a YOLOv5 model to TensorRT engine format, requiring GPU and TensorRT>=7.0.0.\n    Args:\n        model (torch.nn.Module): YOLOv5 model to be exported.\n        im (torch.Tensor): Input tensor of shape (B, C, H, W).\n        file (pathlib.Path): Path to save the exported model.\n        half (bool): Set to True to export with FP16 precision.",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_saved_model",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_saved_model(\n    model,\n    im,\n    file,\n    dynamic,\n    tf_nms=False,\n    agnostic_nms=False,\n    topk_per_class=100,\n    topk_all=100,\n    iou_thres=0.45,",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_pb",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_pb(keras_model, file, prefix=colorstr(\"TensorFlow GraphDef:\")):\n    \"\"\"\n    Export YOLOv5 model to TensorFlow GraphDef (*.pb) format.\n    Args:\n        keras_model (tf.keras.Model): The Keras model to be converted.\n        file (Path): The output file path where the GraphDef will be saved.\n        prefix (str): Optional prefix string; defaults to a colored string indicating TensorFlow GraphDef export status.\n    Returns:\n        Tuple[Path, None]: The file path where the GraphDef model was saved and a None placeholder.\n    Notes:",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_tflite",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_tflite(\n    keras_model, im, file, int8, per_tensor, data, nms, agnostic_nms, prefix=colorstr(\"TensorFlow Lite:\")\n):\n    # YOLOv5 TensorFlow Lite export\n    \"\"\"\n    Export a YOLOv5 model to TensorFlow Lite format with optional INT8 quantization and NMS support.\n    Args:\n        keras_model (tf.keras.Model): The Keras model to be exported.\n        im (torch.Tensor): An input image tensor for normalization and model tracing.\n        file (Path): The file path to save the TensorFlow Lite model.",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_edgetpu",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_edgetpu(file, prefix=colorstr(\"Edge TPU:\")):\n    \"\"\"\n    Exports a YOLOv5 model to Edge TPU compatible TFLite format; requires Linux and Edge TPU compiler.\n    Args:\n        file (Path): Path to the YOLOv5 model file to be exported (.pt format).\n        prefix (str, optional): Prefix for logging messages. Defaults to colorstr(\"Edge TPU:\").\n    Returns:\n        tuple[Path, None]: Path to the exported Edge TPU compatible TFLite model, None.\n    Raises:\n        AssertionError: If the system is not Linux.",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "export_tfjs",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def export_tfjs(file, int8, prefix=colorstr(\"TensorFlow.js:\")):\n    \"\"\"\n    Convert a YOLOv5 model to TensorFlow.js format with optional uint8 quantization.\n    Args:\n        file (Path): Path to the YOLOv5 model file to be converted, typically having a \".pt\" or \".onnx\" extension.\n        int8 (bool): If True, applies uint8 quantization during the conversion process.\n        prefix (str): Optional prefix for logging messages, default is 'TensorFlow.js:' with color formatting.\n    Returns:\n        (str, None): Tuple containing the output directory path as a string and None.\n    Notes:",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "add_tflite_metadata",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def add_tflite_metadata(file, metadata, num_outputs):\n    \"\"\"\n    Adds metadata to a TensorFlow Lite (TFLite) model file, supporting multiple outputs according to TensorFlow\n    guidelines.\n    Args:\n        file (str): Path to the TFLite model file to which metadata will be added.\n        metadata (dict): Metadata information to be added to the model, structured as required by the TFLite metadata schema.\n            Common keys include \"name\", \"description\", \"version\", \"author\", and \"license\".\n        num_outputs (int): Number of output tensors the model has, used to configure the metadata properly.\n    Returns:",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "pipeline_coreml",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def pipeline_coreml(model, im, file, names, y, mlmodel, prefix=colorstr(\"CoreML Pipeline:\")):\n    \"\"\"\n    Convert a PyTorch YOLOv5 model to CoreML format with Non-Maximum Suppression (NMS), handling different input/output\n    shapes, and saving the model.\n    Args:\n        model (torch.nn.Module): The YOLOv5 PyTorch model to be converted.\n        im (torch.Tensor): Example input tensor with shape (N, C, H, W), where N is the batch size, C is the number of channels,\n            H is the height, and W is the width.\n        file (Path): Path to save the converted CoreML model.\n        names (dict[int, str]): Dictionary mapping class indices to class names.",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def run(\n    data=ROOT / \"data/coco128.yaml\",  # 'dataset.yaml path'\n    weights=ROOT / \"yolov5s.pt\",  # weights path\n    imgsz=(640, 640),  # image (height, width)\n    batch_size=1,  # batch size\n    device=\"cpu\",  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n    include=(\"torchscript\", \"onnx\"),  # include formats\n    half=False,  # FP16 half-precision export\n    inplace=False,  # set YOLOv5 Detect() inplace=True\n    keras=False,  # use Keras",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def parse_opt(known=False):\n    \"\"\"\n    Parse command-line options for YOLOv5 model export configurations.\n    Args:\n        known (bool): If True, uses `argparse.ArgumentParser.parse_known_args`; otherwise, uses `argparse.ArgumentParser.parse_args`.\n                      Default is False.\n    Returns:\n        argparse.Namespace: Object containing parsed command-line arguments.\n    Example:\n        ```python",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "def main(opt):\n    \"\"\"Run(**vars(opt))  # Execute the run function with parsed options.\"\"\"\n    for opt.weights in opt.weights if isinstance(opt.weights, list) else [opt.weights]:\n        run(**vars(opt))\nif __name__ == \"__main__\":\n    opt = parse_opt()\n    main(opt)",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nif platform.system() != \"Windows\":\n    ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.experimental import attempt_load\nfrom models.yolo import ClassificationModel, Detect, DetectionModel, SegmentationModel\nfrom utils.dataloaders import LoadImages\nfrom utils.general import (",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "ROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nif platform.system() != \"Windows\":\n    ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.experimental import attempt_load\nfrom models.yolo import ClassificationModel, Detect, DetectionModel, SegmentationModel\nfrom utils.dataloaders import LoadImages\nfrom utils.general import (\n    LOGGER,",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "MACOS",
        "kind": 5,
        "importPath": "yolov5.export",
        "description": "yolov5.export",
        "peekOfCode": "MACOS = platform.system() == \"Darwin\"  # macOS environment\nclass iOSModel(torch.nn.Module):\n    \"\"\"An iOS-compatible wrapper for YOLOv5 models that normalizes input images based on their dimensions.\"\"\"\n    def __init__(self, model, im):\n        \"\"\"\n        Initializes an iOS compatible model with normalization based on image dimensions.\n        Args:\n            model (torch.nn.Module): The PyTorch model to be adapted for iOS compatibility.\n            im (torch.Tensor): An input tensor representing a batch of images with shape (B, C, H, W).\n        Returns:",
        "detail": "yolov5.export",
        "documentation": {}
    },
    {
        "label": "custom",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def custom(path=\"path/to/model.pt\", autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Loads a custom or local YOLOv5 model from a given path with optional autoshaping and device specification.\n    Args:\n        path (str): Path to the custom model file (e.g., 'path/to/model.pt').\n        autoshape (bool): Apply YOLOv5 .autoshape() wrapper to model if True, enabling compatibility with various input\n            types (default is True).\n        _verbose (bool): If True, prints all informational messages to the screen; otherwise, operates silently\n            (default is True).\n        device (str | torch.device | None): Device to load the model on, e.g., 'cpu', 'cuda', torch.device('cuda:0'), etc.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5n",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5n(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Instantiates the YOLOv5-nano model with options for pretraining, input channels, class count, autoshaping,\n    verbosity, and device.\n    Args:\n        pretrained (bool): If True, loads pretrained weights into the model. Defaults to True.\n        channels (int): Number of input channels for the model. Defaults to 3.\n        classes (int): Number of classes for object detection. Defaults to 80.\n        autoshape (bool): If True, applies the YOLOv5 .autoshape() wrapper to the model for various formats (file/URI/PIL/\n            cv2/np) and non-maximum suppression (NMS) during inference. Defaults to True.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5s",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5s(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Create a YOLOv5-small (yolov5s) model with options for pretraining, input channels, class count, autoshaping,\n    verbosity, and device configuration.\n    Args:\n        pretrained (bool, optional): Flag to load pretrained weights into the model. Defaults to True.\n        channels (int, optional): Number of input channels. Defaults to 3.\n        classes (int, optional): Number of model classes. Defaults to 80.\n        autoshape (bool, optional): Whether to wrap the model with YOLOv5's .autoshape() for handling various input formats.\n            Defaults to True.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5m",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5m(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Instantiates the YOLOv5-medium model with customizable pretraining, channel count, class count, autoshaping,\n    verbosity, and device.\n    Args:\n        pretrained (bool, optional): Whether to load pretrained weights into the model. Default is True.\n        channels (int, optional): Number of input channels. Default is 3.\n        classes (int, optional): Number of model classes. Default is 80.\n        autoshape (bool, optional): Apply YOLOv5 .autoshape() wrapper to the model for handling various input formats.\n            Default is True.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5l",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5l(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Creates YOLOv5-large model with options for pretraining, channels, classes, autoshaping, verbosity, and device\n    selection.\n    Args:\n        pretrained (bool): Load pretrained weights into the model. Default is True.\n        channels (int): Number of input channels. Default is 3.\n        classes (int): Number of model classes. Default is 80.\n        autoshape (bool): Apply YOLOv5 .autoshape() wrapper to model. Default is True.\n        _verbose (bool): Print all information to screen. Default is True.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5x",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5x(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Perform object detection using the YOLOv5-xlarge model with options for pretraining, input channels, class count,\n    autoshaping, verbosity, and device specification.\n    Args:\n        pretrained (bool): If True, loads pretrained weights into the model. Defaults to True.\n        channels (int): Number of input channels for the model. Defaults to 3.\n        classes (int): Number of model classes for object detection. Defaults to 80.\n        autoshape (bool): If True, applies the YOLOv5 .autoshape() wrapper for handling different input formats. Defaults to\n            True.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5n6",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5n6(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Creates YOLOv5-nano-P6 model with options for pretraining, channels, classes, autoshaping, verbosity, and device.\n    Args:\n        pretrained (bool, optional): If True, loads pretrained weights into the model. Default is True.\n        channels (int, optional): Number of input channels. Default is 3.\n        classes (int, optional): Number of model classes. Default is 80.\n        autoshape (bool, optional): If True, applies the YOLOv5 .autoshape() wrapper to the model. Default is True.\n        _verbose (bool, optional): If True, prints all information to screen. Default is True.\n        device (str | torch.device | None, optional): Device to use for model parameters. Can be 'cpu', 'cuda', or None.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5s6",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5s6(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Instantiate the YOLOv5-small-P6 model with options for pretraining, input channels, number of classes, autoshaping,\n    verbosity, and device selection.\n    Args:\n        pretrained (bool): If True, loads pretrained weights. Default is True.\n        channels (int): Number of input channels. Default is 3.\n        classes (int): Number of object detection classes. Default is 80.\n        autoshape (bool): If True, applies YOLOv5 .autoshape() wrapper to the model, allowing for varied input formats.\n            Default is True.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5m6",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5m6(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Create YOLOv5-medium-P6 model with options for pretraining, channel count, class count, autoshaping, verbosity, and\n    device.\n    Args:\n        pretrained (bool): If True, loads pretrained weights. Default is True.\n        channels (int): Number of input channels. Default is 3.\n        classes (int): Number of model classes. Default is 80.\n        autoshape (bool): Apply YOLOv5 .autoshape() wrapper to the model for file/URI/PIL/cv2/np inputs and NMS.\n            Default is True.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5l6",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5l6(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Instantiate the YOLOv5-large-P6 model with options for pretraining, channel and class counts, autoshaping,\n    verbosity, and device selection.\n    Args:\n        pretrained (bool, optional): If True, load pretrained weights into the model. Default is True.\n        channels (int, optional): Number of input channels. Default is 3.\n        classes (int, optional): Number of model classes. Default is 80.\n        autoshape (bool, optional): If True, apply YOLOv5 .autoshape() wrapper to the model for input flexibility. Default is True.\n        _verbose (bool, optional): If True, print all information to the screen. Default is True.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "yolov5x6",
        "kind": 2,
        "importPath": "yolov5.hubconf",
        "description": "yolov5.hubconf",
        "peekOfCode": "def yolov5x6(pretrained=True, channels=3, classes=80, autoshape=True, _verbose=True, device=None):\n    \"\"\"\n    Creates the YOLOv5-xlarge-P6 model with options for pretraining, number of input channels, class count, autoshaping,\n    verbosity, and device selection.\n    Args:\n        pretrained (bool): If True, loads pretrained weights into the model. Default is True.\n        channels (int): Number of input channels. Default is 3.\n        classes (int): Number of model classes. Default is 80.\n        autoshape (bool): If True, applies YOLOv5 .autoshape() wrapper to the model. Default is True.\n        _verbose (bool): If True, prints all information to the screen. Default is True.",
        "detail": "yolov5.hubconf",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "def train(hyp, opt, device, callbacks):\n    \"\"\"\n    Train a YOLOv5 model on a custom dataset using specified hyperparameters, options, and device, managing datasets,\n    model architecture, loss computation, and optimizer steps.\n    Args:\n        hyp (str | dict): Path to the hyperparameters YAML file or a dictionary of hyperparameters.\n        opt (argparse.Namespace): Parsed command-line arguments containing training options.\n        device (torch.device): Device on which training occurs, e.g., 'cuda' or 'cpu'.\n        callbacks (Callbacks): Callback functions for various training events.\n    Returns:",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "def parse_opt(known=False):\n    \"\"\"\n    Parse command-line arguments for YOLOv5 training, validation, and testing.\n    Args:\n        known (bool, optional): If True, parses known arguments, ignoring the unknown. Defaults to False.\n    Returns:\n        (argparse.Namespace): Parsed command-line arguments containing options for YOLOv5 execution.\n    Example:\n        ```python\n        from ultralytics.yolo import parse_opt",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "def main(opt, callbacks=Callbacks()):\n    \"\"\"\n    Runs the main entry point for training or hyperparameter evolution with specified options and optional callbacks.\n    Args:\n        opt (argparse.Namespace): The command-line arguments parsed for YOLOv5 training and evolution.\n        callbacks (ultralytics.utils.callbacks.Callbacks, optional): Callback functions for various training stages.\n            Defaults to Callbacks().\n    Returns:\n        None\n    Note:",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "generate_individual",
        "kind": 2,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "def generate_individual(input_ranges, individual_length):\n    \"\"\"\n    Generate an individual with random hyperparameters within specified ranges.\n    Args:\n        input_ranges (list[tuple[float, float]]): List of tuples where each tuple contains the lower and upper bounds\n            for the corresponding gene (hyperparameter).\n        individual_length (int): The number of genes (hyperparameters) in the individual.\n    Returns:\n        list[float]: A list representing a generated individual with random gene values within the specified ranges.\n    Example:",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "def run(**kwargs):\n    \"\"\"\n    Execute YOLOv5 training with specified options, allowing optional overrides through keyword arguments.\n    Args:\n        weights (str, optional): Path to initial weights. Defaults to ROOT / 'yolov5s.pt'.\n        cfg (str, optional): Path to model YAML configuration. Defaults to an empty string.\n        data (str, optional): Path to dataset YAML configuration. Defaults to ROOT / 'data/coco128.yaml'.\n        hyp (str, optional): Path to hyperparameters YAML configuration. Defaults to ROOT / 'data/hyps/hyp.scratch-low.yaml'.\n        epochs (int, optional): Total number of training epochs. Defaults to 100.\n        batch_size (int, optional): Total batch size for all GPUs. Use -1 for automatic batch size determination. Defaults to 16.",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nimport val as validate  # for end-of-epoch mAP\nfrom models.experimental import attempt_load\nfrom models.yolo import Model\nfrom utils.autoanchor import check_anchors\nfrom utils.autobatch import check_train_batch_size",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "ROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nimport val as validate  # for end-of-epoch mAP\nfrom models.experimental import attempt_load\nfrom models.yolo import Model\nfrom utils.autoanchor import check_anchors\nfrom utils.autobatch import check_train_batch_size\nfrom utils.callbacks import Callbacks",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nimport val as validate  # for end-of-epoch mAP\nfrom models.experimental import attempt_load\nfrom models.yolo import Model\nfrom utils.autoanchor import check_anchors\nfrom utils.autobatch import check_train_batch_size\nfrom utils.callbacks import Callbacks\nfrom utils.dataloaders import create_dataloader\nfrom utils.downloads import attempt_download, is_url\nfrom utils.general import (",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "kind": 5,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "LOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nGIT_INFO = check_git_info()\ndef train(hyp, opt, device, callbacks):\n    \"\"\"\n    Train a YOLOv5 model on a custom dataset using specified hyperparameters, options, and device, managing datasets,\n    model architecture, loss computation, and optimizer steps.\n    Args:\n        hyp (str | dict): Path to the hyperparameters YAML file or a dictionary of hyperparameters.",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "RANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nGIT_INFO = check_git_info()\ndef train(hyp, opt, device, callbacks):\n    \"\"\"\n    Train a YOLOv5 model on a custom dataset using specified hyperparameters, options, and device, managing datasets,\n    model architecture, loss computation, and optimizer steps.\n    Args:\n        hyp (str | dict): Path to the hyperparameters YAML file or a dictionary of hyperparameters.\n        opt (argparse.Namespace): Parsed command-line arguments containing training options.",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "WORLD_SIZE",
        "kind": 5,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "WORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\nGIT_INFO = check_git_info()\ndef train(hyp, opt, device, callbacks):\n    \"\"\"\n    Train a YOLOv5 model on a custom dataset using specified hyperparameters, options, and device, managing datasets,\n    model architecture, loss computation, and optimizer steps.\n    Args:\n        hyp (str | dict): Path to the hyperparameters YAML file or a dictionary of hyperparameters.\n        opt (argparse.Namespace): Parsed command-line arguments containing training options.\n        device (torch.device): Device on which training occurs, e.g., 'cuda' or 'cpu'.",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "GIT_INFO",
        "kind": 5,
        "importPath": "yolov5.train",
        "description": "yolov5.train",
        "peekOfCode": "GIT_INFO = check_git_info()\ndef train(hyp, opt, device, callbacks):\n    \"\"\"\n    Train a YOLOv5 model on a custom dataset using specified hyperparameters, options, and device, managing datasets,\n    model architecture, loss computation, and optimizer steps.\n    Args:\n        hyp (str | dict): Path to the hyperparameters YAML file or a dictionary of hyperparameters.\n        opt (argparse.Namespace): Parsed command-line arguments containing training options.\n        device (torch.device): Device on which training occurs, e.g., 'cuda' or 'cpu'.\n        callbacks (Callbacks): Callback functions for various training events.",
        "detail": "yolov5.train",
        "documentation": {}
    },
    {
        "label": "save_one_txt",
        "kind": 2,
        "importPath": "yolov5.val",
        "description": "yolov5.val",
        "peekOfCode": "def save_one_txt(predn, save_conf, shape, file):\n    \"\"\"\n    Saves one detection result to a txt file in normalized xywh format, optionally including confidence.\n    Args:\n        predn (torch.Tensor): Predicted bounding boxes and associated confidence scores and classes in xyxy format, tensor\n            of shape (N, 6) where N is the number of detections.\n        save_conf (bool): If True, saves the confidence scores along with the bounding box coordinates.\n        shape (tuple): Shape of the original image as (height, width).\n        file (str | Path): File path where the result will be saved.\n    Returns:",
        "detail": "yolov5.val",
        "documentation": {}
    },
    {
        "label": "save_one_json",
        "kind": 2,
        "importPath": "yolov5.val",
        "description": "yolov5.val",
        "peekOfCode": "def save_one_json(predn, jdict, path, class_map):\n    \"\"\"\n    Saves a single JSON detection result, including image ID, category ID, bounding box, and confidence score.\n    Args:\n        predn (torch.Tensor): Predicted detections in xyxy format with shape (n, 6) where n is the number of detections.\n                              The tensor should contain [x_min, y_min, x_max, y_max, confidence, class_id] for each detection.\n        jdict (list[dict]): List to collect JSON formatted detection results.\n        path (pathlib.Path): Path object of the image file, used to extract image_id.\n        class_map (dict[int, int]): Mapping from model class indices to dataset-specific category IDs.\n    Returns:",
        "detail": "yolov5.val",
        "documentation": {}
    },
    {
        "label": "process_batch",
        "kind": 2,
        "importPath": "yolov5.val",
        "description": "yolov5.val",
        "peekOfCode": "def process_batch(detections, labels, iouv):\n    \"\"\"\n    Return a correct prediction matrix given detections and labels at various IoU thresholds.\n    Args:\n        detections (np.ndarray): Array of shape (N, 6) where each row corresponds to a detection with format\n            [x1, y1, x2, y2, conf, class].\n        labels (np.ndarray): Array of shape (M, 5) where each row corresponds to a ground truth label with format\n            [class, x1, y1, x2, y2].\n        iouv (np.ndarray): Array of IoU thresholds to evaluate at.\n    Returns:",
        "detail": "yolov5.val",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "yolov5.val",
        "description": "yolov5.val",
        "peekOfCode": "def run(\n    data,\n    weights=None,  # model.pt path(s)\n    batch_size=32,  # batch size\n    imgsz=640,  # inference size (pixels)\n    conf_thres=0.001,  # confidence threshold\n    iou_thres=0.6,  # NMS IoU threshold\n    max_det=300,  # maximum detections per image\n    task=\"val\",  # train, val, test, speed or study\n    device=\"\",  # cuda device, i.e. 0 or 0,1,2,3 or cpu",
        "detail": "yolov5.val",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "yolov5.val",
        "description": "yolov5.val",
        "peekOfCode": "def parse_opt():\n    \"\"\"\n    Parse command-line options for configuring YOLOv5 model inference.\n    Args:\n        data (str, optional): Path to the dataset YAML file. Default is 'data/coco128.yaml'.\n        weights (list[str], optional): List of paths to model weight files. Default is 'yolov5s.pt'.\n        batch_size (int, optional): Batch size for inference. Default is 32.\n        imgsz (int, optional): Inference image size in pixels. Default is 640.\n        conf_thres (float, optional): Confidence threshold for predictions. Default is 0.001.\n        iou_thres (float, optional): IoU threshold for Non-Max Suppression (NMS). Default is 0.6.",
        "detail": "yolov5.val",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "yolov5.val",
        "description": "yolov5.val",
        "peekOfCode": "def main(opt):\n    \"\"\"\n    Executes YOLOv5 tasks like training, validation, testing, speed, and study benchmarks based on provided options.\n    Args:\n        opt (argparse.Namespace): Parsed command-line options.\n            This includes values for parameters like 'data', 'weights', 'batch_size', 'imgsz', 'conf_thres',\n            'iou_thres', 'max_det', 'task', 'device', 'workers', 'single_cls', 'augment', 'verbose', 'save_txt',\n            'save_hybrid', 'save_conf', 'save_json', 'project', 'name', 'exist_ok', 'half', and 'dnn', essential\n            for configuring the YOLOv5 tasks.\n    Returns:",
        "detail": "yolov5.val",
        "documentation": {}
    },
    {
        "label": "FILE",
        "kind": 5,
        "importPath": "yolov5.val",
        "description": "yolov5.val",
        "peekOfCode": "FILE = Path(__file__).resolve()\nROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.common import DetectMultiBackend\nfrom utils.callbacks import Callbacks\nfrom utils.dataloaders import create_dataloader\nfrom utils.general import (\n    LOGGER,",
        "detail": "yolov5.val",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.val",
        "description": "yolov5.val",
        "peekOfCode": "ROOT = FILE.parents[0]  # YOLOv5 root directory\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))  # add ROOT to PATH\nROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.common import DetectMultiBackend\nfrom utils.callbacks import Callbacks\nfrom utils.dataloaders import create_dataloader\nfrom utils.general import (\n    LOGGER,\n    TQDM_BAR_FORMAT,",
        "detail": "yolov5.val",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "yolov5.val",
        "description": "yolov5.val",
        "peekOfCode": "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\nfrom models.common import DetectMultiBackend\nfrom utils.callbacks import Callbacks\nfrom utils.dataloaders import create_dataloader\nfrom utils.general import (\n    LOGGER,\n    TQDM_BAR_FORMAT,\n    Profile,\n    check_dataset,\n    check_img_size,",
        "detail": "yolov5.val",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def main():\n    \"\"\"\n               \n            \n        :\n        1)   dataset/   ,     \n        2)   classes.txt,     \n        3)     dataset/   \n        4)          \n        5)         ",
        "detail": "main",
        "documentation": {}
    }
]